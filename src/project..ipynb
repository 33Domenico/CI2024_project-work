{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3041,
   "id": "10137ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from typing import List, Union, Callable, Optional, Tuple, Dict, Any\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from icecream import ic\n",
    "from tqdm.auto import tqdm\n",
    "import sympy as sp\n",
    "from sympy.parsing.sympy_parser import parse_expr\n",
    "import re "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72598ca0",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3042,
   "id": "c3df2c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ../data/problem_0.npz...\n",
      "Detected format with features on rows and samples on columns, transposition...\n",
      "Final form: X shape (1000, 2), y shape (1000,)\n",
      "Input 2-dimensional with 1000 samples\n",
      "\n",
      "GP Configuration: {'variables': ['x[0]', 'x[1]'], 'n_features': 2, 'const_range': np.float64(3.23346517158693), 'y_stats': {'mean': 0.0740349656325135, 'std': 1.8421127520800509, 'min': -3.208666606823163, 'max': 3.23346517158693}, 'dataset_size': 1000}\n",
      "--------------------------------------------------\n",
      "Loading data from ../data/problem_1.npz...\n",
      "Detected format with features on rows and samples on columns, transposition...\n",
      "Final form: X shape (500, 1), y shape (500,)\n",
      "Input 1-dimensional with 500 samples\n",
      "\n",
      "GP Configuration: {'variables': ['x[0]'], 'n_features': 1, 'const_range': np.float64(0.9954328739932046), 'y_stats': {'mean': -0.028581340125470176, 'std': 0.5035248258112494, 'min': -0.8322110937504172, 'max': 0.8389945887188881}, 'dataset_size': 500}\n",
      "--------------------------------------------------\n",
      "Loading data from ../data/problem_2.npz...\n",
      "Detected format with features on rows and samples on columns, transposition...\n",
      "Final form: X shape (5000, 3), y shape (5000,)\n",
      "Input 3-dimensional with 5000 samples\n",
      "\n",
      "GP Configuration: {'variables': ['x[0]', 'x[1]', 'x[2]'], 'n_features': 3, 'const_range': np.float64(7643020.544814716), 'y_stats': {'mean': 56465.10655809015, 'std': 5441856.124013525, 'min': -7643020.544814716, 'max': 7643015.666932668}, 'dataset_size': 5000}\n",
      "--------------------------------------------------\n",
      "Loading data from ../data/problem_3.npz...\n",
      "Detected format with features on rows and samples on columns, transposition...\n",
      "Final form: X shape (5000, 3), y shape (5000,)\n",
      "Input 3-dimensional with 5000 samples\n",
      "\n",
      "GP Configuration: {'variables': ['x[0]', 'x[1]', 'x[2]'], 'n_features': 3, 'const_range': np.float64(187.18503862007498), 'y_stats': {'mean': 21.20757039569563, 'std': 50.61161179521197, 'min': -134.0160235060043, 'max': 187.18503862007498}, 'dataset_size': 5000}\n",
      "--------------------------------------------------\n",
      "Loading data from ../data/problem_4.npz...\n",
      "Detected format with features on rows and samples on columns, transposition...\n",
      "Final form: X shape (5000, 2), y shape (5000,)\n",
      "Input 2-dimensional with 5000 samples\n",
      "\n",
      "GP Configuration: {'variables': ['x[0]', 'x[1]'], 'n_features': 2, 'const_range': np.float64(10.701637922762112), 'y_stats': {'mean': 1.9997861267141543, 'std': 4.649946409222459, 'min': -4.158487374107485, 'max': 10.701637922762112}, 'dataset_size': 5000}\n",
      "--------------------------------------------------\n",
      "Loading data from ../data/problem_5.npz...\n",
      "Detected format with features on rows and samples on columns, transposition...\n",
      "Final form: X shape (5000, 2), y shape (5000,)\n",
      "Input 2-dimensional with 5000 samples\n",
      "\n",
      "GP Configuration: {'variables': ['x[0]', 'x[1]'], 'n_features': 2, 'const_range': np.float64(4.999969022322079), 'y_stats': {'mean': -5.794871983107769e-10, 'std': 2.2884503096224874e-09, 'min': -2.8520706810421616e-08, 'max': 1.6242242902247692e-10}, 'dataset_size': 5000}\n",
      "--------------------------------------------------\n",
      "Loading data from ../data/problem_6.npz...\n",
      "Detected format with features on rows and samples on columns, transposition...\n",
      "Final form: X shape (5000, 2), y shape (5000,)\n",
      "Input 2-dimensional with 5000 samples\n",
      "\n",
      "GP Configuration: {'variables': ['x[0]', 'x[1]'], 'n_features': 2, 'const_range': np.float64(11.914375580518566), 'y_stats': {'mean': -3.599013872003943, 'std': 3.694501463162234, 'min': -11.914375580518566, 'max': 4.569846551384467}, 'dataset_size': 5000}\n",
      "--------------------------------------------------\n",
      "Loading data from ../data/problem_7.npz...\n",
      "Detected format with features on rows and samples on columns, transposition...\n",
      "Final form: X shape (5000, 2), y shape (5000,)\n",
      "Input 2-dimensional with 5000 samples\n",
      "\n",
      "GP Configuration: {'variables': ['x[0]', 'x[1]'], 'n_features': 2, 'const_range': np.float64(508.41757230561365), 'y_stats': {'mean': 10.230460379797575, 'std': 26.66750114052942, 'min': 1.299874436653608, 'max': 508.41757230561365}, 'dataset_size': 5000}\n",
      "--------------------------------------------------\n",
      "Loading data from ../data/problem_8.npz...\n",
      "Detected format with features on rows and samples on columns, transposition...\n",
      "Final form: X shape (50000, 6), y shape (50000,)\n",
      "Input 6-dimensional with 50000 samples\n",
      "\n",
      "GP Configuration: {'variables': ['x[0]', 'x[1]', 'x[2]', 'x[3]', 'x[4]', 'x[5]'], 'n_features': 6, 'const_range': np.float64(18052.7428193291), 'y_stats': {'mean': -549.7154440795717, 'std': 4765.072335625078, 'min': -18052.7428193291, 'max': 15742.204109576767}, 'dataset_size': 50000}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(file_path):\n",
    "    \"\"\"\n",
    "    Prepares the data for Symbolic Regression with Genetic Programming\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the .npz file containing the data\n",
    "        \n",
    "    Returns:\n",
    "        X: Array of input features\n",
    "        y: Array of target outputs\n",
    "        config: Configuration for GP based on the data\n",
    "    \"\"\"\n",
    "    # 1. Loading the data\n",
    "    print(f\"Loading data from {file_path}...\")\n",
    "    data = np.load(file_path)\n",
    "    X = data['x']\n",
    "    y = data['y']\n",
    "    \n",
    "    # Specific handling for data with transposed dimensions\n",
    "    # If we have more features than samples, we probably need to transpose\n",
    "    if X.ndim > 1 and X.shape[1] > X.shape[0] and y.shape[0] == X.shape[1]:\n",
    "        print(\"Detected format with features on rows and samples on columns, transposition...\")\n",
    "        X = X.T  # Trasponiamo per avere i campioni sulle righe\n",
    "    \n",
    "    # Management of different formats\n",
    "    if y.ndim > 1:\n",
    "        if y.shape[0] == 1 or y.shape[1] == 1:  # If y is [1, n_samples] or [n_samples, 1]\n",
    "            y = y.flatten()\n",
    "            print(f\"y transformed into form {y.shape}\")\n",
    "    \n",
    "    # Make sure that X is 2D if multidimensional\n",
    "    if X.ndim == 1:\n",
    "        X = X.reshape(-1, 1)\n",
    "        print(f\"X rendered 2D with shape{X.shape}\")\n",
    "    \n",
    "    print(f\"Final form: X shape {X.shape}, y shape {y.shape}\")\n",
    "    \n",
    "    # Check for consistency in the number of samples\n",
    "    if X.shape[0] != len(y):\n",
    "        raise ValueError(f\"Inconsistent number of samples: X ha {X.shape[0]} campioni, y ne ha {len(y)}\")\n",
    "    \n",
    "    \n",
    "    # Determining the dimensionality of the input\n",
    "    n_features = X.shape[1]\n",
    "    print(f\"Input {n_features}-dimensional with {X.shape[0]} samples\")\n",
    "    \n",
    "    # Configuration for GP\n",
    "    # We define the ser of variables base on dimensionality\n",
    "    # We assume that the variables are named x[0], x[1], ..., x[n_features-1]\n",
    "    variables = [f'x[{i}]' for i in range(n_features)]\n",
    "    \n",
    "    # We define the range of constants based on the data\n",
    "    const_range = max(np.max(np.abs(X)), np.max(np.abs(y)))\n",
    "    \n",
    "    # Complete configuration for GP\n",
    "    config = {\n",
    "        'variables': variables,\n",
    "        'n_features': n_features,\n",
    "        'const_range': const_range,\n",
    "        'y_stats': {\n",
    "            'mean': float(np.mean(y)),\n",
    "            'std': float(np.std(y)),\n",
    "            'min': float(np.min(y)),\n",
    "            'max': float(np.max(y))\n",
    "        },\n",
    "        'dataset_size': len(y)\n",
    "    }\n",
    "    \n",
    "    return X, y, config\n",
    "\n",
    "for i in range(0, 9):\n",
    "    file_path = f\"../data/problem_{i}.npz\"\n",
    "    X, y, config = prepare_data(file_path)\n",
    "    print(f\"\\nGP Configuration: {config}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf6c960",
   "metadata": {},
   "source": [
    "### Expression Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3043,
   "id": "6d3a13a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"Base class for representing a node in the expression tree\"\"\"\n",
    "    def __init__(self):\n",
    "        self.depth = 0  # Node depth\n",
    "    \n",
    "    def evaluate(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Evaluates the node given an input X\"\"\"\n",
    "        raise NotImplementedError(\"You must implement the evaluate method in the subclass\")\n",
    "    def copy(self) -> 'Node':\n",
    "        \"\"\"Copy current node\"\"\"\n",
    "        raise NotImplementedError(\"You must implement the copy method in the subclass\")\n",
    "    \n",
    "    def to_string(self) -> str:\n",
    "        \"\"\"Returns a string representation of the node\"\"\"\n",
    "        raise NotImplementedError(\"You must implement the to_string method in the subclass\")\n",
    "    \n",
    "    def get_complexity(self) -> int:\n",
    "        \"\"\"Returns the complexity of the node (number of nodes)\"\"\"\n",
    "        return NotImplementedError(\"You must implement the get_complexity method in the subclass\")\n",
    "    \n",
    "    def get_height(self) -> int:\n",
    "        \"\"\"Returns the height of the node\"\"\"\n",
    "        return NotImplementedError(\"You must implement the get_height method in the subclass\")\n",
    "    \n",
    "    def get_nodes(self) -> int:\n",
    "        \"\"\"Returns the total number of nodes in the tree\"\"\"\n",
    "        return NotImplementedError(\"You must implement the get_nodes method in the subclass\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3044,
   "id": "87aba7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionNode(Node):\n",
    "    \"\"\"Class to represent a function node in the expression tree\"\"\"\n",
    "    def __init__(self, function: Callable, arity: int, symbol: str, children: List[Node] = None):\n",
    "        super().__init__()\n",
    "        self.function = function # Function (np) to be applied\n",
    "        self.arity = arity # Number of arguments (children) the function takes\n",
    "        self.symbol = symbol # Symbol to represent the function (e.g., '+', '-', '*', '/')\n",
    "        self.children = children if children is not None else []\n",
    "\n",
    "    def evaluate(self, X: np.ndarray)->np.ndarray:\n",
    "        \"\"\"Evaluate the function by applying it to the children's results\"\"\"\n",
    "        #Evaluate the children\n",
    "        args= [child.evaluate(X) for child in self.children]\n",
    "        # Apply the function\n",
    "        return self.function(*args)\n",
    "    \n",
    "    def copy(self) -> 'FunctionNode':\n",
    "        \"\"\"Creates a deep copy of the function node\"\"\"\n",
    "        new_children = [child.copy() for child in self.children]\n",
    "        new_node = FunctionNode(self.function, self.arity, self.symbol, new_children)\n",
    "        new_node.depth = self.depth\n",
    "        return new_node\n",
    "    \n",
    "    def to_string(self) -> str:\n",
    "        \"\"\"Returns a string representation of the function node\"\"\"\n",
    "        if self.arity == 1:\n",
    "            # Unary function\n",
    "            return f\"{self.symbol}({self.children[0].to_string()})\"\n",
    "        elif self.arity == 2:\n",
    "            # Binary function (e.g. +, -, *, /)\n",
    "            return f\"({self.children[0].to_string()} {self.symbol} {self.children[1].to_string()})\"\n",
    "        else:\n",
    "            # Functions with greater arity (although they should not be common)\n",
    "            args = \", \".join(child.to_string() for child in self.children)\n",
    "            return f\"{self.symbol}({args})\"\n",
    "        \n",
    "    def get_complexity(self) -> int:\n",
    "        \"\"\"Returns the complexity of the node (number of nodes)\"\"\"\n",
    "        return 1 + sum(child.get_complexity() for child in self.children)\n",
    "\n",
    "    def get_height(self) -> int:\n",
    "        \"\"\"Returns the height of the node\"\"\"\n",
    "        return 1 + max((child.get_height() for child in self.children), default=0)\n",
    "\n",
    "    def get_nodes(self) -> List[Node]:\n",
    "        \"\"\"Returns a list of all nodes in the tree\"\"\"\n",
    "        nodes = [self]\n",
    "        for child in self.children:\n",
    "            nodes.extend(child.get_nodes())\n",
    "        return nodes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3045,
   "id": "7dd03f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerminalNode(Node):\n",
    "    \"\"\"Represents an end node in the tree (variable or constant)\"\"\"\n",
    "    \n",
    "    def __init__(self, value, is_variable: bool = False, var_index: int = None):\n",
    "        super().__init__()\n",
    "        self.value = value\n",
    "        self.is_variable = is_variable\n",
    "        self.var_index = var_index  # only used if is_variable is True\n",
    "    \n",
    "    def evaluate(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Evaluate the terminal node\"\"\"\n",
    "        if self.is_variable:\n",
    "            # If it is a variable, we take the value from the input X\n",
    "            if X.ndim == 1 and self.var_index == 0:\n",
    "                return X  # special case for 1D \n",
    "            else:\n",
    "                return X[:, self.var_index]\n",
    "        else:\n",
    "            # If it is a constant, we return the value (broadcast on all samples)\n",
    "            return np.full(X.shape[0] if X.ndim > 1 else len(X), self.value)\n",
    "    \n",
    "    def copy(self) -> 'TerminalNode':\n",
    "        \"\"\"Creates a copy of the terminal node\"\"\"\n",
    "        new_node = TerminalNode(self.value, self.is_variable, self.var_index)\n",
    "        new_node.depth = self.depth\n",
    "        return new_node\n",
    "    \n",
    "    def to_string(self) -> str:\n",
    "        \"\"\"Returns the string representation of the node\"\"\"\n",
    "        if self.is_variable:\n",
    "            return f\"x[{self.var_index}]\"\n",
    "        else:\n",
    "            return str(self.value)\n",
    "    \n",
    "    def get_complexity(self) -> int:\n",
    "        \"\"\"The complexity of a terminal node is 1\"\"\"\n",
    "        return 1\n",
    "    \n",
    "    def get_height(self) -> int:\n",
    "        \"\"\"The height of an end node is 0\"\"\"\n",
    "        return 0\n",
    "    \n",
    "    def get_nodes(self) -> List[Node]:\n",
    "        \"\"\"Returns a list containing only this node\"\"\"\n",
    "        return [self]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3046,
   "id": "417e489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressionTree:\n",
    "    \"\"\"It represents a complete expression tree\"\"\"\n",
    "    \n",
    "    def __init__(self, root: Node):\n",
    "        self.root = root\n",
    "        self.update_node_depths()\n",
    "        self.fitness = None\n",
    "        self.adjusted_fitness = None  # for fitness sharing\n",
    "        self.age = 0  # for age of the tree\n",
    "    \n",
    "    def evaluate(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Evaluates the expression tree on input data\"\"\"\n",
    "        return self.root.evaluate(X)\n",
    "    \n",
    "    def copy(self) -> 'ExpressionTree':\n",
    "        \"\"\"Creates a deep copy of the tree\"\"\"\n",
    "        new_tree = ExpressionTree(self.root.copy())\n",
    "        new_tree.fitness = self.fitness\n",
    "        new_tree.adjusted_fitness = self.adjusted_fitness\n",
    "        new_tree.age = self.age\n",
    "        return new_tree\n",
    "    \n",
    "    def to_string(self) -> str:\n",
    "        \"\"\"Returns the string representation of the tree\"\"\"\n",
    "        return self.root.to_string()\n",
    "    \n",
    "    def get_complexity(self) -> int:\n",
    "        \"\"\"Returns the complexity of the tree\"\"\"\n",
    "        return self.root.get_complexity()\n",
    "    \n",
    "    def get_height(self) -> int:\n",
    "        \"\"\"Returns the height of the tree\"\"\"\n",
    "        return self.root.get_height()\n",
    "    \n",
    "    def get_nodes(self) -> List[Node]:\n",
    "        \"\"\"Returns a list of all nodes in the tree\"\"\"\n",
    "        return self.root.get_nodes()\n",
    "    \n",
    "    def get_subtree_at_index(self, index: int) -> Node:\n",
    "        \"\"\"\n",
    "        Returns the subtree at the node specified by the index\n",
    "        Useful for crossover and mutation operations\n",
    "        \"\"\"\n",
    "        nodes = self.get_nodes()\n",
    "        if 0 <= index < len(nodes):\n",
    "            return nodes[index]\n",
    "        return None\n",
    "    \n",
    "    def replace_subtree_at_index(self, index: int, new_subtree: Node) -> bool:\n",
    "        \"\"\"\n",
    "        Replaces the subtree at the node specified by the index\n",
    "        Returns True if the operation is successful, False otherwise\n",
    "        \"\"\"\n",
    "        nodes = self.get_nodes()\n",
    "        if not (0 <= index < len(nodes)):\n",
    "            return False\n",
    "        \n",
    "        target_node = nodes[index]\n",
    "        \n",
    "        # Special case: replacing the tree root\n",
    "        if target_node == self.root:\n",
    "            self.root = new_subtree\n",
    "            self.update_node_depths()\n",
    "            return True\n",
    "        \n",
    "        # Otherwise, we need to find the parent of the target node\n",
    "        for node in nodes:\n",
    "            if isinstance(node, FunctionNode):\n",
    "                for i, child in enumerate(node.children):\n",
    "                    if child == target_node:\n",
    "                        node.children[i] = new_subtree\n",
    "                        self.update_node_depths()\n",
    "                        return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def update_node_depths(self):\n",
    "        \"\"\"Updates the depth of all nodes in the tree\"\"\"\n",
    "        self._update_depth(self.root, 0)\n",
    "    \n",
    "    def _update_depth(self, node: Node, depth: int):\n",
    "        \"\"\"Recursive helper to update depth\"\"\"\n",
    "        node.depth = depth\n",
    "        if isinstance(node, FunctionNode):\n",
    "            for child in node.children:\n",
    "                self._update_depth(child, depth + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8352c5",
   "metadata": {},
   "source": [
    "### Function Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3047,
   "id": "ce9660cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_div(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Protected division: returns a/b or 1 when b is close to zero\"\"\"\n",
    "    return np.divide(a, b, out=np.ones_like(a), where=np.abs(b) > 1e-8)\n",
    "\n",
    "def safe_log(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Protected logarithm: returns log(|a|) or 0 for a close to zero\"\"\"\n",
    "    return np.log(np.abs(a), out=np.zeros_like(a), where=np.abs(a) > 1e-10)\n",
    "\n",
    "def safe_sqrt(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Square root protected: returns sqrt(|a|)\"\"\"\n",
    "    return np.sqrt(np.abs(a))\n",
    "\n",
    "def safe_exp(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Protected exponential: limits input to avoid overflow\"\"\"\n",
    "    return np.exp(np.clip(a, -200, 200))\n",
    "\n",
    "def safe_sin(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Protected sin\"\"\"\n",
    "    return np.sin(np.clip(a, -1000, 1000))\n",
    "\n",
    "def safe_cos(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Protected cos\"\"\"\n",
    "    return np.cos(np.clip(a, -1000, 1000))\n",
    "\n",
    "def safe_tan(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Protected tangent: limits outputs to avoid extreme values\"\"\"\n",
    "    return np.clip(np.tan(a), -200, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3048,
   "id": "0bf5fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_function_set(use_trig: bool = True, use_exp_log: bool = True) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Creates a set of functions to be used in the expression tree.\n",
    "    \n",
    "    Args:\n",
    "        use_trig: Whether to include trigonometric functions.\n",
    "        use_exp_log: Whether to include exponential and logarithmic functions.\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries, each containing:\n",
    "            - function: the Python function to call.\n",
    "            - arity: the number of arguments required.\n",
    "            - symbol: the symbol for display.\n",
    "            - weight: selection weight (relative probability).\n",
    "    \"\"\"\n",
    "    # Basic arithmetic functions (always included)\n",
    "    functions = [\n",
    "        {'function': np.add, 'arity': 2, 'symbol': '+', 'weight': 1.0},\n",
    "        {'function': np.subtract, 'arity': 2, 'symbol': '-', 'weight': 1.0},\n",
    "        {'function': np.multiply, 'arity': 2, 'symbol': '*', 'weight': 1.0},\n",
    "        {'function': safe_div, 'arity': 2, 'symbol': '/', 'weight': 0.7},  # Peso più basso per la divisione\n",
    "    ]\n",
    "    \n",
    "    # Trigonometric functions (optional)\n",
    "    if use_trig:\n",
    "        functions.extend([\n",
    "            {'function': safe_sin, 'arity': 1, 'symbol': 'sin', 'weight': 0.6},\n",
    "            {'function': safe_cos, 'arity': 1, 'symbol': 'cos', 'weight': 0.6},\n",
    "            {'function': safe_tan, 'arity': 1, 'symbol': 'tan', 'weight': 0.5},  # Peso più basso per la tangente\n",
    "        ])\n",
    "    \n",
    "    # Exponential and logarithmic functions (optional)\n",
    "    if use_exp_log:\n",
    "        functions.extend([\n",
    "            {'function': safe_exp, 'arity': 1, 'symbol': 'exp', 'weight': 0.4},\n",
    "            {'function': safe_log, 'arity': 1, 'symbol': 'log', 'weight': 0.5},\n",
    "            {'function': safe_sqrt, 'arity': 1, 'symbol': 'sqrt', 'weight': 0.6},\n",
    "        ])\n",
    "    \n",
    "    return functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1309f4b7",
   "metadata": {},
   "source": [
    "### Terminal Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3049,
   "id": "f9b96171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variable_terminals(n_features: int, variable_weight: float = 1.0) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Create terminals for input variables\n",
    "    \n",
    "    Args:\n",
    "        n_features: Number of input variables\n",
    "        variable_weight: Weight assigned to the variables\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries for variable terminals\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {\n",
    "            'is_variable': True, \n",
    "            'var_index': i, \n",
    "            'weight': variable_weight\n",
    "        } for i in range(n_features)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3050,
   "id": "e1743b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_constant_terminals(const_range: float, n_constants: int = 10, \n",
    "                             standard_weight: float = 0.3,\n",
    "                             zero_weight: float = 0.5,\n",
    "                             one_weight: float = 0.5,\n",
    "                             minus_one_weight: float = 0.3,\n",
    "                             pi_weight: float = 0.2,\n",
    "                             e_weight: float = 0.2) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Creates terminals for constants\n",
    "    \n",
    "    Args:\n",
    "        const_range: Range for random constants\n",
    "        n_constants: Number of pre-generated constants\n",
    "        standard_weight: Weight for random constants\n",
    "        zero_weight: Weight for the constant 0\n",
    "        one_weight: Weight for the constant 1\n",
    "        minus_one_weight: Weight for the constant -1\n",
    "        pi_weight: Weight for the constant π\n",
    "        e_weight: Weight for the constant e\n",
    "        \n",
    "    Returns:\n",
    "        List of dictionaries for constant terminals\n",
    "    \"\"\"\n",
    "    # Costanti fisse importanti\n",
    "    fixed_constants = [\n",
    "        {'is_variable': False, 'value': 1.0, 'weight': one_weight},\n",
    "        {'is_variable': False, 'value': -1.0, 'weight': minus_one_weight},\n",
    "        {'is_variable': False, 'value': np.pi, 'weight': pi_weight},\n",
    "        {'is_variable': False, 'value': np.e, 'weight': e_weight},\n",
    "    ]\n",
    "    \n",
    "    # Random constants pre-generated\n",
    "    random_constants = [\n",
    "        {\n",
    "            'is_variable': False, \n",
    "            'value': random.uniform(-const_range, const_range) if abs(random.uniform(-const_range, const_range)) > 1e-8 else 1.0, # Avoid zero\n",
    "            'weight': standard_weight\n",
    "        } for _ in range(n_constants)\n",
    "    ]\n",
    "    \n",
    "    return fixed_constants + random_constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3051,
   "id": "6323bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ephemeral_constant(const_range: float) -> float:\n",
    "    \"\"\"\n",
    "    Generates an ephemeral random constant\n",
    "    avoiding values too close to zero\n",
    "    \"\"\"\n",
    "    value = random.uniform(-const_range, const_range)\n",
    "    # Avoid values too close to zero\n",
    "    if abs(value) < 1e-8:\n",
    "        if random.random() < 0.5:\n",
    "            value = 1e-8\n",
    "        else:\n",
    "            value = -1e-8\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3052,
   "id": "cdd938e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPConfig:\n",
    "    \"\"\"Class for managing the configuration of the GP algorithm\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_features: int,\n",
    "                 const_range: float,\n",
    "                 use_trig: bool = True,\n",
    "                 use_exp_log: bool = True,\n",
    "                 min_depth: int = 2,\n",
    "                 max_depth: int = 6,\n",
    "                 pop_size: int = 500,\n",
    "                 generations: int = 50,\n",
    "                 tournament_size: int = 5,\n",
    "                 crossover_prob: float = 0.7,\n",
    "                 mutation_prob: float = 0.2,\n",
    "                 elitism_rate: float = 0.1,\n",
    "                 max_tree_size: int = 50,\n",
    "                 parsimony_coef: float = 0.01,\n",
    "                function_weights: dict = None,\n",
    "                terminal_weights: dict = None):\n",
    "        \n",
    "        # Function Set Configuration and Terminals\n",
    "        self.function_set = create_function_set(use_trig, use_exp_log)\n",
    "        self.variable_terminals = create_variable_terminals(n_features)\n",
    "        self.constant_terminals = create_constant_terminals(const_range)\n",
    "        \n",
    "        # Apply any custom weights to functions\n",
    "        if function_weights:\n",
    "            self._apply_function_weights(function_weights)\n",
    "            \n",
    "        # Apply any customised weights to the terminals\n",
    "        if terminal_weights:\n",
    "            self._apply_terminal_weights(terminal_weights)\n",
    "\n",
    "\n",
    "\n",
    "        # Calculates cumulative weights for weighted selection\n",
    "        self._calculate_weights()\n",
    "        \n",
    "        # Tree size limits\n",
    "        self.min_depth = min_depth\n",
    "        self.max_depth = max_depth\n",
    "        self.max_tree_size = max_tree_size\n",
    "        \n",
    "        # Parameters of the evolutionary algorithm\n",
    "        self.pop_size = pop_size\n",
    "        self.generations = generations\n",
    "        self.tournament_size = tournament_size\n",
    "        self.crossover_prob = crossover_prob\n",
    "        self.mutation_prob = mutation_prob\n",
    "        self.elitism_rate = elitism_rate\n",
    "        \n",
    "        # Bloat control and diversity maintenance\n",
    "        self.parsimony_coef = parsimony_coef  # penalty for complexity\n",
    "        \n",
    "        # Other parameters\n",
    "        self.n_features = n_features\n",
    "        self.const_range = const_range\n",
    "\n",
    "\n",
    "    def _apply_function_weights(self, function_weights):\n",
    "        \"\"\"Apply custom weights to functions\"\"\"\n",
    "        for func in self.function_set:\n",
    "            symbol = func['symbol']\n",
    "            if symbol in function_weights:\n",
    "                func['weight'] = function_weights[symbol]\n",
    "                print(f\"Personalised weight for {symbol}: {func['weight']}\")\n",
    "    \n",
    "    def _apply_terminal_weights(self, terminal_weights):\n",
    "        \"\"\"Apply custom weights to terminals\"\"\"\n",
    "        # For variables\n",
    "        if 'variables' in terminal_weights:\n",
    "            for var in self.variable_terminals:\n",
    "                var['weight'] = terminal_weights['variables']\n",
    "                \n",
    "        \n",
    "        if 'constants' in terminal_weights:\n",
    "            for const in self.constant_terminals:\n",
    "                if isinstance(const['value'], float) and not (const['value'] in [1.0, -1.0, np.pi, np.e]):\n",
    "                    const['weight'] = terminal_weights['constants']\n",
    "                    \n",
    "        if 'one' in terminal_weights:\n",
    "            for const in self.constant_terminals:\n",
    "                if const['value'] == 1.0:\n",
    "                    const['weight'] = terminal_weights['one']\n",
    "                    \n",
    "        if 'minus_one' in terminal_weights:\n",
    "            for const in self.constant_terminals:\n",
    "                if const['value'] == -1.0:\n",
    "                    const['weight'] = terminal_weights['minus_one']\n",
    "        \n",
    "        if 'pi' in terminal_weights:\n",
    "            for const in self.constant_terminals:\n",
    "                if const['value'] == np.pi:\n",
    "                    const['weight'] = terminal_weights['pi']\n",
    "                    \n",
    "        if 'e' in terminal_weights:\n",
    "            for const in self.constant_terminals:\n",
    "                if const['value'] == np.e:\n",
    "                    const['weight'] = terminal_weights['e']\n",
    "        \n",
    "                \n",
    "\n",
    "\n",
    "    def _calculate_weights(self):\n",
    "        \"\"\"Calculates cumulative weights for weighted selection of functions and terminals\"\"\"\n",
    "        # Cumulative weights for functions\n",
    "        cum_weight = 0\n",
    "        self.function_cumulative_weights  = []\n",
    "        for func in self.function_set:\n",
    "            cum_weight += func['weight']\n",
    "            self.function_cumulative_weights.append(cum_weight)\n",
    "        \n",
    "        # Normalise weights\n",
    "        if cum_weight > 0:\n",
    "            self.function_cumulative_weights  = [w / cum_weight for w in self.function_cumulative_weights]\n",
    "        \n",
    "        # Cumulative weights for variable terminalsi\n",
    "        cum_weight = 0\n",
    "        self.variable_weights = []\n",
    "        for var in self.variable_terminals:\n",
    "            cum_weight += var['weight']\n",
    "            self.variable_weights.append(cum_weight)\n",
    "        \n",
    "        # Normalise weights\n",
    "        if cum_weight > 0:\n",
    "            self.variable_weights = [w / cum_weight for w in self.variable_weights]\n",
    "        \n",
    "        # Cumulative weights for constant terminals\n",
    "        cum_weight = 0\n",
    "        self.constant_weights = []\n",
    "        for const in self.constant_terminals:\n",
    "            cum_weight += const['weight']\n",
    "            self.constant_weights.append(cum_weight)\n",
    "        \n",
    "        # Normalise weights\n",
    "        if cum_weight > 0:\n",
    "            self.constant_weights = [w / cum_weight for w in self.constant_weights]\n",
    "    \n",
    "    def get_random_function(self) -> Dict[str, Any]:\n",
    "        \"\"\"Randomly selects a function from the set, based on weights\"\"\"\n",
    "        r = random.random()\n",
    "        for i, w in enumerate(self.function_cumulative_weights):\n",
    "            if r <= w:\n",
    "                return self.function_set[i]\n",
    "        return self.function_set[-1]  # fallback\n",
    "    \n",
    "    def get_random_variable(self) -> Dict[str, Any]:\n",
    "        \"\"\"Randomly selects a terminal variable from the set, based on the weights\"\"\"\n",
    "        if not self.variable_terminals:\n",
    "            raise ValueError(\"No variables available\")\n",
    "        \n",
    "        r = random.random()\n",
    "        for i, w in enumerate(self.variable_weights):\n",
    "            if r <= w:\n",
    "                return self.variable_terminals[i]\n",
    "        return self.variable_terminals[-1]  # fallback\n",
    "    \n",
    "    def get_random_constant(self) -> Dict[str, Any]:\n",
    "        \"\"\"Randomly selects a terminal constant from the set, based on the weights\"\"\"\n",
    "        if not self.constant_terminals:\n",
    "            # Generates a new ephemeral constant if no pre-defined constants are available\n",
    "            return {'is_variable': False, 'value': generate_ephemeral_constant(self.const_range)}\n",
    "        \n",
    "        # Occasionally generates a new efimera constant instead of using a default one\n",
    "        if random.random() < 0.3:  # 30% probability of generating a new constant\n",
    "            return {'is_variable': False, 'value': generate_ephemeral_constant(self.const_range)}\n",
    "        \n",
    "        # Otherwise, select from the default constants\n",
    "        r = random.random()\n",
    "        for i, w in enumerate(self.constant_weights):\n",
    "            if r <= w:\n",
    "                return self.constant_terminals[i]\n",
    "        return self.constant_terminals[-1]  # fallback\n",
    "    \n",
    "    def get_random_terminal(self) -> Dict[str, Any]:\n",
    "        \"\"\"Randomly selects a terminal (variable or constant)\"\"\"\n",
    "        # Probability of selecting a variable vs. a constant\n",
    "        # We generally want to give more weight to the variable\n",
    "        if random.random() < 0.7:  # 70% probability of selecting a variable\n",
    "            try:\n",
    "                return self.get_random_variable()\n",
    "            except ValueError:\n",
    "                return self.get_random_constant()\n",
    "        else:\n",
    "            return self.get_random_constant()\n",
    "        \n",
    "    def print_function_weights(self):\n",
    "        \"\"\"Print current function weights\"\"\"\n",
    "        print(\"Function weights:\")\n",
    "        for func in self.function_set:\n",
    "            print(f\"  {func['symbol']}: {func['weight']:.2f}\")\n",
    "    \n",
    "    def print_terminal_weights(self):\n",
    "        \"\"\"Print current terminal weights\"\"\"\n",
    "        print(\"Variable terminal weights:\")\n",
    "        for var in self.variable_terminals:\n",
    "            print(f\"  x[{var['var_index']}]: {var['weight']:.2f}\")\n",
    "        \n",
    "        print(\"Constant terminal weights:\")\n",
    "        for const in self.constant_terminals:\n",
    "            value_str = f\"{const['value']}\" if not const['is_variable'] else f\"x[{const['var_index']}]\"\n",
    "            print(f\"  {value_str}: {const['weight']:.2f}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b102241",
   "metadata": {},
   "source": [
    "### Initial Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3053,
   "id": "ec8fc748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow_tree(config: GPConfig, max_depth: int, min_depth: int = 1, current_depth: int = 0) -> Node:\n",
    "    \"\"\"\n",
    "    Grow' method for generating a tree with variable depth\n",
    "    \n",
    "    Args:\n",
    "        config: GP configuration\n",
    "        max_depth: Maximum depth of the tree\n",
    "        min_depth: Minimum depth of the tree\n",
    "        current_depth: Current depth of the node\n",
    "        \n",
    "    Returns:\n",
    "        Root node of the generated tree\n",
    "    \"\"\"\n",
    "    # If we are at the maximum depth, we can only create terminal nodes\n",
    "    if current_depth >= max_depth:\n",
    "        terminal_info = config.get_random_terminal()\n",
    "        if terminal_info['is_variable']:\n",
    "            return TerminalNode(None, is_variable=True, var_index=terminal_info['var_index'])\n",
    "        else:\n",
    "            return TerminalNode(terminal_info['value'], is_variable=False)\n",
    "    \n",
    "    # If we have not yet reached the minimum depth, we only create function nodes\n",
    "    if current_depth < min_depth:\n",
    "        function_info = config.get_random_function()\n",
    "        children = [grow_tree(config, max_depth, min_depth, current_depth + 1) for _ in range(function_info['arity'])]\n",
    "        return FunctionNode(function_info['function'], function_info['arity'], function_info['symbol'], children)\n",
    "    \n",
    "    # Otherwise, we randomly choose between functions and terminals\n",
    "    if random.random() < 0.5:  # 50% probability for functions or terminals\n",
    "        function_info = config.get_random_function()\n",
    "        children = [grow_tree(config, max_depth, min_depth, current_depth + 1) for _ in range(function_info['arity'])]\n",
    "        return FunctionNode(function_info['function'], function_info['arity'], function_info['symbol'], children)\n",
    "    else:\n",
    "        terminal_info = config.get_random_terminal()\n",
    "        if terminal_info['is_variable']:\n",
    "            return TerminalNode(None, is_variable=True, var_index=terminal_info['var_index'])\n",
    "        else:\n",
    "            return TerminalNode(terminal_info['value'], is_variable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3054,
   "id": "dc30d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_tree(config: GPConfig, max_depth: int, current_depth: int = 0) -> Node:\n",
    "    \"\"\"\n",
    "    Full' method for generating a tree with all branches at the same depth\n",
    "    \n",
    "    Args:\n",
    "        config: GP configuration\n",
    "        max_depth: Maximum depth of the tree\n",
    "        current_depth: Current depth of the node\n",
    "        \n",
    "    Returns:\n",
    "        Root node of the generated tree\n",
    "    \"\"\"\n",
    "    # If we are at the maximum depth, we can only create terminal nodes\n",
    "    if current_depth >= max_depth:\n",
    "        terminal_info = config.get_random_terminal()\n",
    "        if terminal_info['is_variable']:\n",
    "            return TerminalNode(None, is_variable=True, var_index=terminal_info['var_index'])\n",
    "        else:\n",
    "            return TerminalNode(terminal_info['value'], is_variable=False)\n",
    "    \n",
    "    # Otherwise, we create only function nodes\n",
    "    function_info = config.get_random_function()\n",
    "    children = [full_tree(config, max_depth, current_depth + 1) for _ in range(function_info['arity'])]\n",
    "    return FunctionNode(function_info['function'], function_info['arity'], function_info['symbol'], children)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3055,
   "id": "b52d2edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ramped_half_and_half(config: GPConfig, min_depth: int, max_depth: int) -> ExpressionTree:\n",
    "    \"\"\"\n",
    "    Ramped half-and-half' initialisation method\n",
    "    Combines grow and full for greater diversity\n",
    "    \n",
    "    Args:\n",
    "        config: GP configuration\n",
    "        min_depth: Minimum tree depth\n",
    "        max_depth: Maximum depth of trees\n",
    "        \n",
    "    Returns:\n",
    "        A new expression tree\n",
    "    \"\"\"\n",
    "    # Choose a random depth between min_depth and max_depth\n",
    "    depth = random.randint(min_depth, max_depth)\n",
    "    \n",
    "    # Choose randomly between ‘grow’ and ‘full’.\n",
    "    if random.random() < 0.5:\n",
    "        root = grow_tree(config, depth, min_depth)\n",
    "    else:\n",
    "        root = full_tree(config, depth)\n",
    "    \n",
    "    return ExpressionTree(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3056,
   "id": "52eb95a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_population(config: GPConfig) -> List[ExpressionTree]:\n",
    "    \"\"\"\n",
    "    Creates the initial population of expression trees\n",
    "    \n",
    "    Args:\n",
    "        config: GP configuration\n",
    "        \n",
    "    Returns:\n",
    "        List of expression trees\n",
    "    \"\"\"\n",
    "    population = []\n",
    "    unique_expressions = set()  # For tracking unique expressions\n",
    "    \n",
    "    print(f\"Population initialisation of  {config.pop_size} individuals...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Generate individuals until the population is full\n",
    "    while len(population) < config.pop_size:\n",
    "        tree = ramped_half_and_half(config, config.min_depth, config.max_depth)\n",
    "        \n",
    "        # Check if the expression is unique to contribute to inizial diversity\n",
    "        expr_str = tree.to_string()\n",
    "        if expr_str not in unique_expressions:\n",
    "            unique_expressions.add(expr_str)\n",
    "            population.append(tree)\n",
    "            \n",
    "            # We update the status every 100 individuals\n",
    "            if len(population) % 1000 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"  Generated  {len(population)} individuals in  {elapsed:.2f} seconds\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Population initialised in {elapsed:.2f} seconds\")\n",
    "    \n",
    "    # Initial population statistics\n",
    "    heights = [tree.get_height() for tree in population]\n",
    "    sizes = [tree.get_complexity() for tree in population]\n",
    "    print(f\"Initial population statistics:\")\n",
    "    print(f\"  - Average height: {np.mean(heights):.2f} (min: {min(heights)}, max: {max(heights)})\")\n",
    "    print(f\"  - Average size: {np.mean(sizes):.2f} nodes (min: {min(sizes)}, max: {max(sizes)})\")\n",
    "    \n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ea1ca6",
   "metadata": {},
   "source": [
    "### Fitness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3057,
   "id": "e30d6f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fitness(tree: ExpressionTree, X: np.ndarray, y: np.ndarray, \n",
    "                      parsimony_coef: float = 0.001) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the fitness of an individual\n",
    "    \n",
    "    Args:\n",
    "        tree: The expression tree to be evaluated\n",
    "        X: Input features\n",
    "        y: Output target\n",
    "        parsimony_coef: Penalty coefficient for the complexity of the tree\n",
    "        \n",
    "    Returns:\n",
    "        Fitness value (the lower the bett\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Evaluates the tree on input data        \n",
    "        predictions = tree.evaluate(X)        # In the case of NaN or infinite values, it assigns a very high (bad) fitness\n",
    "        if np.any(np.isnan(predictions)) or np.any(np.isinf(predictions)):\n",
    "            return float('inf')\n",
    "        \n",
    "        # Calculate the mean square error (MSE)\n",
    "        mse = np.mean((predictions - y) ** 2)\n",
    "        # add a small penalty to encourage more complex solutions\n",
    "        complexity = tree.get_complexity()\n",
    "        complexity_penalty = 0.0\n",
    "        if complexity < 1:\n",
    "            complexity_penalty = parsimony_coef * (complexity - 2)\n",
    "        \n",
    "        # The final fitness is MSE + penalty (lower is better)\n",
    "        fitness = mse + complexity_penalty\n",
    "        return fitness\n",
    "    \n",
    "    except Exception as e:\n",
    "        # In case of errors during the evaluation, it assigns a very high fitness\n",
    "        print(f\"Errore durante la valutazione: {e}\")\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3058,
   "id": "4d1cfbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_population(population: List[ExpressionTree], X: np.ndarray, y: np.ndarray, \n",
    "                       config: GPConfig) -> None:\n",
    "    \"\"\"\n",
    "    Evaluates all individuals in the population\n",
    "    \n",
    "    Args:\n",
    "        population: List of expression trees\n",
    "        X: Input features\n",
    "        y: Output target\n",
    "        config: GP configuration\n",
    "    \"\"\"\n",
    "    for i, tree in enumerate(population):\n",
    "        tree.fitness = calculate_fitness(tree, X, y, config.parsimony_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3059,
   "id": "d9698616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fitness_sharing(population: List[ExpressionTree], sigma: float = 0.1, \n",
    "                         use_sympy: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Apply fitness sharing to foster diversity in the population\n",
    "    \n",
    "    Args:\n",
    "    population: List of expression trees already evaluated\n",
    "    sigma: Radius of the sharing kernel\n",
    "    use_sympy: Whether to use sympy to simplify expressions\n",
    "    \n",
    "    \"\"\"\n",
    "    n = len(population)\n",
    "    \n",
    "    # Pre-calculates expression strings (with sympy if required)\n",
    "    expressions = []\n",
    "    for tree in population:\n",
    "        expr = tree.to_string()\n",
    "        if use_sympy:\n",
    "            try:\n",
    "                #print(\"Tree Complexity: \", tree.get_complexity())\n",
    "                expr = sympy_simplify_expression(expr)\n",
    "\n",
    "            except Exception as e:\n",
    "                # Fallback to basic simplification in the event of an error\n",
    "                expr = simplify_expression(expr)\n",
    "        else:\n",
    "            expr = simplify_expression(expr)\n",
    "        expressions.append(expr)\n",
    "    \n",
    "    # Calculate the sharing factors\n",
    "    for i in range(n):\n",
    "        sharing_factor = 1.0\n",
    "        \n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                # If the expressions are identical after simplification,\n",
    "                # the distance is 0 and the sharing factor is maximum\n",
    "                if expressions[i] == expressions[j]:\n",
    "                    sharing_factor += 1.0\n",
    "                else:\n",
    "                    # For different expressions, calculate a similarity measure\n",
    "                    expr_i = expressions[i]\n",
    "                    expr_j = expressions[j]\n",
    "                    \n",
    "                    # Jaccard similarity on terms\n",
    "                    terms_i = set(re.findall(r'[\\w\\.]+|\\[\\d+\\]', expr_i))\n",
    "                    terms_j = set(re.findall(r'[\\w\\.]+|\\[\\d+\\]', expr_j))\n",
    "                    if terms_i and terms_j:\n",
    "                        jaccard_terms = len(terms_i & terms_j) / len(terms_i | terms_j)\n",
    "                    else:\n",
    "                        jaccard_terms = 0\n",
    "                    \n",
    "                    # Structural similarity (based on operators)\n",
    "                    ops_i = set(re.findall(r'[\\+\\-\\*\\/\\^\\(\\)]|sin|cos|exp|log', expr_i))\n",
    "                    ops_j = set(re.findall(r'[\\+\\-\\*\\/\\^\\(\\)]|sin|cos|exp|log', expr_j))\n",
    "                    if ops_i and ops_j:\n",
    "                        structure_sim = len(ops_i & ops_j) / len(ops_i | ops_j)\n",
    "                    else:\n",
    "                        structure_sim = 0\n",
    "                    \n",
    "                    # Complexity similarity (based on the number of nodes)\n",
    "                    len_i = len(expr_i)\n",
    "                    len_j = len(expr_j)\n",
    "                    len_ratio = min(len_i, len_j) / max(len_i, len_j) if max(len_i, len_j) > 0 else 1\n",
    "                    \n",
    "                    # Combines the three similarity measures with weights\n",
    "                    similarity = (0.5 * jaccard_terms + 0.3 * structure_sim + 0.2 * len_ratio)\n",
    "                    \n",
    "                    # Apply the sharing formula only if similar enough\n",
    "                    if similarity > 1 - sigma:\n",
    "                        d = 1 - similarity\n",
    "                        sharing_factor += max(0, 1 - (d/sigma)**2)\n",
    "        \n",
    "        # Limits the sharing factor\n",
    "        sharing_factor = min(10.0, max(1.0, sharing_factor))\n",
    "        \n",
    "        # Adjust fitness\n",
    "        if population[i].fitness != float('inf'):\n",
    "            population[i].adjusted_fitness = population[i].fitness * sharing_factor\n",
    "        else:\n",
    "            population[i].adjusted_fitness = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3060,
   "id": "e1fde4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_semantic_distance(tree1: ExpressionTree, tree2: ExpressionTree, \n",
    "                               X_sample: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the semantic distance between two expression trees\n",
    "    based on the behaviour on a data sample\n",
    "    \n",
    "    Args:\n",
    "        tree1, tree2: Expression trees to compare\n",
    "        X_sample: Input data sample to test behaviour\n",
    "        \n",
    "    Returns:\n",
    "        Semantic distance (0 = identical behaviour)\n",
    "    \"\"\"\n",
    "    # We evaluate trees on the data sample\n",
    "    try:\n",
    "        output1 = tree1.evaluate(X_sample)\n",
    "        output2 = tree2.evaluate(X_sample)\n",
    "        \n",
    "        # Distance calculation (mean square error)\n",
    "        if np.any(np.isnan(output1)) or np.any(np.isinf(output1)) or \\\n",
    "           np.any(np.isnan(output2)) or np.any(np.isinf(output2)):\n",
    "            return float('inf')\n",
    "        \n",
    "        # Normalisation of outputs for fairer comparison\n",
    "        if np.std(output1) > 0 and np.std(output2) > 0:\n",
    "            output1 = (output1 - np.mean(output1)) / np.std(output1)\n",
    "            output2 = (output2 - np.mean(output2)) / np.std(output2)\n",
    "        \n",
    "        # Calculate distance\n",
    "        return np.mean((output1 - output2) ** 2)\n",
    "    \n",
    "    except Exception:\n",
    "        # In case of errors, we consider the trees far apart\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df07dec",
   "metadata": {},
   "source": [
    "### Selection Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3061,
   "id": "2b903d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_selection(population: List[ExpressionTree], tournament_size: int, \n",
    "                         use_adjusted_fitness: bool = False) -> ExpressionTree:\n",
    "    \"\"\"\n",
    "    Select an individual by tournament selection\n",
    "    \n",
    "    Args:\n",
    "        population: List of expression trees\n",
    "        tournament_size: Number of tournament participants\n",
    "        use_adjusted_fitness: Whether to use diversity-adjusted fitness\n",
    "        \n",
    "    Returns:\n",
    "        The selected individual\n",
    "    \"\"\"\n",
    "    # Randomly selects tournament_size individuals from the population\n",
    "    contestants = random.sample(population, min(tournament_size, len(population)))\n",
    "    \n",
    "    # Find the individual with the best (lowest) fitness\n",
    "    if use_adjusted_fitness:\n",
    "        # Use fitness adjusted for diversity, if available\n",
    "        best = min(contestants, key=lambda x: float('inf') if x.adjusted_fitness is None else x.adjusted_fitness)\n",
    "    else:\n",
    "        best = min(contestants, key=lambda x: float('inf') if x.fitness is None else x.fitness)\n",
    "    \n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3062,
   "id": "5fa8ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_weighted_selection(population: List[ExpressionTree], \n",
    "                          max_age: int = 10, \n",
    "                          young_advantage: float = 0.3) -> ExpressionTree:\n",
    "    \"\"\"\n",
    "    Selection favouring younger individuals (with less age)\n",
    "    \n",
    "    Args:\n",
    "        population: List of expression trees\n",
    "        max_age: Maximum age considered for advantage\n",
    "        young_advantage: Percentage advantage for young individuals\n",
    "        \n",
    "    Returns:\n",
    "        The selected individual\n",
    "    \"\"\"\n",
    "    # Calculates weights based on age\n",
    "    age_weights = [max(0.1, 1.0 - (tree.age / max_age) * young_advantage) \n",
    "                  for tree in population]\n",
    "    \n",
    "    # Normalise weights\n",
    "    total_weight = sum(age_weights)\n",
    "    if total_weight > 0:\n",
    "        norm_weights = [w / total_weight for w in age_weights]\n",
    "    else:\n",
    "        norm_weights = [1.0 / len(population)] * len(population)\n",
    "    \n",
    "    # Weighted selection\n",
    "    return random.choices(population, weights=norm_weights, k=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3063,
   "id": "3be03a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parents(population: List[ExpressionTree], config: GPConfig, \n",
    "                  X_sample: np.ndarray) -> Tuple[ExpressionTree, ExpressionTree]:\n",
    "    \"\"\"\n",
    "    Select two parents from the population\n",
    "    \n",
    "    Args:\n",
    "        population: List of expression trees\n",
    "        config: GP configuration\n",
    "        X_sample: Data sample to calculate semantic diversity\n",
    "        \n",
    "    Returns:\n",
    "        Parent pair\n",
    "    \"\"\"\n",
    "    # We randomly choose the selection method\n",
    "    selection_r = random.random()\n",
    "    \n",
    "    if selection_r < 0.9:  # 90% chance of using the standard tournament with adjusted fitness\n",
    "        parent1 = tournament_selection(population, config.tournament_size, use_adjusted_fitness=True)\n",
    "        parent2 = tournament_selection(population, config.tournament_size, use_adjusted_fitness=True)\n",
    "    else:  # 10% probability of using age-based selection\n",
    "        parent1 = age_weighted_selection(population)\n",
    "        parent2 = age_weighted_selection(population)\n",
    "    \n",
    "    # Make sure the parents are different\n",
    "    attempts = 0\n",
    "    while parent1 == parent2 and attempts < 5:\n",
    "        parent2 = tournament_selection(population, config.tournament_size)\n",
    "        attempts += 1\n",
    "    \n",
    "    return parent1, parent2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eda1b96",
   "metadata": {},
   "source": [
    "### Genetic Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3064,
   "id": "026db31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtree_crossover(parent1: ExpressionTree, parent2: ExpressionTree, \n",
    "                     max_tries: int = 5, max_depth: int = 10) -> Tuple[ExpressionTree, ExpressionTree]:\n",
    "    \"\"\"\n",
    "    Crossover for trees: exchanging subtrees between parents\n",
    "    \n",
    "    Args:\n",
    "        parent1, parent2: Parent trees\n",
    "        max_tries: Maximum number of attempts to find valid crossover points\n",
    "        max_depth: Maximum depth allowed for the resulting tree\n",
    "        \n",
    "    Returns:\n",
    "        Two child trees generated by the crossover\n",
    "    \"\"\"\n",
    "    # We create copies of parents\n",
    "    child1 = parent1.copy()\n",
    "    child2 = parent2.copy()\n",
    "    \n",
    "    # Get all nodes in trees\n",
    "    nodes1 = child1.get_nodes()\n",
    "    nodes2 = child2.get_nodes()\n",
    "    \n",
    "    if not nodes1 or not nodes2:\n",
    "        return child1, child2  # We cannot crossover if one of the trees is empty\n",
    "    \n",
    "    # Attempts crossover a limited number of times\n",
    "    for _ in range(max_tries):\n",
    "        # Randomly choose crossover points\n",
    "        crossover_point1 = random.randrange(len(nodes1))\n",
    "        crossover_point2 = random.randrange(len(nodes2))\n",
    "        \n",
    "        # Obtain the subtrees to be exchanged\n",
    "        subtree1 = nodes1[crossover_point1]\n",
    "        subtree2 = nodes2[crossover_point2]\n",
    "        \n",
    "        # Create copies of the subtrees to avoid modifying the originals\n",
    "        subtree1_copy = subtree1.copy()\n",
    "        subtree2_copy = subtree2.copy()\n",
    "        \n",
    "        # Replace the subtrees in the children\n",
    "        child1.replace_subtree_at_index(crossover_point1, subtree2_copy)\n",
    "        child2.replace_subtree_at_index(crossover_point2, subtree1_copy)\n",
    "        \n",
    "        # Update the depths of the nodes in the children\n",
    "        child1.update_node_depths()\n",
    "        child2.update_node_depths()\n",
    "        \n",
    "        # Check if the resulting trees are within the allowed depth\n",
    "        if child1.get_height() <= max_depth and child2.get_height() <= max_depth:\n",
    "            break\n",
    "        else:\n",
    "            # Restore children from parental copies\n",
    "            child1 = parent1.copy()\n",
    "            child2 = parent2.copy()\n",
    "            nodes1 = child1.get_nodes()\n",
    "            nodes2 = child2.get_nodes()\n",
    "    \n",
    "    # Increase age\n",
    "    child1.age = 0\n",
    "    child2.age = 0\n",
    "    \n",
    "    return child1, child2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3065,
   "id": "c2c818b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtree_mutation(tree: ExpressionTree, config: GPConfig, \n",
    "                    max_depth: int = 10) -> ExpressionTree:\n",
    "    \"\"\"\n",
    "    Subtree mutation: replaces a random subtree with a new one\n",
    "    \n",
    "    Args:\n",
    "        tree: Tree to be mutated\n",
    "        config: GP configuration\n",
    "        max_depth: Maximum depth allowed for the resulting tree\n",
    "        \n",
    "    Returns:\n",
    "        Shaft mutated\n",
    "    \"\"\"\n",
    "    # Create a copy of the tree\n",
    "    mutated = tree.copy()\n",
    "    \n",
    "    # Get all nodes in the tree\n",
    "    nodes = mutated.get_nodes()\n",
    "    \n",
    "    if not nodes:\n",
    "        return mutated  # We cannot mutate an empty tree\n",
    "    \n",
    "    # Randomly select a mutation point\n",
    "    mutation_point = random.randrange(len(nodes))\n",
    "    \n",
    "    # Calculate the maximum depth for the new subtree\n",
    "    node_depth = nodes[mutation_point].depth\n",
    "    remaining_depth = max_depth - node_depth\n",
    "    \n",
    "    if remaining_depth < 1:\n",
    "        return mutated  # We cannot change if there is no room to grow\n",
    "    \n",
    "    # Generates a new random subtree\n",
    "    new_subtree = grow_tree(config, remaining_depth, min_depth=1)\n",
    "    \n",
    "    # Replace the subtree\n",
    "    mutated.replace_subtree_at_index(mutation_point, new_subtree)\n",
    "    \n",
    "    # Updates node depths\n",
    "    mutated.update_node_depths()\n",
    "    \n",
    "    # Reset age\n",
    "    mutated.age = 0\n",
    "    \n",
    "    return mutated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3066,
   "id": "cdedbc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_mutation(tree: ExpressionTree, config: GPConfig) -> ExpressionTree:\n",
    "    \"\"\"\n",
    "    Point mutation: changes a single node while maintaining the tree structure\n",
    "    \n",
    "    Args:\n",
    "        tree: Tree to be mutated\n",
    "        config: GP configuration\n",
    "        \n",
    "    Returns:\n",
    "        Tree mutated\n",
    "    \"\"\"\n",
    "    # Create a copy of the tree\n",
    "    mutated = tree.copy()\n",
    "    \n",
    "    # Obtain all nodes in the tree\n",
    "    nodes = mutated.get_nodes()\n",
    "    \n",
    "    if not nodes:\n",
    "        return mutated  # We cannot mutate an empty tree\n",
    "    \n",
    "    # Randomly select a mutation point\n",
    "    mutation_point = random.randrange(len(nodes))\n",
    "    node = nodes[mutation_point]\n",
    "    \n",
    "    # Mutation based on node type\n",
    "    if isinstance(node, FunctionNode):\n",
    "        # Replace with another function of the same arity\n",
    "        compatible_functions = [f for f in config.function_set if f['arity'] == node.arity]\n",
    "        if compatible_functions:\n",
    "            function_info = random.choice(compatible_functions)\n",
    "            new_node = FunctionNode(function_info['function'], \n",
    "                                   function_info['arity'], \n",
    "                                   function_info['symbol'],\n",
    "                                   node.children.copy())  # reuses the same children\n",
    "            \n",
    "            # Replace the node\n",
    "            mutated.replace_subtree_at_index(mutation_point, new_node)\n",
    "    \n",
    "    elif isinstance(node, TerminalNode):\n",
    "        if node.is_variable:\n",
    "            # Replace with another variable\n",
    "            if len(config.variable_terminals) > 1:\n",
    "                terminal_info = config.get_random_variable()\n",
    "                while terminal_info['var_index'] == node.var_index:\n",
    "                    terminal_info = config.get_random_variable()\n",
    "                \n",
    "                new_node = TerminalNode(None, True, terminal_info['var_index'])\n",
    "                mutated.replace_subtree_at_index(mutation_point, new_node)\n",
    "        else:\n",
    "            # We could replace it with another constant or slightly modify the valu\n",
    "            if random.random() < 0.5:  # 50% probability of changing the value\n",
    "                # Change existing value (small perturbation)\n",
    "                new_value = node.value * (1.0 + random.uniform(-0.1, 0.1))\n",
    "                new_node = TerminalNode(new_value, False)\n",
    "                #Avoid zero values\n",
    "                if abs(new_value) < 1e-8:\n",
    "                    new_value = 1e-8 if new_value >= 0 else -1e-8\n",
    "            else:\n",
    "                # Replace with a new constant\n",
    "                terminal_info = config.get_random_constant()\n",
    "                new_node = TerminalNode(terminal_info['value'], False)\n",
    "            \n",
    "            mutated.replace_subtree_at_index(mutation_point, new_node)\n",
    "    \n",
    "    # Updates node depths\n",
    "    mutated.update_node_depths()\n",
    "    \n",
    "    # Reset age\n",
    "    mutated.age = 0\n",
    "    \n",
    "    return mutated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3067,
   "id": "6ec9a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deterministic_crowding(parent1: ExpressionTree, parent2: ExpressionTree,\n",
    "                          child1: ExpressionTree, child2: ExpressionTree,\n",
    "                          X: np.ndarray, y: np.ndarray, config: GPConfig) -> List[ExpressionTree]:\n",
    "    \"\"\"\n",
    "    Deterministic crowding: children replace parents only if they have better fitness\n",
    "    \n",
    "    Args:\n",
    "        parent1, parent2: Parents\n",
    "        child1, child2: Children generated by parents\n",
    "        X, y: Data for evaluation\n",
    "        config: GP configuration\n",
    "        \n",
    "    Returns:\n",
    "        List of selected individuals\n",
    "    \"\"\"\n",
    "    # Calculate children's fitness\n",
    "    child1.fitness = calculate_fitness(child1, X, y, config.parsimony_coef)\n",
    "    child2.fitness = calculate_fitness(child2, X, y, config.parsimony_coef)\n",
    "    \n",
    "    # Apply fitness sharing to parents and children\n",
    "    # We can create a small temporary population with children to calculate their adjusted_fitness\n",
    "    temp_pop = [parent1, parent2, child1, child2]\n",
    "    apply_fitness_sharing(temp_pop)\n",
    "\n",
    "    # Calculates similarities between parents and children\n",
    "    X_sample = X[:min(len(X), 100)]  # Use a sample for efficiency\n",
    "    \n",
    "    dist_p1c1 = calculate_semantic_distance(parent1, child1, X_sample)\n",
    "    dist_p1c2 = calculate_semantic_distance(parent1, child2, X_sample)\n",
    "    \n",
    "    # Decide which parent-child pairings to compare\n",
    "    if dist_p1c1 <= dist_p1c2:\n",
    "        # parent1 vs child1, parent2 vs child2\n",
    "        competition1 = (parent1, child1)\n",
    "        competition2 = (parent2, child2)\n",
    "    else:\n",
    "        # parent1 vs child2, parent2 vs child1\n",
    "        competition1 = (parent1, child2)\n",
    "        competition2 = (parent2, child1)\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    # First competition\n",
    "    if competition1[1].adjusted_fitness <= competition1[0].adjusted_fitness:\n",
    "        result.append(competition1[1])  # the child wins\n",
    "    else:\n",
    "        result.append(competition1[0])  # the parent wins\n",
    "    \n",
    "    # Second competition\n",
    "    if competition2[1].adjusted_fitness <= competition2[0].adjusted_fitness:\n",
    "        result.append(competition2[1])  # The child wins\n",
    "    else:\n",
    "        result.append(competition2[0])  # The parent wins\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54d457",
   "metadata": {},
   "source": [
    "###  Genetic Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3068,
   "id": "16152735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_genetic_operators(population: List[ExpressionTree], X: np.ndarray, y: np.ndarray, \n",
    "                           config: GPConfig) -> List[ExpressionTree]:\n",
    "    \"\"\"\n",
    "    Apply genetic operators to create a new population\n",
    "    \n",
    "    Args:\n",
    "        population: List of expression trees\n",
    "        X, y: Evaluation data\n",
    "        config: GP configuration\n",
    "        \n",
    "    Returns:\n",
    "        New population\n",
    "    \"\"\"\n",
    "    # Sort population by fitness (best first)\n",
    "    sorted_population = sorted(population, key=lambda x: float('inf') if x.adjusted_fitness is None else x.adjusted_fitness)\n",
    "    \n",
    "    # Number of individuals to be selected by elitism\n",
    "    n_elite = int(config.pop_size * config.elitism_rate)\n",
    "    \n",
    "    # Sample to calculate semantic diversity\n",
    "    X_sample = X[:min(len(X), 100)]  # Use a sample for efficiency\n",
    "    \n",
    "    # Select elites\n",
    "    new_population = [tree.copy() for tree in sorted_population[:n_elite]]\n",
    "    \n",
    "    # Increase the age of each elite individual\n",
    "    for tree in new_population:\n",
    "        tree.age += 1\n",
    "    \n",
    "    # Complete the population with new individual\n",
    "    while len(new_population) < config.pop_size:\n",
    "        # Select genetic operation (crossover or mutation)\n",
    "        op_choice = random.random()\n",
    "        \n",
    "        if op_choice < config.crossover_prob:\n",
    "            # Crossover\n",
    "            parent1, parent2 = select_parents(population, config, X_sample)\n",
    "            child1, child2 = subtree_crossover(parent1, parent2, max_depth=config.max_depth)\n",
    "            \n",
    "            # Use deterministic crowding to decide which individuals to keep\n",
    "            selected = deterministic_crowding(parent1, parent2, child1, child2, X, y, config)\n",
    "            \n",
    "            # Add to new population\n",
    "            new_population.extend(selected)\n",
    "            if len(new_population) > config.pop_size:\n",
    "                new_population = new_population[:config.pop_size]\n",
    "        \n",
    "        elif op_choice < config.crossover_prob + config.mutation_prob:\n",
    "            # Mutation\n",
    "            parent = tournament_selection(population, config.tournament_size)\n",
    "            \n",
    "            # Rnandomly choose between subtree mutation and point mutation\n",
    "            mutation_choice = random.random()\n",
    "            \n",
    "            if mutation_choice < 0.7:  # 70% subtree mutation\n",
    "                child = subtree_mutation(parent, config, max_depth=config.max_depth)\n",
    "            else:  # 30% point mutation\n",
    "                child = point_mutation(parent, config)\n",
    "            \n",
    "            # Calculate fitness of the child\n",
    "            child.fitness = calculate_fitness(child, X, y, config.parsimony_coef)\n",
    "            temp_pop = [parent, child]\n",
    "            apply_fitness_sharing(temp_pop)\n",
    "            # Compare parent and child\n",
    "            if child.adjusted_fitness <= parent.adjusted_fitness:\n",
    "                new_population.append(child)\n",
    "            else:\n",
    "                # Still add the son with some probability\n",
    "                if random.random() < 0.1:  # 10% probability\n",
    "                    new_population.append(child)\n",
    "                else:\n",
    "                    new_population.append(parent.copy())\n",
    "        \n",
    "        else:\n",
    "            # Playback (direct copy)\n",
    "            parent = tournament_selection(population, config.tournament_size)\n",
    "            offspring = parent.copy()\n",
    "            offspring.age += 1  # Increase age\n",
    "            new_population.append(offspring)\n",
    "    \n",
    "    # Make sure the population is exactly the right size\n",
    "    if len(new_population) > config.pop_size:\n",
    "        new_population = new_population[:config.pop_size]\n",
    "    \n",
    "    # Fitness adjusted for diversity\n",
    "    apply_fitness_sharing(new_population)\n",
    "    \n",
    "    return new_population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4358633",
   "metadata": {},
   "source": [
    "### Diversity Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3069,
   "id": "505d6125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Island:\n",
    "    \"\"\"Representing an island in the Island Model\"\"\"\n",
    "    \n",
    "    def __init__(self, population: List[ExpressionTree], config: GPConfig, island_id: int):\n",
    "        self.population = population\n",
    "        self.config = config\n",
    "        self.id = island_id\n",
    "        self.best_individual = None\n",
    "        self.best_fitness = float('inf')\n",
    "        self.generations_without_improvement = 0\n",
    "    \n",
    "    def evolve(self, X: np.ndarray, y: np.ndarray, generation: int) -> None:\n",
    "        \"\"\"\n",
    "        Evolving the island for a generation\n",
    "        \n",
    "        Args:\n",
    "            X, y: Training data\n",
    "            generation: Number of the current generatione\n",
    "        \"\"\"\n",
    "        # Apply genetic operators\n",
    "        self.population = apply_genetic_operators(self.population, X, y, self.config)\n",
    "        \n",
    "        # Update the best solution\n",
    "        current_best = min(self.population, key=lambda x: float('inf') if x.adjusted_fitness is None else x.adjusted_fitness)\n",
    "        if current_best.adjusted_fitness < self.best_fitness:\n",
    "            self.best_individual = current_best.copy()\n",
    "            self.best_fitness = current_best.adjusted_fitness\n",
    "            self.generations_without_improvement = 0\n",
    "        else:\n",
    "            self.generations_without_improvement += 1\n",
    "        \n",
    "        # Progress log\n",
    "        if generation % 100 == 0:  # Every 100 generations\n",
    "            print(f\"Island {self.id} | Generation {generation} | Best Fitness: {self.best_fitness}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3070,
   "id": "dcd731c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_islands(total_population: List[ExpressionTree], config: GPConfig, n_islands: int = 3) -> List[Island]:\n",
    "    \"\"\"\n",
    "    Initialise islands by dividing the population\n",
    "    \n",
    "    Args:\n",
    "        total_population: Full list of expression trees\n",
    "        config: GP configuration\n",
    "        n_islands: Number of islands to create\n",
    "        \n",
    "    Returns:\n",
    "        List of Island objects\n",
    "    \"\"\"\n",
    "    islands = []\n",
    "    # Randomly mixing the population\n",
    "    shuffled_population = random.sample(total_population, len(total_population))\n",
    "    \n",
    "    # Calculate the size of each island\n",
    "    island_size = len(shuffled_population ) // n_islands\n",
    "    \n",
    "    # Distribute the population among the islands\n",
    "    for i in range(n_islands):\n",
    "        start_idx = i * island_size\n",
    "        end_idx = start_idx + island_size if i < n_islands - 1 else len(shuffled_population)\n",
    "        island_population = shuffled_population[start_idx:end_idx]\n",
    "        \n",
    "        # Create island-specific configuration\n",
    "        island_config = copy.deepcopy(config)\n",
    "        island_config.pop_size = len(island_population)\n",
    "        \n",
    "        # Create isaland\n",
    "        island = Island(island_population, island_config, i)\n",
    "        islands.append(island)\n",
    "    \n",
    "    return islands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3071,
   "id": "8d31ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def migration(islands: List[Island], migration_rate: float = 0.2, mutate_migrants: bool = True, mutation_strength: float = 1.5) -> None:\n",
    "    \"\"\"\n",
    "    Allows migration of individuals between islands, with the possibility of mutating migrants\n",
    "    \n",
    "    Args:\n",
    "        islands: List of Island objects\n",
    "        migration_rate: Percentage of population migrating\n",
    "        mutate_migrants: Whether to apply mutation to migrants\n",
    "        mutation_strength: Factor amplifying the mutation probability\n",
    "    \"\"\"\n",
    "    if len(islands) <= 1:\n",
    "        return\n",
    "    \n",
    "    print(\"Performing inter-island migration...\")\n",
    "    \n",
    "    for i, source_island in enumerate(islands):\n",
    "        # Calculates the destination island (the next, or the first if it is the last)\n",
    "        dest_idx = (i + 1) % len(islands)\n",
    "        dest_island = islands[dest_idx]\n",
    "        \n",
    "        # Number of individuals to migrate\n",
    "        n_migrants = max(1, int(source_island.config.pop_size * migration_rate))\n",
    "        \n",
    "        # Select migrants (half best, half random)\n",
    "        n_best = n_migrants // 2\n",
    "        n_random = n_migrants - n_best\n",
    "        \n",
    "        # Sort by fitness\n",
    "        sorted_pop = sorted(source_island.population, \n",
    "                          key=lambda x: float('inf') if x.adjusted_fitness is None else x.adjusted_fitness)\n",
    "        \n",
    "        # Get the best\n",
    "        migrants_best = [ind.copy() for ind in sorted_pop[:n_best]]\n",
    "        \n",
    "        # Take some random\n",
    "        migrants_random = [ind.copy() for ind in random.sample(source_island.population, n_random)]\n",
    "        \n",
    "        migrants = migrants_best + migrants_random\n",
    "        # Mutation of migrants if requested\n",
    "        if mutate_migrants:\n",
    "            for j, migrant in enumerate(migrants):\n",
    "                # Apply mutation with increased probability\n",
    "                if random.random() < source_island.config.mutation_prob * mutation_strength:\n",
    "                    # Randomly choose the mutation type\n",
    "                    mutation_choice = random.random()\n",
    "                    \n",
    "                    if mutation_choice < 0.7:  # 70% subtree mutation\n",
    "                        migrants[j] = subtree_mutation(migrant, source_island.config, \n",
    "                                                     max_depth=source_island.config.max_depth)\n",
    "                    else:  # 30% point mutation\n",
    "                        migrants[j] = point_mutation(migrant, source_island.config)\n",
    "        \n",
    "        # Replace the worst in the destination island\n",
    "        dest_sorted = sorted(dest_island.population, \n",
    "                           key=lambda x: float('inf') if x.adjusted_fitness is None else x.adjusted_fitness, \n",
    "                           reverse=True)  # decrescent order\n",
    "        \n",
    "        # Remove the worst individuals from the destination island\n",
    "        for j in range(min(n_migrants, len(dest_sorted))):\n",
    "            dest_island.population.remove(dest_sorted[j])\n",
    "        \n",
    "        # Add the migrants to the destination island\n",
    "        dest_island.population.extend(migrants)\n",
    "        \n",
    "        print(f\"  Migration: {n_migrants} individuals from island {i} to island {dest_idx}\" + \n",
    "              (\", with mutation\" if mutate_migrants else \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c8be6f",
   "metadata": {},
   "source": [
    "### Bloat Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3072,
   "id": "18881137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bloat_control(population: List[ExpressionTree], config: GPConfig) -> None:\n",
    "    \"\"\"\n",
    "    Applies various bloat control techniques\n",
    "    \n",
    "    Args:\n",
    "        population: List of expression trees\n",
    "        config: GP configuration\n",
    "    \"\"\"\n",
    "    # Check for oversized individuals\n",
    "    oversized = [i for i, tree in enumerate(population) if tree.get_complexity() > config.max_tree_size]\n",
    "    \n",
    "    if oversized:\n",
    "        print(f\"Bloat control: {len(oversized)} individuals exceed the maximum size\")\n",
    "        \n",
    "        for idx in oversized:\n",
    "            # Attempt to reduce size by replacing sub-shafts with terminals\n",
    "            tree = population[idx]\n",
    "            nodes = tree.get_nodes()\n",
    "            \n",
    "            # Find non-terminal knots at greater depths\n",
    "            non_terminal_nodes = [i for i, node in enumerate(nodes) \n",
    "                                if isinstance(node, FunctionNode) and node.depth > 2]\n",
    "            \n",
    "            if non_terminal_nodes:\n",
    "                # Replace a random node with a terminal\n",
    "                node_idx = random.choice(non_terminal_nodes)\n",
    "                \n",
    "                # Create a new terminal node\n",
    "                terminal_info = config.get_random_terminal()\n",
    "                if terminal_info['is_variable']:\n",
    "                    new_node = TerminalNode(None, True, terminal_info['var_index'])\n",
    "                else:\n",
    "                    new_node = TerminalNode(terminal_info['value'], False)\n",
    "                \n",
    "                # Replace the subtree\n",
    "                tree.replace_subtree_at_index(node_idx, new_node)\n",
    "                tree.update_node_depths()\n",
    "    \n",
    "    # Apply lexicographic parsimony pressure\n",
    "    # When two individuals have similar fitness, prefer the simpler one\n",
    "    epsilon = 0.0000001  # threshold for considering similar fitness\n",
    "    \n",
    "    for i in range(len(population)):\n",
    "        for j in range(i + 1, len(population)):\n",
    "            tree_i = population[i]\n",
    "            tree_j = population[j]\n",
    "            \n",
    "            # If the fitnesses are similar\n",
    "            if abs(tree_i.adjusted_fitness - tree_j.adjusted_fitness) < epsilon:\n",
    "                # Get complexity\n",
    "                complexity_i = tree_i.get_complexity()\n",
    "                complexity_j = tree_j.get_complexity()\n",
    "                \n",
    "                # If tree j is significantly more complex, penalise it\n",
    "                if complexity_j > complexity_i * 1.5:\n",
    "                    # Add a small fitness penalty\n",
    "                    tree_j.adjusted_fitness += epsilon\n",
    "                \n",
    "                # If tree i is significantly more complex, penalise it\n",
    "                elif complexity_i > complexity_j * 1.5:\n",
    "                    # Add a small fitness penalty\n",
    "                    tree_i.adjusted_fitness += epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2556436",
   "metadata": {},
   "source": [
    "### Simplify Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3073,
   "id": "c1ed3652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_expression(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Simplifies a mathematical expression using basic algebraic rules.\n",
    "    \n",
    "    Args:\n",
    "        expression: Expression as string\n",
    "        \n",
    "    Returns:\n",
    "        Simplified expression\n",
    "    \"\"\"\n",
    "    # For complete simplification you would need a library like sympy\n",
    "    # This is an improved version that implements more simplification rules\n",
    "    \n",
    "    # Initial cleaning: removes excess spaces\n",
    "    expression = expression.strip()\n",
    "    \n",
    "    # Liste di pattern di semplificazione in ordine di applicazione\n",
    "    simplification_rules = [\n",
    "        # Operations with 0\n",
    "        (r'\\(\\s*0\\.0+\\s*\\+\\s*(.*?)\\s*\\)', r'(\\1)'),  # (0.0 + x) -> (x)\n",
    "        (r'\\(\\s*(.*?)\\s*\\+\\s*0\\.0+\\s*\\)', r'(\\1)'),  # (x + 0.0) -> (x)\n",
    "        (r'\\(\\s*0\\.0+\\s*\\-\\s*(.*?)\\s*\\)', r'(0.0 - \\1)'),  # (0.0 - x) -> (0.0 - x) [keep]\n",
    "        (r'\\(\\s*(.*?)\\s*\\-\\s*0\\.0+\\s*\\)', r'(\\1)'),  # (x - 0.0) -> (x)\n",
    "        (r'\\(\\s*(.*?)\\s*\\*\\s*0\\.0+\\s*\\)', r'0.0000'),  # (x * 0.0) -> 0.0\n",
    "        (r'\\(\\s*0\\.0+\\s*\\*\\s*(.*?)\\s*\\)', r'0.0000'),  # (0.0 * x) -> 0.0\n",
    "        (r'\\(\\s*0\\.0+\\s*\\/\\s*(.*?)\\s*\\)', r'0.0000'),  # (0.0 / x) -> 0.0\n",
    "        (r'\\(\\s*(.*?)\\s*\\/\\s*0\\.0+\\s*\\)', r'inf'),  # (x / 0.0) -> inf [capture division by zero]\n",
    "        \n",
    "        # Operations with 1\n",
    "        (r'\\(\\s*(.*?)\\s*\\*\\s*1\\.0+\\s*\\)', r'(\\1)'),  # (x * 1.0) -> (x)\n",
    "        (r'\\(\\s*1\\.0+\\s*\\*\\s*(.*?)\\s*\\)', r'(\\1)'),  # (1.0 * x) -> (x)\n",
    "        (r'\\(\\s*(.*?)\\s*\\/\\s*1\\.0+\\s*\\)', r'(\\1)'),  # (x / 1.0) -> (x)\n",
    "        (r'\\(\\s*1\\.0+\\s*\\/\\s*(.*?)\\s*\\)', r'(1.0 / \\1)'),  # (1.0 / x) keep\n",
    "        \n",
    "        # Operations with himself\n",
    "        (r'\\(\\s*(.*?)\\s*\\-\\s*\\1\\s*\\)', r'0.0000'),  # (x - x) -> 0.0\n",
    "        (r'\\(\\s*(.*?)\\s*\\/\\s*\\1\\s*\\)', r'1.0000'),  # (x / x) -> 1.0 [dangerous for x=0, but we handle it in safe_div]\n",
    "        \n",
    "        # Functional simplifications\n",
    "        (r'sin\\(\\s*0\\.0+\\s*\\)', r'0.0000'),  # sin(0.0) -> 0.0\n",
    "        (r'cos\\(\\s*0\\.0+\\s*\\)', r'1.0000'),  # cos(0.0) -> 1.0\n",
    "        (r'exp\\(\\s*0\\.0+\\s*\\)', r'1.0000'),  # exp(0.0) -> 1.0\n",
    "        (r'log\\(\\s*1\\.0+\\s*\\)', r'0.0000'),  # log(1.0) -> 0.0\n",
    "        \n",
    "        # Nested operations\n",
    "        (r'\\(\\(\\s*(.*?)\\s*\\)\\)', r'(\\1)'),  # ((x)) -> (x) Remove double parentheses\n",
    "        \n",
    "        # More specific nested operations\n",
    "        (r'\\(\\(([^()]*)\\)\\s*\\+\\s*\\(([^()]*)\\)\\)', r'((\\1) + (\\2))'),  # ((a) + (b)) -> (a + b)\n",
    "        (r'\\(\\(([^()]*)\\)\\s*\\-\\s*\\(([^()]*)\\)\\)', r'((\\1) - (\\2))'),  # ((a) - (b)) -> (a - b)\n",
    "        \n",
    "        # Other algebraic simplifications\n",
    "        (r'\\(\\s*(.*?)\\s*\\+\\s*\\(\\s*\\-\\s*(.*?)\\s*\\)\\s*\\)', r'(\\1 - \\2)'),  # (a + (-b)) -> (a - b)\n",
    "        (r'\\(\\s*(.*?)\\s*\\-\\s*\\(\\s*\\-\\s*(.*?)\\s*\\)\\s*\\)', r'(\\1 + \\2)'),  # (a - (-b)) -> (a + b)\n",
    "    ]\n",
    "    \n",
    "    # Final cleaning pattern (to be applied at the end)\n",
    "    cleanup_rules = [\n",
    "        # Removes outer brackets if possible\n",
    "        (r'^\\((.*)\\)$', r'\\1'),  # (x) -> x for the entire expression\n",
    "        \n",
    "        # Number Formatting\n",
    "        (r'0\\.0+', r'0.0'),  # 0.0000 -> 0.0\n",
    "        (r'1\\.0+', r'1.0'),  # 1.0000 -> 1.0\n",
    "        \n",
    "        # Removal of unnecessary brackets\n",
    "        (r'\\(\\s*x\\[(\\d+)\\]\\s*\\)', r'x[\\1]'),  # (x[0]) -> x[0]\n",
    "    ]\n",
    "    \n",
    "    # Applies simplification rules repeatedly\n",
    "    prev_expr = \"\"\n",
    "    while prev_expr != expression:\n",
    "        prev_expr = expression\n",
    "        for pattern, replacement in simplification_rules:\n",
    "            expression = re.sub(pattern, replacement, expression)\n",
    "    \n",
    "    # Applies final cleaning rules\n",
    "    for pattern, replacement in cleanup_rules:\n",
    "        expression = re.sub(pattern, replacement, expression)\n",
    "    \n",
    "    return expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3074,
   "id": "36fca2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sympy_simplify_expression(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Simplifies an expression using the sympy library for symbolic calculation.\n",
    "    \n",
    "    Args:\n",
    "        expression: Expression as string\n",
    "        \n",
    "    Returns:\n",
    "        Simplified expression\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #print(f\"Expression: {expression}\")\n",
    "        # Prepare the expression for sympy (replacing x[0] with x_0, etc.).\n",
    "        prepared_expr = re.sub(r'x\\[(\\d+)\\]', r'x_\\1', expression)\n",
    "        \n",
    "        #print(f\"Prepared expression: {prepared_expr}\")\n",
    "        # Define Symbols\n",
    "        symbol_names = set(re.findall(r'x_(\\d+)', prepared_expr))\n",
    "        symbols = {f'x_{i}': sp.Symbol(f'x_{i}', real=True) for i in symbol_names}  # Forza i simboli ad essere reali\n",
    "        \n",
    "        # Analyses and simplifies the expression\n",
    "        parsed_expr = parse_expr(prepared_expr, local_dict=symbols)\n",
    "        simplified = sp.expand(parsed_expr) #or expand \n",
    "        \n",
    "        # Checks whether the expression contains complex numbers or special symbols such as zoo\n",
    "        if \"zoo\" in str(simplified) or \"I\" in str(simplified) or \"oo\" in str(simplified):\n",
    "            # Fallback to basic simplification if we obtain problematic results\n",
    "            return simplify_expression(expression)\n",
    "        #print(f\"Sympy simplification: {simplified}\")\n",
    "        # Convert back to original format\n",
    "        result = str(simplified)\n",
    "        result = re.sub(r'x_(\\d+)', r'x[\\1]', result)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        # Fallback to basic simplification if sympy is not available or there is an error\n",
    "        print(f\"Invalid expression for sympy: {expression}\")\n",
    "        print(f\"Preapred expression: {prepared_expr}\")\n",
    "        print(f\"Error in simplification sympy: {str(e)}\")\n",
    "        return simplify_expression(expression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63257b48",
   "metadata": {},
   "source": [
    "### Princial Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3075,
   "id": "61327cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_programming(X: np.ndarray, y: np.ndarray, config: GPConfig, \n",
    "                       # Parameters for the island model\n",
    "                       use_islands: bool = False,\n",
    "                       n_islands: int = 5, \n",
    "                       migration_interval: int = 10,\n",
    "                       migration_rate: float = 0.1,\n",
    "                       \n",
    "                       # Parameters for bloat control\n",
    "                       bloat_control_interval: int = 5,\n",
    "                       \n",
    "                       # Other parameters\n",
    "                       early_stopping_generations: int = 20) -> ExpressionTree:\n",
    "    \"\"\"\n",
    "    Main Genetic Programming Algorithm for Symbolic Regression\n",
    "    \n",
    "    Args:\n",
    "        X: Input features\n",
    "        y: Output target\n",
    "        config: GP configuration\n",
    "        \n",
    "        # Parameters for the island model\n",
    "        use_islands: Whether to use the island model\n",
    "        n_islands: Number of islands (if use_islands is True)\n",
    "        migration_interval: Interval of generations between migrations\n",
    "        migration_rate: Percentage of population migrating\n",
    "        \n",
    "        # Parameters for bloat control\n",
    "        bloat_control_interval: Interval of generations for bloat control\n",
    "        \n",
    "        # Other parameters\n",
    "        early_stopping_generations: Number of generations without improvement before stopping\n",
    "        \n",
    "    Returns:\n",
    "        Best expression tree found\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"Starting Genetic Programming for Symbolic Regression...\")\n",
    "    print(f\"Configuration: pop_size={config.pop_size}, max_depth={config.max_depth}, \"\n",
    "          f\"generations={config.generations}\")\n",
    "    if use_islands:\n",
    "        print(f\"Island model: {n_islands} islands, migration every {migration_interval} generations\")\n",
    "        config.print_function_weights()\n",
    "    \n",
    "    # Initialise the population\n",
    "    initial_population = initialize_population(config)\n",
    "    \n",
    "    # Assess the initial population\n",
    "    evaluate_population(initial_population, X, y, config)\n",
    "    \n",
    "    # Apply fitness sharing for diversity\n",
    "    apply_fitness_sharing(initial_population) \n",
    "    \n",
    "    # Initialise islands or single population\n",
    "    if use_islands:\n",
    "        islands = initialize_islands(initial_population, config, n_islands)\n",
    "        best_individual = min([island.best_individual for island in islands if island.best_individual], \n",
    "                            key=lambda x: x.adjusted_fitness, default=None)\n",
    "        best_fitness = float('inf') if best_individual is None else best_individual.adjusted_fitness\n",
    "    else:\n",
    "        population = initial_population\n",
    "        best_individual = min(population, key=lambda x: float('inf') if x.adjusted_fitness is None else x.adjusted_fitness)\n",
    "        best_fitness = best_individual.adjusted_fitness\n",
    "    \n",
    "    # Statistics for monitoring\n",
    "    stats = {\n",
    "        'best_fitness': [],\n",
    "        'avg_fitness': [],\n",
    "        'avg_size': [],\n",
    "        'best_size': [],\n",
    "        'diversity': []\n",
    "    }\n",
    "    \n",
    "    # Principal loop of the algorithm\n",
    "    generations_without_improvement = 0\n",
    "    for generation in tqdm(range(config.generations)):\n",
    "        generation_start = time.time()\n",
    "        diversity = 0  \n",
    "        \n",
    "        if use_islands:\n",
    "            # Evolve each island separately\n",
    "            for island in islands:\n",
    "                island.evolve(X, y, generation)\n",
    "            \n",
    "            # Collect all individuals for statistics and migration\n",
    "            all_individuals = []\n",
    "            for island in islands:\n",
    "                all_individuals.extend(island.population)\n",
    "            \n",
    "            # Calculates diversity (number of unique expressions) once\n",
    "            all_expressions = [hash(sympy_simplify_expression(tree.to_string())) for tree in all_individuals]\n",
    "            unique_expressions = set(all_expressions)\n",
    "            diversity = len(unique_expressions) / len(all_individuals)\n",
    "            \n",
    "            # Periodic migration\n",
    "            if (generation + 1) % migration_interval == 0:\n",
    "                # If diversity is low, it activates migrant mutation\n",
    "                if diversity < 0.2:  # Arbitrary threshold to be adjusted\n",
    "                    migration(islands, migration_rate=migration_rate, mutate_migrants=True, \n",
    "                             mutation_strength=1.5)\n",
    "                else:\n",
    "                    migration(islands, migration_rate=migration_rate, mutate_migrants=False)\n",
    "            \n",
    "            # Calculate the best overall individual\n",
    "            current_best = min([island.best_individual for island in islands if island.best_individual], \n",
    "                             key=lambda x: x.adjusted_fitness)\n",
    "            \n",
    "            #  Periodic bloat control\n",
    "            if generation % bloat_control_interval == 0:\n",
    "                for island in islands:\n",
    "                    apply_bloat_control(island.population, config)\n",
    "\n",
    "            # Calculate other statistics\n",
    "            avg_fitness = np.mean([tree.adjusted_fitness for tree in all_individuals if tree.adjusted_fitness != float('inf')])\n",
    "            avg_size = np.mean([tree.get_complexity() for tree in all_individuals])\n",
    "            \n",
    "        else:\n",
    "            # Apply genetic operators\n",
    "            population = apply_genetic_operators(population, X, y, config)\n",
    "                        \n",
    "            # Periodic bloat control\n",
    "            if generation % bloat_control_interval == 0:\n",
    "                apply_bloat_control(population, config)\n",
    "            \n",
    "            # Calculate the best individual\n",
    "            current_best = min(population, key=lambda x: float('inf') if x.adjusted_fitness is None else x.adjusted_fitness)\n",
    "            \n",
    "            # Calculate statistics\n",
    "            avg_fitness = np.mean([tree.adjusted_fitness for tree in population if tree.adjusted_fitness != float('inf')])\n",
    "            avg_size = np.mean([tree.get_complexity() for tree in population])\n",
    "            \n",
    "            # Calculate diversity (number of unique expressions)\n",
    "            expressions = [hash(sympy_simplify_expression(tree.to_string())) for tree in population]\n",
    "            unique_expressions = set(expressions)\n",
    "            diversity = len(unique_expressions) / len(population)\n",
    "        \n",
    "        # Upgrade the best global individual\n",
    "        if current_best.adjusted_fitness < best_fitness:\n",
    "            best_individual = current_best.copy()\n",
    "            best_fitness = current_best.adjusted_fitness\n",
    "            generations_without_improvement = 0\n",
    "            print(f\"New best solution found:\")\n",
    "            print(f\"  Expression: {best_individual.to_string()}\")\n",
    "            print(f\"  Simplified Expression: {sympy_simplify_expression(best_individual.to_string())}\")\n",
    "            print(f\"  Fitness: {best_fitness}\")\n",
    "            print(f\"  Complexity: {best_individual.get_complexity()} nodes\")\n",
    "        else:\n",
    "            generations_without_improvement += 1\n",
    "        \n",
    "        # Store statistics\n",
    "        stats['best_fitness'].append(best_fitness)\n",
    "        stats['avg_fitness'].append(avg_fitness)\n",
    "        stats['avg_size'].append(avg_size)\n",
    "        stats['best_size'].append(best_individual.get_complexity())\n",
    "        stats['diversity'].append(diversity)\n",
    "        \n",
    "        # Generation log\n",
    "        generation_time = time.time() - generation_start\n",
    "        if generation % 5 == 0 or generation == config.generations - 1:\n",
    "           print(f\"Generazione {generation}, Best Fitness: {best_fitness}, Diversità: {diversity:.2f}, Tempo: {generation_time:.2f}s\")\n",
    "        \n",
    "        # Early Termination Criterion\n",
    "        if generations_without_improvement >= early_stopping_generations:\n",
    "            print(f\"Terminazione anticipata: nessun miglioramento nelle ultime {early_stopping_generations} generazioni\")\n",
    "            break\n",
    "        #!!todo: si potrebbe pensare di ristaratare il tutto con una nuova popolazione ma con pesi sulle funzionie variabili e coistanti diverse\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Algorithm completed in {total_time:.2f} seconds\")\n",
    "    print(f\"Best solution found:\")\n",
    "    print(f\"  Simplified Expression: {sympy_simplify_expression(best_individual.to_string())}\")\n",
    "    print(f\"  Expression: {best_individual.to_string()}\")\n",
    "    print(f\"  Fitness: {best_fitness}\")\n",
    "    print(f\"  Complexity: {best_individual.get_complexity()} nodes\")\n",
    "    \n",
    "    # Visualizza statistiche\n",
    "    plot_statistics(stats)\n",
    "    \n",
    "    return best_individual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444fe737",
   "metadata": {},
   "source": [
    "### Termination AND Evaluetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3076,
   "id": "3d4e75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_statistics(stats: Dict) -> None:\n",
    "    \"\"\"\n",
    "    View execution statistics\n",
    "    \n",
    "    Args:\n",
    "        stats: Dictionary with collected statistics\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(10, 12))\n",
    "    \n",
    "    # Fitness plot\n",
    "    axs[0].plot(stats['best_fitness'], label='Best fitness')\n",
    "    axs[0].plot(stats['avg_fitness'], label='Average fitness')\n",
    "    axs[0].set_title('Evolution of fitness')\n",
    "    axs[0].set_xlabel('Generation')\n",
    "    axs[0].set_ylabel('Fitness')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "    \n",
    "    # Size plot\n",
    "    axs[1].plot(stats['best_size'], label='Best individual size')\n",
    "    axs[1].plot(stats['avg_size'], label='Average size')\n",
    "    axs[1].set_title('Evolution of size')\n",
    "    axs[1].set_xlabel('Generation')\n",
    "    axs[1].set_ylabel('Numebr of nodes')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(True)\n",
    "    \n",
    "    # Diversity plot\n",
    "    axs[2].plot(stats['diversity'], label='Diversity')\n",
    "    axs[2].set_title('Evolution of diversity')\n",
    "    axs[2].set_xlabel('Generation')\n",
    "    axs[2].set_ylabel('Proportion of unique expressions')\n",
    "    axs[2].legend()\n",
    "    axs[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gp_statistics.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_predictions(tree: ExpressionTree, X: np.ndarray, y: np.ndarray, title: str) -> None:\n",
    "    \"\"\"\n",
    "    View model predictions compared with actual data\n",
    "    \n",
    "    Args:\n",
    "        tree: Expression tree\n",
    "        X: Input features\n",
    "        y: Output target\n",
    "        title: Title of graph\n",
    "    \"\"\"\n",
    "    # Calculate forecasts\n",
    "    predictions = tree.evaluate(X)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    if X.ndim == 1 or (X.ndim == 2 and X.shape[1] == 1):\n",
    "        # For 1D data, display predictions vs. actual data.\n",
    "        x_plot = X.flatten() if X.ndim == 2 else X\n",
    "        sort_idx = np.argsort(x_plot)\n",
    "        x_plot = x_plot[sort_idx]\n",
    "        y_plot = y[sort_idx]\n",
    "        predictions = predictions[sort_idx]\n",
    "        \n",
    "        plt.scatter(x_plot, y_plot, alpha=0.5, label='Dati reali')\n",
    "        plt.plot(x_plot, predictions, 'r-', linewidth=2, label='Modello GP')\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('y')\n",
    "    else:\n",
    "        # For multidimensional data, display predictions vs. actuals.\n",
    "        plt.scatter(y, predictions, alpha=0.5)\n",
    "        plt.plot([min(y), max(y)], [min(y), max(y)], 'r--', linewidth=2)\n",
    "        plt.xlabel('Target reale')\n",
    "        plt.ylabel('Previsione')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('gp_predictions.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c43ec6",
   "metadata": {},
   "source": [
    "### Configuration and Execution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3077,
   "id": "8dda068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gp_on_problem(file_path: str, config_overrides: Dict = None,\n",
    "    # Additional parameters\n",
    "    function_weights: Dict = None,\n",
    "    terminal_weights: Dict = None,\n",
    "                      \n",
    "    # Parameters for the island model\n",
    "    use_islands: bool = False,\n",
    "    n_islands: int = 5,\n",
    "    migration_interval: int = 50,\n",
    "    migration_rate: float = 0.1,\n",
    "                      \n",
    "    # Parameters for bloat control\n",
    "    bloat_control_interval: int = 5,\n",
    "                      \n",
    "    # Other parameters\n",
    "    early_stopping_generations: int = 100) -> ExpressionTree:\n",
    "    \"\"\"\n",
    "    Runs the GP algorithm on a specific problem with various configurable options\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the problem file\n",
    "        config_overrides: Overrides the default configuration\n",
    "        \n",
    "        # Parameters for function weights and terminals\n",
    "        function_weights: Dictionary of custom weights for functions, ex: {'+': 1.5, '*': 0.8, 'sin': 0.3}\n",
    "        terminal_weights: Dictionary of custom weights for terminals, ex: {'variables': 2.0, 'constants': 0.5}\n",
    "        \n",
    "        # Parameters for island model.\n",
    "        use_islands: Whether to use the island model\n",
    "        n_islands: Number of islands\n",
    "        migration_interval: Interval of generations between migrations\n",
    "        migration_rate: Percentage of population that migrates\n",
    "  \n",
    "        \n",
    "        # Parameters for bloat control\n",
    "        bloat_control_interval: Interval of generations for bloat control.\n",
    "        \n",
    "        # Other parameters\n",
    "        early_stopping_generations: Number of generations without improvement before stopping\n",
    "        \n",
    "    Returns:\n",
    "        Best expression tree found\n",
    "    \"\"\"\n",
    "    # Upload and prepare data\n",
    "    X, y, data_config = prepare_data(file_path)\n",
    "    \n",
    "    # Create the basic configuration\n",
    "    config = GPConfig(\n",
    "        n_features=data_config['n_features'],\n",
    "        const_range=data_config['const_range'],\n",
    "        use_trig=True,\n",
    "        use_exp_log=True,\n",
    "        min_depth=2,\n",
    "        max_depth=6,\n",
    "        pop_size=500,\n",
    "        generations=50,\n",
    "        tournament_size=100,\n",
    "        crossover_prob=0.7,\n",
    "        mutation_prob=0.05,\n",
    "        elitism_rate=0.1,\n",
    "        max_tree_size=50,\n",
    "        parsimony_coef=0.01,\n",
    "        function_weights=function_weights,\n",
    "        terminal_weights=terminal_weights\n",
    "    )\n",
    "    \n",
    "    # Apply overwrites to configuration\n",
    "    if config_overrides:\n",
    "        for key, value in config_overrides.items():\n",
    "            if hasattr(config, key):\n",
    "                setattr(config, key, value)\n",
    "    \n",
    "    # Run the algorithm\n",
    "    print(f\"\\nGP execution on {file_path}...\")\n",
    "    best_tree = genetic_programming(X, y, config, \n",
    "        use_islands=use_islands,\n",
    "        n_islands=n_islands,\n",
    "        migration_interval=migration_interval,\n",
    "        migration_rate=migration_rate,\n",
    "        bloat_control_interval=bloat_control_interval,\n",
    "        early_stopping_generations=early_stopping_generations,)\n",
    "    \n",
    "    # Visualize results\n",
    "    plot_predictions(best_tree, X, y, f\"Previsioni GP su {file_path}\")\n",
    "    \n",
    "    # Simplify the best expression\n",
    "    simplified_expr = sympy_simplify_expression(best_tree.to_string())\n",
    "    print(f\"Original expression: {best_tree.to_string()}\")\n",
    "    print(f\"Simplified expression: {simplified_expr}\")\n",
    "    \n",
    "    return best_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3078,
   "id": "23fb8320",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = [\n",
    "\n",
    "    {\"file_path\": \"../data/problem_0.npz\", \n",
    "     \"config\": {\n",
    "         \"max_depth\": 8, \n",
    "         \"pop_size\": 5000, \n",
    "         \"generations\": 1000,\n",
    "         \"max_tree_size\": 70\n",
    "     },\n",
    "     \"use_islands\": True,\n",
    "     \"n_islands\": 5,\n",
    "     \"migration_interval\": 100,\n",
    "     \"migration_rate\": 0.1\n",
    "    },\n",
    "    \n",
    "\n",
    "    {\"file_path\": \"../data/problem_1.npz\", \n",
    "     \"config\": {\n",
    "         \"max_depth\": 8, \n",
    "         \"pop_size\": 10000, \n",
    "         \"generations\": 1000,\n",
    "         \"max_tree_size\": 70\n",
    "     },\n",
    "     \"use_islands\": True,\n",
    "     \"n_islands\": 5,\n",
    "     \"migration_interval\": 100,\n",
    "     \"migration_rate\": 0.1\n",
    "    },\n",
    "    \n",
    "\n",
    "    {\"file_path\": \"../data/problem_2.npz\", \n",
    "     \"config\": {\n",
    "         \"max_depth\": 8, \n",
    "         \"pop_size\": 10000, \n",
    "         \"generations\": 1000,\n",
    "         \"max_tree_size\": 60\n",
    "     },\n",
    "     \"use_islands\": True,\n",
    "     \"n_islands\": 5,\n",
    "     \"migration_interval\": 80,\n",
    "     \"migration_rate\": 0.12\n",
    "    },\n",
    "    \n",
    " \n",
    "    {\"file_path\": \"../data/problem_3.npz\", \n",
    "     \"config\": {\n",
    "         \"max_depth\": 8, \n",
    "         \"pop_size\": 10000, \n",
    "         \"generations\": 1000,\n",
    "         \"max_tree_size\": 65,\n",
    "     },\n",
    "     \"use_islands\": True,\n",
    "     \"n_islands\": 4,\n",
    "     \"migration_interval\": 50,\n",
    "     \"migration_rate\": 0.2\n",
    "    },\n",
    "\n",
    "    {\"file_path\": \"../data/problem_4.npz\", \n",
    "     \"config\": {\n",
    "         \"max_depth\": 8, \n",
    "         \"pop_size\": 10000, \n",
    "         \"generations\": 1000,\n",
    "         \"max_tree_size\": 100,\n",
    "     },\n",
    "     \"use_islands\": True,\n",
    "     \"n_islands\": 5,  \n",
    "     \"migration_interval\": 50,\n",
    "     \"migration_rate\": 0.08\n",
    "    },\n",
    "\n",
    "    {\"file_path\": \"../data/problem_5.npz\", \n",
    "     \"config\": {\n",
    "         \"max_depth\": 10,  \n",
    "         \"pop_size\": 10000, \n",
    "         \"generations\": 1000,\n",
    "         \"max_tree_size\": 80\n",
    "     },\n",
    "     \"use_islands\": True,\n",
    "     \"n_islands\": 5,\n",
    "     \"migration_interval\": 50,\n",
    "     \"migration_rate\": 0.15\n",
    "    },\n",
    "    \n",
    "\n",
    "    {\"file_path\": \"../data/problem_6.npz\", \n",
    "     \"config\": {\n",
    "         \"max_depth\": 10,  \n",
    "         \"pop_size\": 10000, \n",
    "         \"generations\": 1000,\n",
    "         \"max_tree_size\": 40,\n",
    "         \"parsimony_coef\": 0.05, \n",
    "     },\n",
    "     \"use_islands\": True, \n",
    "     \"early_stopping_generations\": 50 \n",
    "    },\n",
    "    \n",
    "\n",
    "    {\"file_path\": \"../data/problem_7.npz\", \n",
    "     \"config\": {\n",
    "         \"max_depth\": 8, \n",
    "         \"pop_size\": 10000, \n",
    "         \"generations\": 1000,\n",
    "         \"max_tree_size\": 60,\n",
    "         \"tournament_size\": 100, \n",
    "         \"elitism_rate\": 0.2,    \n",
    "     },\n",
    "     \"use_islands\": True,\n",
    "     \"n_islands\": 5,\n",
    "     \"migration_interval\": 50,\n",
    "     \"migration_rate\": 0.25  \n",
    "    },\n",
    "    \n",
    "    {\"file_path\": \"../data/problem_8.npz\", \n",
    "     \"config\": {\n",
    "         \"max_depth\": 8, \n",
    "         \"pop_size\": 10000, \n",
    "         \"generations\": 1000,\n",
    "         \"max_tree_size\": 50,\n",
    "     },\n",
    "     \"use_islands\": True,\n",
    "     \"n_islands\": 5,\n",
    "     \"migration_interval\": 50,\n",
    "     \"migration_rate\": 0.15\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b2b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Esecuzione GP su ../data/problem_0.npz ===\n",
      "Loading data from ../data/problem_0.npz...\n",
      "Detected format with features on rows and samples on columns, transposition...\n",
      "Final form: X shape (1000, 2), y shape (1000,)\n",
      "Input 2-dimensional with 1000 samples\n",
      "\n",
      "GP execution on ../data/problem_0.npz...\n",
      "Starting Genetic Programming for Symbolic Regression...\n",
      "Configuration: pop_size=5000, max_depth=8, generations=1000\n",
      "Island model: 5 islands, migration every 100 generations\n",
      "Function weights:\n",
      "  +: 1.00\n",
      "  -: 1.00\n",
      "  *: 1.00\n",
      "  /: 0.70\n",
      "  sin: 0.60\n",
      "  cos: 0.60\n",
      "  tan: 0.50\n",
      "  exp: 0.40\n",
      "  log: 0.50\n",
      "  sqrt: 0.60\n",
      "Population initialisation of  5000 individuals...\n",
      "  Generated  1000 individuals in  0.03 seconds\n",
      "  Generated  2000 individuals in  0.07 seconds\n",
      "  Generated  3000 individuals in  0.09 seconds\n",
      "  Generated  4000 individuals in  0.12 seconds\n",
      "  Generated  5000 individuals in  0.15 seconds\n",
      "Population initialised in 0.15 seconds\n",
      "Initial population statistics:\n",
      "  - Average height: 4.40 (min: 2, max: 8)\n",
      "  - Average size: 22.13 nodes (min: 3, max: 266)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[0]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(\n",
    "    problems[0]['file_path'], \n",
    "    problems[0]['config'],\n",
    "    function_weights=problems[0]['config'].get('function_weights'),\n",
    "    terminal_weights=problems[0]['config'].get('terminal_weights'),\n",
    "    use_islands=problems[0].get('use_islands', False),\n",
    "    n_islands=problems[0].get('n_islands', 5),\n",
    "    migration_interval=problems[0].get('migration_interval', 10),\n",
    "    migration_rate=problems[0].get('migration_rate', 0.1),\n",
    "    early_stopping_generations=problems[0].get('early_stopping_generations', 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f05602",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[1]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(\n",
    "    problems[1]['file_path'], \n",
    "    problems[1]['config'],\n",
    "    function_weights=problems[1]['config'].get('function_weights'),\n",
    "    terminal_weights=problems[1]['config'].get('terminal_weights'),\n",
    "    use_islands=problems[1].get('use_islands', False),\n",
    "    n_islands=problems[1].get('n_islands', 5),\n",
    "    migration_interval=problems[1].get('migration_interval', 10),\n",
    "    migration_rate=problems[1].get('migration_rate', 0.1),\n",
    "    early_stopping_generations=problems[1].get('early_stopping_generations', 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a93d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[2]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(\n",
    "    problems[2]['file_path'], \n",
    "    problems[2]['config'],\n",
    "    function_weights=problems[2]['config'].get('function_weights'),\n",
    "    terminal_weights=problems[2]['config'].get('terminal_weights'),\n",
    "    use_islands=problems[2].get('use_islands', False),\n",
    "    n_islands=problems[2].get('n_islands', 5),\n",
    "    migration_interval=problems[2].get('migration_interval', 10),\n",
    "    migration_rate=problems[2].get('migration_rate', 0.1),\n",
    "    early_stopping_generations=problems[2].get('early_stopping_generations', 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d9c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[3]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(\n",
    "    problems[3]['file_path'], \n",
    "    problems[3]['config'],\n",
    "    function_weights=problems[3]['config'].get('function_weights'),\n",
    "    terminal_weights=problems[3]['config'].get('terminal_weights'),\n",
    "    use_islands=problems[3].get('use_islands', False),\n",
    "    n_islands=problems[3].get('n_islands', 5),\n",
    "    migration_interval=problems[3].get('migration_interval', 10),\n",
    "    migration_rate=problems[3].get('migration_rate', 0.1),\n",
    "    early_stopping_generations=problems[3].get('early_stopping_generations', 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750a8f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[4]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(problems[4]['file_path'],\n",
    "    problems[4]['config'],\n",
    "    function_weights=problems[4]['config'].get('function_weights'),\n",
    "    terminal_weights=problems[4]['config'].get('terminal_weights'),\n",
    "    use_islands=problems[4].get('use_islands', False),\n",
    "    n_islands=problems[4].get('n_islands', 5),\n",
    "    migration_interval=problems[4].get('migration_interval', 10),\n",
    "    migration_rate=problems[4].get('migration_rate', 0.1),\n",
    "    early_stopping_generations=problems[4].get('early_stopping_generations', 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4203d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[5]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(problems[5]['file_path'],\n",
    "    problems[5]['config'],\n",
    "    function_weights=problems[5]['config'].get('function_weights'),\n",
    "    terminal_weights=problems[5]['config'].get('terminal_weights'),\n",
    "    use_islands=problems[5].get('use_islands', False),\n",
    "    n_islands=problems[5].get('n_islands', 5),\n",
    "    migration_interval=problems[5].get('migration_interval', 10),\n",
    "    migration_rate=problems[5].get('migration_rate', 0.1),\n",
    "    early_stopping_generations=problems[5].get('early_stopping_generations', 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b247a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[6]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(problems[6]['file_path'],\n",
    "    problems[6]['config'],\n",
    "    function_weights=problems[6]['config'].get('function_weights'),\n",
    "    terminal_weights=problems[6]['config'].get('terminal_weights'),\n",
    "    use_islands=problems[6].get('use_islands', False),\n",
    "    n_islands=problems[6].get('n_islands', 5),\n",
    "    migration_interval=problems[6].get('migration_interval', 10),\n",
    "    migration_rate=problems[6].get('migration_rate', 0.1),\n",
    "    early_stopping_generations=problems[6].get('early_stopping_generations', 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dceedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[7]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(problems[7]['file_path'],\n",
    "    problems[7]['config'],\n",
    "    function_weights=problems[7]['config'].get('function_weights'),\n",
    "    terminal_weights=problems[7]['config'].get('terminal_weights'),\n",
    "    use_islands=problems[7].get('use_islands', False),\n",
    "    n_islands=problems[7].get('n_islands', 5),\n",
    "    migration_interval=problems[7].get('migration_interval', 10),\n",
    "    migration_rate=problems[7].get('migration_rate', 0.1),\n",
    "    early_stopping_generations=problems[7].get('early_stopping_generations', 100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[8]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(problems[8]['file_path'],\n",
    "    problems[8]['config'],\n",
    "    function_weights=problems[8]['config'].get('function_weights'),\n",
    "    terminal_weights=problems[8]['config'].get('terminal_weights'),\n",
    "    use_islands=problems[8].get('use_islands', False),\n",
    "    n_islands=problems[8].get('n_islands', 5),\n",
    "    migration_interval=problems[8].get('migration_interval', 10),\n",
    "    migration_rate=problems[8].get('migration_rate', 0.1),\n",
    "    early_stopping_generations=problems[8].get('early_stopping_generations', 100)\n",
    ")  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
