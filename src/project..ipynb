{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a15723d4",
   "metadata": {},
   "source": [
    "### Cos'è `prepare_data`?\n",
    "\n",
    "La funzione `prepare_data` è responsabile di eseguire tutti i passaggi preparatori prima di iniziare l'algoritmo genetico vero e proprio. Analizziamola passo per passo:\n",
    "\n",
    "#### 1. Caricamento dei dati\n",
    "\n",
    "```python\n",
    "data = np.load(file_path)\n",
    "X = data['x']  # Input (valori delle variabili)\n",
    "y = data['y']  # Output (risultato che vogliamo predire)\n",
    "```\n",
    "\n",
    "Questo carica i dati dal file .npz. `X` contiene i valori delle variabili indipendenti (input) e `y` contiene i valori della variabile dipendente (output).\n",
    "\n",
    "#### 2. Analisi della dimensionalità\n",
    "\n",
    "```python\n",
    "if X.ndim == 1:\n",
    "    n_features = 1\n",
    "else:\n",
    "    n_features = X.shape[1]\n",
    "```\n",
    "\n",
    "Qui determiniamo se stiamo lavorando con una singola variabile (ad es. `y = f(x)`) o con più variabili (ad es. `y = f(x₁, x₂, x₃, ...)`). Questo è fondamentale perché:\n",
    "- Con una variabile, le nostre espressioni saranno del tipo `2*x + 3`\n",
    "- Con più variabili, saranno tipo `2*x[0] + 3*x[1] - 5`\n",
    "\n",
    "#### 3. Calcolo delle statistiche\n",
    "\n",
    "```python\n",
    "print(f\"- Media: {np.mean(y):.4f}\")\n",
    "print(f\"- Min: {np.min(y):.4f}, Max: {np.max(y):.4f}\")\n",
    "```\n",
    "\n",
    "Queste statistiche ci aiutano a capire la natura dei dati: la scala, il range, ecc.\n",
    "\n",
    "\n",
    "#### 4. Configurazione per il GP\n",
    "\n",
    "```python\n",
    "variables = [f'x[{i}]' for i in range(n_features)]\n",
    "const_range = max(np.max(np.abs(X)), np.max(np.abs(y)))\n",
    "```\n",
    "\n",
    "Qui creiamo i nomi delle variabili (`x[0]`, `x[1]`, ecc.) e definiamo il range per le costanti.\n",
    "\n",
    "### Cosa sono le costanti e perché sono importanti?\n",
    "\n",
    "#### Le costanti nell'ambito della Symbolic Regression\n",
    "\n",
    "Nel contesto della programmazione genetica per symbolic regression, le espressioni matematiche contengono:\n",
    "\n",
    "1. **Variabili** (come `x` o `x[0]`, `x[1]`): Questi sono i valori di input che cambiano per ogni punto dati.\n",
    "\n",
    "2. **Operatori** (come `+`, `-`, `*`, `/`, `sin`, `exp`): Sono le operazioni matematiche.\n",
    "\n",
    "3. **Costanti** (come `2.5`, `3.14`, `-0.7`): Sono numeri fissi che completano l'espressione.\n",
    "\n",
    "**Esempio**: In un'espressione come `2.5 * x² + 3.14 * sin(x) - 0.7`, i numeri `2.5`, `3.14` e `-0.7` sono costanti.\n",
    "\n",
    "#### A cosa serve `const_range`?\n",
    "\n",
    "`const_range` determina il range entro cui verranno generate casualmente le costanti durante:\n",
    "\n",
    "1. **Inizializzazione della popolazione**: Quando creiamo le espressioni iniziali, dobbiamo inserire costanti ragionevoli.\n",
    "   - Se i dati sono nell'ordine di 0.001, costanti come 1000 sarebbero inutili\n",
    "   - Se i dati sono nell'ordine di 1000, costanti come 0.001 sarebbero inefficaci\n",
    "\n",
    "2. **Mutazione delle costanti**: Durante l'evoluzione, alcune mutazioni modificheranno i valori delle costanti.\n",
    "\n",
    "```python\n",
    "# Esempio di generazione di una costante casuale\n",
    "random_constant = random.uniform(-const_range, const_range)\n",
    "# o con distribuzione più centrata\n",
    "random_constant = random.uniform(-const_range/2, const_range/2)\n",
    "```\n",
    "\n",
    "#### Perché calcoliamo `const_range` dai dati?\n",
    "\n",
    "Calcoliamo `const_range` in base ai valori massimi assoluti di X e y per:\n",
    "\n",
    "1. **Efficienza**: Costanti troppo grandi o troppo piccole rispetto ai dati rendono l'evoluzione inefficiente.\n",
    "\n",
    "2. **Convergenza più rapida**: Con costanti nel range giusto, l'algoritmo trova più velocemente soluzioni valide.\n",
    "\n",
    "3. **Evitare problemi numerici**: Costanti troppo estreme possono causare overflow/underflow con operazioni come potenze o esponenziali.\n",
    "\n",
    "### Esempio pratico\n",
    "\n",
    "Supponiamo di voler trovare una funzione che rappresenti la relazione `y = 2x² + 3.5`:\n",
    "\n",
    "- I valori di X potrebbero essere tra -10 e 10\n",
    "- I valori di y sarebbero quindi tra 0 e 200+\n",
    "- `const_range` sarebbe circa 200\n",
    "- La GP genererà costanti casuali tipo 53.2, -47.8, 122.6, ecc.\n",
    "- Con l'evoluzione, alcune si avvicineranno ai valori reali (2 e 3.5)\n",
    "\n",
    "In breve, le costanti sono i \"numeri\" nelle espressioni matematiche, e `const_range` aiuta l'algoritmo a generare questi numeri in modo sensato rispetto ai dati che sta analizzando.\n",
    "\n",
    "Ti è più chiaro ora? Hai altre domande specifiche sulla funzione `prepare_data` o sul ruolo delle costanti?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10137ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\domen\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from typing import List, Union, Callable, Optional, Tuple, Dict, Any\n",
    "import time\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from icecream import ic\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72598ca0",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3df2c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dati da ../data/problem_0.npz...\n",
      "Forme originali: X shape (2, 1000), y shape (1000,)\n",
      "Rilevato formato con features sulle righe e campioni sulle colonne, trasposizione...\n",
      "X trasposto ha forma (1000, 2)\n",
      "Forme finali: X shape (1000, 2), y shape (1000,)\n",
      "Input 2-dimensionale con 1000 campioni\n",
      "\n",
      "Configurazione per GP: {'variables': ['x[0]', 'x[1]'], 'n_features': 2, 'const_range': np.float64(3.23346517158693), 'y_stats': {'mean': 0.0740349656325135, 'std': 1.8421127520800509, 'min': -3.208666606823163, 'max': 3.23346517158693}, 'dataset_size': 1000}\n",
      "--------------------------------------------------\n",
      "Caricamento dati da ../data/problem_1.npz...\n",
      "Forme originali: X shape (1, 500), y shape (500,)\n",
      "Rilevato formato con features sulle righe e campioni sulle colonne, trasposizione...\n",
      "X trasposto ha forma (500, 1)\n",
      "Forme finali: X shape (500, 1), y shape (500,)\n",
      "Input 1-dimensionale con 500 campioni\n",
      "\n",
      "Configurazione per GP: {'variables': ['x[0]'], 'n_features': 1, 'const_range': np.float64(0.9954328739932046), 'y_stats': {'mean': -0.028581340125470176, 'std': 0.5035248258112494, 'min': -0.8322110937504172, 'max': 0.8389945887188881}, 'dataset_size': 500}\n",
      "--------------------------------------------------\n",
      "Caricamento dati da ../data/problem_2.npz...\n",
      "Forme originali: X shape (3, 5000), y shape (5000,)\n",
      "Rilevato formato con features sulle righe e campioni sulle colonne, trasposizione...\n",
      "X trasposto ha forma (5000, 3)\n",
      "Forme finali: X shape (5000, 3), y shape (5000,)\n",
      "Input 3-dimensionale con 5000 campioni\n",
      "\n",
      "Configurazione per GP: {'variables': ['x[0]', 'x[1]', 'x[2]'], 'n_features': 3, 'const_range': np.float64(7643020.544814716), 'y_stats': {'mean': 56465.10655809015, 'std': 5441856.124013525, 'min': -7643020.544814716, 'max': 7643015.666932668}, 'dataset_size': 5000}\n",
      "--------------------------------------------------\n",
      "Caricamento dati da ../data/problem_3.npz...\n",
      "Forme originali: X shape (3, 5000), y shape (5000,)\n",
      "Rilevato formato con features sulle righe e campioni sulle colonne, trasposizione...\n",
      "X trasposto ha forma (5000, 3)\n",
      "Forme finali: X shape (5000, 3), y shape (5000,)\n",
      "Input 3-dimensionale con 5000 campioni\n",
      "\n",
      "Configurazione per GP: {'variables': ['x[0]', 'x[1]', 'x[2]'], 'n_features': 3, 'const_range': np.float64(187.18503862007498), 'y_stats': {'mean': 21.20757039569563, 'std': 50.61161179521197, 'min': -134.0160235060043, 'max': 187.18503862007498}, 'dataset_size': 5000}\n",
      "--------------------------------------------------\n",
      "Caricamento dati da ../data/problem_4.npz...\n",
      "Forme originali: X shape (2, 5000), y shape (5000,)\n",
      "Rilevato formato con features sulle righe e campioni sulle colonne, trasposizione...\n",
      "X trasposto ha forma (5000, 2)\n",
      "Forme finali: X shape (5000, 2), y shape (5000,)\n",
      "Input 2-dimensionale con 5000 campioni\n",
      "\n",
      "Configurazione per GP: {'variables': ['x[0]', 'x[1]'], 'n_features': 2, 'const_range': np.float64(10.701637922762112), 'y_stats': {'mean': 1.9997861267141543, 'std': 4.649946409222459, 'min': -4.158487374107485, 'max': 10.701637922762112}, 'dataset_size': 5000}\n",
      "--------------------------------------------------\n",
      "Caricamento dati da ../data/problem_5.npz...\n",
      "Forme originali: X shape (2, 5000), y shape (5000,)\n",
      "Rilevato formato con features sulle righe e campioni sulle colonne, trasposizione...\n",
      "X trasposto ha forma (5000, 2)\n",
      "Forme finali: X shape (5000, 2), y shape (5000,)\n",
      "Input 2-dimensionale con 5000 campioni\n",
      "\n",
      "Configurazione per GP: {'variables': ['x[0]', 'x[1]'], 'n_features': 2, 'const_range': np.float64(4.999969022322079), 'y_stats': {'mean': -5.794871983107769e-10, 'std': 2.2884503096224874e-09, 'min': -2.8520706810421616e-08, 'max': 1.6242242902247692e-10}, 'dataset_size': 5000}\n",
      "--------------------------------------------------\n",
      "Caricamento dati da ../data/problem_6.npz...\n",
      "Forme originali: X shape (2, 5000), y shape (5000,)\n",
      "Rilevato formato con features sulle righe e campioni sulle colonne, trasposizione...\n",
      "X trasposto ha forma (5000, 2)\n",
      "Forme finali: X shape (5000, 2), y shape (5000,)\n",
      "Input 2-dimensionale con 5000 campioni\n",
      "\n",
      "Configurazione per GP: {'variables': ['x[0]', 'x[1]'], 'n_features': 2, 'const_range': np.float64(11.914375580518566), 'y_stats': {'mean': -3.599013872003943, 'std': 3.694501463162234, 'min': -11.914375580518566, 'max': 4.569846551384467}, 'dataset_size': 5000}\n",
      "--------------------------------------------------\n",
      "Caricamento dati da ../data/problem_7.npz...\n",
      "Forme originali: X shape (2, 5000), y shape (5000,)\n",
      "Rilevato formato con features sulle righe e campioni sulle colonne, trasposizione...\n",
      "X trasposto ha forma (5000, 2)\n",
      "Forme finali: X shape (5000, 2), y shape (5000,)\n",
      "Input 2-dimensionale con 5000 campioni\n",
      "\n",
      "Configurazione per GP: {'variables': ['x[0]', 'x[1]'], 'n_features': 2, 'const_range': np.float64(508.41757230561365), 'y_stats': {'mean': 10.230460379797575, 'std': 26.66750114052942, 'min': 1.299874436653608, 'max': 508.41757230561365}, 'dataset_size': 5000}\n",
      "--------------------------------------------------\n",
      "Caricamento dati da ../data/problem_8.npz...\n",
      "Forme originali: X shape (6, 50000), y shape (50000,)\n",
      "Rilevato formato con features sulle righe e campioni sulle colonne, trasposizione...\n",
      "X trasposto ha forma (50000, 6)\n",
      "Forme finali: X shape (50000, 6), y shape (50000,)\n",
      "Input 6-dimensionale con 50000 campioni\n",
      "\n",
      "Configurazione per GP: {'variables': ['x[0]', 'x[1]', 'x[2]', 'x[3]', 'x[4]', 'x[5]'], 'n_features': 6, 'const_range': np.float64(18052.7428193291), 'y_stats': {'mean': -549.7154440795717, 'std': 4765.072335625078, 'min': -18052.7428193291, 'max': 15742.204109576767}, 'dataset_size': 50000}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def prepare_data(file_path):\n",
    "    \"\"\"\n",
    "    Prepara i dati per la Symbolic Regression con Genetic Programming\n",
    "    \n",
    "    Args:\n",
    "        file_path: Percorso del file .npz con i dati\n",
    "        \n",
    "    Returns:\n",
    "        X: Array di input features\n",
    "        y: Array di output target\n",
    "        config: Configurazione per il GP basata sui dati\n",
    "    \"\"\"\n",
    "    # 1. Caricamento dei dati\n",
    "    print(f\"Caricamento dati da {file_path}...\")\n",
    "    data = np.load(file_path)\n",
    "    X = data['x']\n",
    "    y = data['y']\n",
    "    \n",
    "    # Stampa forme originali per debug\n",
    "    print(f\"Forme originali: X shape {X.shape}, y shape {y.shape}\")\n",
    "    \n",
    "    # Gestione specifica per dati con dimensioni trasposte\n",
    "    # Se abbiamo più features che campioni, probabilmente dobbiamo trasporre\n",
    "    if X.ndim > 1 and X.shape[1] > X.shape[0] and y.shape[0] == X.shape[1]:\n",
    "        print(\"Rilevato formato con features sulle righe e campioni sulle colonne, trasposizione...\")\n",
    "        X = X.T  # Trasponiamo per avere i campioni sulle righe\n",
    "        print(f\"X trasposto ha forma {X.shape}\")\n",
    "    \n",
    "    # Gestione di formati diversi\n",
    "    if y.ndim > 1:\n",
    "        if y.shape[0] == 1 or y.shape[1] == 1:  # Se y è [1, n_samples] o [n_samples, 1]\n",
    "            y = y.flatten()\n",
    "            print(f\"y trasformato in forma {y.shape}\")\n",
    "    \n",
    "    # Assicuriamo che X sia 2D se multidimensionale\n",
    "    if X.ndim == 1:\n",
    "        X = X.reshape(-1, 1)\n",
    "        print(f\"X reso 2D con forma {X.shape}\")\n",
    "    \n",
    "    print(f\"Forme finali: X shape {X.shape}, y shape {y.shape}\")\n",
    "    \n",
    "    # Verifica di coerenza: il numero di campioni deve corrispondere\n",
    "    if X.shape[0] != len(y):\n",
    "        raise ValueError(f\"Numero di campioni non coerente: X ha {X.shape[0]} campioni, y ne ha {len(y)}\")\n",
    "    \n",
    "    # 2. Analisi dei dati\n",
    "    # Determinare la dimensionalità dell'input\n",
    "    n_features = X.shape[1]\n",
    "    print(f\"Input {n_features}-dimensionale con {X.shape[0]} campioni\")\n",
    "    \n",
    "    # 3. Configurazione per GP\n",
    "    # Definiamo il set di variabili in base alla dimensionalità\n",
    "    variables = [f'x[{i}]' for i in range(n_features)]\n",
    "    \n",
    "    # Determiniamo un range ragionevole per le costanti casuali\n",
    "    const_range = max(np.max(np.abs(X)), np.max(np.abs(y)))\n",
    "    \n",
    "    # Configurazione completa per il GP\n",
    "    config = {\n",
    "        'variables': variables,\n",
    "        'n_features': n_features,\n",
    "        'const_range': const_range,\n",
    "        'y_stats': {\n",
    "            'mean': float(np.mean(y)),\n",
    "            'std': float(np.std(y)),\n",
    "            'min': float(np.min(y)),\n",
    "            'max': float(np.max(y))\n",
    "        },\n",
    "        'dataset_size': len(y)\n",
    "    }\n",
    "    \n",
    "    return X, y, config\n",
    "\n",
    "for i in range(0, 9):\n",
    "    file_path = f\"../data/problem_{i}.npz\"\n",
    "    X, y, config = prepare_data(file_path)\n",
    "    print(f\"\\nConfigurazione per GP: {config}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf6c960",
   "metadata": {},
   "source": [
    "### Expression Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d3a13a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"Classe base per rappresentare un nodo nell'albero di espressioni\"\"\"\n",
    "    def __init__(self):\n",
    "        self.depth = 0  # Profondità del nodo\n",
    "    \n",
    "    def evaluate(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Valuta il nodo dato un input X\"\"\"\n",
    "        raise NotImplementedError(\"Devi implementare il metodo evaluate nella sottoclasse\")\n",
    "    def copy(self) -> 'Node':\n",
    "        \"\"\"Copia il nodo corrente\"\"\"\n",
    "        raise NotImplementedError(\"Devi implementare il metodo copy nella sottoclasse\")\n",
    "    \n",
    "    def to_string(self) -> str:\n",
    "        \"\"\"Restituisce una rappresentazione stringa del nodo\"\"\"\n",
    "        raise NotImplementedError(\"Devi implementare il metodo __str__ nella sottoclasse\")\n",
    "    \n",
    "    def get_complexity(self) -> int:\n",
    "        \"\"\"Restituisce la complessità del nodo (numero di nodi)\"\"\"\n",
    "        return NotImplementedError(\"Devi implementare il metodo get_complexity nella sottoclasse\")\n",
    "    \n",
    "    def get_height(self) -> int:\n",
    "        \"\"\"Restituisce l'altezza del nodo\"\"\"\n",
    "        return NotImplementedError(\"Devi implementare il metodo get_height nella sottoclasse\")\n",
    "    \n",
    "    def get_nodes(self) -> int:\n",
    "        \"\"\"Restituisce il numero totale di nodi nell'albero\"\"\"\n",
    "        return NotImplementedError(\"Devi implementare il metodo get_nodes nella sottoclasse\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87aba7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionNode(Node):\n",
    "    \"\"\"Classe per rappresentare un nodo funzione nell'albero di espressioni\"\"\"\n",
    "    def __init__(self, function: Callable, arity: int, symbol: str, children: List[Node] = None):\n",
    "        super().__init__()\n",
    "        self.function = function # Funzione (np) da applicare\n",
    "        self.arity = arity # Numero di argomenti richiesti dalla funzione\n",
    "        self.symbol = symbol # Simbolo per la rappresentazione stringa\n",
    "        self.children = children if children is not None else []\n",
    "\n",
    "    def evaluate(self, X: np.ndarray)->np.ndarray:\n",
    "        \"\"\"Valuta la funzione applicandola ai risultati dei figli\"\"\"\n",
    "        # Valuta i figli\n",
    "        args= [child.evaluate(X) for child in self.children]\n",
    "        # Applica la funzione\n",
    "        return self.function(*args)\n",
    "    \n",
    "    def copy(self) -> 'FunctionNode':\n",
    "        \"\"\"Crea una copia profonda del nodo funzione\"\"\"\n",
    "        new_children = [child.copy() for child in self.children]\n",
    "        new_node = FunctionNode(self.function, self.arity, self.symbol, new_children)\n",
    "        new_node.depth = self.depth\n",
    "        return new_node\n",
    "    \n",
    "    def to_string(self) -> str:\n",
    "        \"\"\"Restituisce una rappresentazione stringa del nodo funzione\"\"\"\n",
    "        if self.arity == 1:\n",
    "            # Funzione unaria\n",
    "            return f\"{self.symbol}({self.children[0].to_string()})\"\n",
    "        elif self.arity == 2:\n",
    "            # Funzione binaria (es. +, -, *, /)\n",
    "            return f\"({self.children[0].to_string()} {self.symbol} {self.children[1].to_string()})\"\n",
    "        else:\n",
    "            # Funzioni con arità maggiore (anche se non dovrebbero essere comuni)\n",
    "            args = \", \".join(child.to_string() for child in self.children)\n",
    "            return f\"{self.symbol}({args})\"\n",
    "        \n",
    "    def get_complexity(self) -> int:\n",
    "        \"\"\"Restituisce la complessità del nodo (numero di nodi)\"\"\"\n",
    "        return 1 + sum(child.get_complexity() for child in self.children)\n",
    "\n",
    "    def get_height(self) -> int:\n",
    "        \"\"\"Restituisce l'altezza del nodo\"\"\"\n",
    "        return 1 + max((child.get_height() for child in self.children), default=0)\n",
    "\n",
    "    def get_nodes(self) -> List[Node]:\n",
    "        \"\"\"Restituisce una lista di tutti i nodi nell'albero\"\"\"\n",
    "        nodes = [self]\n",
    "        for child in self.children:\n",
    "            nodes.extend(child.get_nodes())\n",
    "        return nodes\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7dd03f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TerminalNode(Node):\n",
    "    \"\"\"Rappresenta un nodo terminale nell'albero (variabile o costante)\"\"\"\n",
    "    \n",
    "    def __init__(self, value, is_variable: bool = False, var_index: int = None):\n",
    "        super().__init__()\n",
    "        self.value = value\n",
    "        self.is_variable = is_variable\n",
    "        self.var_index = var_index  # usato solo se is_variable è True\n",
    "    \n",
    "    def evaluate(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Valuta il nodo terminale\"\"\"\n",
    "        if self.is_variable:\n",
    "            # Se è una variabile, prendiamo il valore dall'input X\n",
    "            if X.ndim == 1 and self.var_index == 0:\n",
    "                return X  # caso speciale per input 1D\n",
    "            else:\n",
    "                return X[:, self.var_index]\n",
    "        else:\n",
    "            # Se è una costante, restituiamo il valore (broadcast su tutti i campioni)\n",
    "            return np.full(X.shape[0] if X.ndim > 1 else len(X), self.value)\n",
    "    \n",
    "    def copy(self) -> 'TerminalNode':\n",
    "        \"\"\"Crea una copia del nodo terminale\"\"\"\n",
    "        new_node = TerminalNode(self.value, self.is_variable, self.var_index)\n",
    "        new_node.depth = self.depth\n",
    "        return new_node\n",
    "    \n",
    "    def to_string(self) -> str:\n",
    "        \"\"\"Restituisce la rappresentazione in forma di stringa del nodo\"\"\"\n",
    "        if self.is_variable:\n",
    "            return f\"x[{self.var_index}]\"\n",
    "        else:\n",
    "            # Formattazione delle costanti per evitare numeri troppo lunghi\n",
    "            if isinstance(self.value, float):\n",
    "                return f\"{self.value:.4f}\"\n",
    "            return str(self.value)\n",
    "    \n",
    "    def get_complexity(self) -> int:\n",
    "        \"\"\"La complessità di un nodo terminale è 1\"\"\"\n",
    "        return 1\n",
    "    \n",
    "    def get_height(self) -> int:\n",
    "        \"\"\"L'altezza di un nodo terminale è 0\"\"\"\n",
    "        return 0\n",
    "    \n",
    "    def get_nodes(self) -> List[Node]:\n",
    "        \"\"\"Restituisce una lista contenente solo questo nodo\"\"\"\n",
    "        return [self]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "417e489d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpressionTree:\n",
    "    \"\"\"Rappresenta un albero di espressione completo\"\"\"\n",
    "    \n",
    "    def __init__(self, root: Node):\n",
    "        self.root = root\n",
    "        self.update_node_depths()\n",
    "        self.fitness = None\n",
    "        self.adjusted_fitness = None  # per fitness sharing e altre tecniche\n",
    "        self.age = 0  # per age layering\n",
    "    \n",
    "    def evaluate(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Valuta l'albero di espressione sui dati di input\"\"\"\n",
    "        return self.root.evaluate(X)\n",
    "    \n",
    "    def copy(self) -> 'ExpressionTree':\n",
    "        \"\"\"Crea una copia profonda dell'albero\"\"\"\n",
    "        new_tree = ExpressionTree(self.root.copy())\n",
    "        new_tree.fitness = self.fitness\n",
    "        new_tree.adjusted_fitness = self.adjusted_fitness\n",
    "        new_tree.age = self.age\n",
    "        return new_tree\n",
    "    \n",
    "    def to_string(self) -> str:\n",
    "        \"\"\"Restituisce la rappresentazione in forma di stringa dell'albero\"\"\"\n",
    "        return self.root.to_string()\n",
    "    \n",
    "    def get_complexity(self) -> int:\n",
    "        \"\"\"Restituisce la complessità dell'albero\"\"\"\n",
    "        return self.root.get_complexity()\n",
    "    \n",
    "    def get_height(self) -> int:\n",
    "        \"\"\"Restituisce l'altezza dell'albero\"\"\"\n",
    "        return self.root.get_height()\n",
    "    \n",
    "    def get_nodes(self) -> List[Node]:\n",
    "        \"\"\"Restituisce una lista di tutti i nodi nell'albero\"\"\"\n",
    "        return self.root.get_nodes()\n",
    "    \n",
    "    def get_subtree_at_index(self, index: int) -> Node:\n",
    "        \"\"\"\n",
    "        Restituisce il sottoalbero al nodo specificato dall'indice\n",
    "        Utile per le operazioni di crossover e mutazione\n",
    "        \"\"\"\n",
    "        nodes = self.get_nodes()\n",
    "        if 0 <= index < len(nodes):\n",
    "            return nodes[index]\n",
    "        return None\n",
    "    \n",
    "    def replace_subtree_at_index(self, index: int, new_subtree: Node) -> bool:\n",
    "        \"\"\"\n",
    "        Sostituisce il sottoalbero al nodo specificato dall'indice\n",
    "        Restituisce True se l'operazione è riuscita, False altrimenti\n",
    "        \"\"\"\n",
    "        nodes = self.get_nodes()\n",
    "        if not (0 <= index < len(nodes)):\n",
    "            return False\n",
    "        \n",
    "        target_node = nodes[index]\n",
    "        \n",
    "        # Caso speciale: sostituire la radice dell'albero\n",
    "        if target_node == self.root:\n",
    "            self.root = new_subtree\n",
    "            self.update_node_depths()\n",
    "            return True\n",
    "        \n",
    "        # Altrimenti, dobbiamo trovare il genitore del nodo target\n",
    "        for node in nodes:\n",
    "            if isinstance(node, FunctionNode):\n",
    "                for i, child in enumerate(node.children):\n",
    "                    if child == target_node:\n",
    "                        node.children[i] = new_subtree\n",
    "                        self.update_node_depths()\n",
    "                        return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def update_node_depths(self):\n",
    "        \"\"\"Aggiorna la profondità di tutti i nodi nell'albero\"\"\"\n",
    "        self._update_depth(self.root, 0)\n",
    "    \n",
    "    def _update_depth(self, node: Node, depth: int):\n",
    "        \"\"\"Helper ricorsivo per aggiornare la profondità\"\"\"\n",
    "        node.depth = depth\n",
    "        if isinstance(node, FunctionNode):\n",
    "            for child in node.children:\n",
    "                self._update_depth(child, depth + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8352c5",
   "metadata": {},
   "source": [
    "### Function Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce9660cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_div(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Divisione protetta: restituisce a/b o 1 quando b è vicino a zero\"\"\"\n",
    "    return np.divide(a, b, out=np.ones_like(a), where=np.abs(b) > 1e-10)\n",
    "\n",
    "def safe_log(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Logaritmo protetto: restituisce log(|a|) o 0 per a vicino a zero\"\"\"\n",
    "    return np.log(np.abs(a), out=np.zeros_like(a), where=np.abs(a) > 1e-10)\n",
    "\n",
    "def safe_sqrt(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Radice quadrata protetta: restituisce sqrt(|a|)\"\"\"\n",
    "    return np.sqrt(np.abs(a))\n",
    "\n",
    "def safe_exp(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Esponenziale protetto: limita l'input per evitare overflow\"\"\"\n",
    "    # Limita gli input a [-200, 100] per evitare overflow\n",
    "    return np.exp(np.clip(a, -200, 200))\n",
    "\n",
    "def safe_sin(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Seno protetto\"\"\"\n",
    "    return np.sin(np.clip(a, -1000, 1000))\n",
    "\n",
    "def safe_cos(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Coseno protetto\"\"\"\n",
    "    return np.cos(np.clip(a, -1000, 1000))\n",
    "\n",
    "def safe_tan(a: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Tangente protetta: limita gli output per evitare valori estremi\"\"\"\n",
    "    return np.clip(np.tan(a), -200, 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf5fa91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_function_set(use_trig: bool = True, use_exp_log: bool = True) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Crea un set di funzioni da utilizzare nell'albero delle espressioni\n",
    "    \n",
    "    Args:\n",
    "        use_trig: Se includere funzioni trigonometriche\n",
    "        use_exp_log: Se includere funzioni esponenziali e logaritmiche\n",
    "        \n",
    "    Returns:\n",
    "        Lista di dizionari, ciascuno con:\n",
    "            - function: la funzione Python da chiamare\n",
    "            - arity: il numero di argomenti richiesti\n",
    "            - symbol: il simbolo per la visualizzazione\n",
    "            - weight: peso di selezione (probabilità relativa)\n",
    "    \"\"\"\n",
    "    # Funzioni aritmetiche di base (sempre incluse)\n",
    "    functions = [\n",
    "        {'function': np.add, 'arity': 2, 'symbol': '+', 'weight': 1.0},\n",
    "        {'function': np.subtract, 'arity': 2, 'symbol': '-', 'weight': 1.0},\n",
    "        {'function': np.multiply, 'arity': 2, 'symbol': '*', 'weight': 1.0},\n",
    "        {'function': safe_div, 'arity': 2, 'symbol': '/', 'weight': 0.7},  # Peso più basso per la divisione\n",
    "    ]\n",
    "    \n",
    "    # Funzioni trigonometriche (opzionali)\n",
    "    if use_trig:\n",
    "        functions.extend([\n",
    "            {'function': safe_sin, 'arity': 1, 'symbol': 'sin', 'weight': 0.6},\n",
    "            {'function': safe_cos, 'arity': 1, 'symbol': 'cos', 'weight': 0.6},\n",
    "            {'function': safe_tan, 'arity': 1, 'symbol': 'tan', 'weight': 0.6},  # Peso più basso per la tangente\n",
    "        ])\n",
    "    \n",
    "    # Funzioni esponenziali e logaritmiche (opzionali)\n",
    "    if use_exp_log:\n",
    "        functions.extend([\n",
    "            {'function': safe_exp, 'arity': 1, 'symbol': 'exp', 'weight': 0.4},\n",
    "            {'function': safe_log, 'arity': 1, 'symbol': 'log', 'weight': 0.5},\n",
    "            {'function': safe_sqrt, 'arity': 1, 'symbol': 'sqrt', 'weight': 0.6},\n",
    "        ])\n",
    "    \n",
    "    return functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1309f4b7",
   "metadata": {},
   "source": [
    "### Terminal Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9b96171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variable_terminals(n_features: int) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Crea terminali per le variabili d'input\n",
    "    \n",
    "    Args:\n",
    "        n_features: Numero di variabili d'input\n",
    "        \n",
    "    Returns:\n",
    "        Lista di dizionari per i terminali variabili\n",
    "    \"\"\"\n",
    "    return [\n",
    "        {\n",
    "            'is_variable': True, \n",
    "            'var_index': i, \n",
    "            'weight': 1.0\n",
    "        } for i in range(n_features)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1743b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_constant_terminals(const_range: float, n_constants: int = 10) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Crea terminali per le costanti\n",
    "    \n",
    "    Args:\n",
    "        const_range: Range per le costanti casuali\n",
    "        n_constants: Numero di costanti pre-generate\n",
    "        \n",
    "    Returns:\n",
    "        Lista di dizionari per i terminali costanti\n",
    "    \"\"\"\n",
    "    # Costanti fisse importanti\n",
    "    fixed_constants = [\n",
    "        {'is_variable': False, 'value': 0.0, 'weight': 0.5},\n",
    "        {'is_variable': False, 'value': 1.0, 'weight': 0.5},\n",
    "        {'is_variable': False, 'value': -1.0, 'weight': 0.3},\n",
    "        {'is_variable': False, 'value': np.pi, 'weight': 0.2},\n",
    "        {'is_variable': False, 'value': np.e, 'weight': 0.2},\n",
    "    ]\n",
    "    \n",
    "    # Costanti casuali pre-generate\n",
    "    random_constants = [\n",
    "        {\n",
    "            'is_variable': False, \n",
    "            'value': random.uniform(-const_range, const_range), \n",
    "            'weight': 0.3\n",
    "        } for _ in range(n_constants)\n",
    "    ]\n",
    "    \n",
    "    return fixed_constants + random_constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6323bcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ephemeral_constant(const_range: float) -> float:\n",
    "    \"\"\"\n",
    "    Genera una costante casuale (ephemeral random constant)\n",
    "    Può essere chiamata durante l'inizializzazione dell'albero\n",
    "    \n",
    "    Args:\n",
    "        const_range: Range per le costanti casuali\n",
    "        \n",
    "    Returns:\n",
    "        Valore della costante generata\n",
    "    \"\"\"\n",
    "    return random.uniform(-const_range, const_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdd938e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPConfig:\n",
    "    \"\"\"Classe per gestire la configurazione dell'algoritmo GP\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 n_features: int,\n",
    "                 const_range: float,\n",
    "                 use_trig: bool = True,\n",
    "                 use_exp_log: bool = True,\n",
    "                 min_depth: int = 2,\n",
    "                 max_depth: int = 6,\n",
    "                 pop_size: int = 500,\n",
    "                 generations: int = 50,\n",
    "                 tournament_size: int = 5,\n",
    "                 crossover_prob: float = 0.7,\n",
    "                 mutation_prob: float = 0.2,\n",
    "                 elitism_rate: float = 0.1,\n",
    "                 max_tree_size: int = 50,\n",
    "                 parsimony_coef: float = 0.01,\n",
    "                 diversity_weight: float = 0.2):\n",
    "        \n",
    "        # Configurazione del set di funzioni e terminali\n",
    "        self.function_set = create_function_set(use_trig, use_exp_log)\n",
    "        self.variable_terminals = create_variable_terminals(n_features)\n",
    "        self.constant_terminals = create_constant_terminals(const_range)\n",
    "        \n",
    "        # Calcola pesi cumulativi per la selezione pesata\n",
    "        self._calculate_weights()\n",
    "        \n",
    "        # Limiti di dimensione dell'albero\n",
    "        self.min_depth = min_depth\n",
    "        self.max_depth = max_depth\n",
    "        self.max_tree_size = max_tree_size\n",
    "        \n",
    "        # Parametri dell'algoritmo evolutivo\n",
    "        self.pop_size = pop_size\n",
    "        self.generations = generations\n",
    "        self.tournament_size = tournament_size\n",
    "        self.crossover_prob = crossover_prob\n",
    "        self.mutation_prob = mutation_prob\n",
    "        self.elitism_rate = elitism_rate\n",
    "        \n",
    "        # Controllo del bloat e mantenimento diversità\n",
    "        self.parsimony_coef = parsimony_coef  # penalità per la complessità\n",
    "        self.diversity_weight = diversity_weight  # peso per la diversità\n",
    "        \n",
    "        # Altri parametri\n",
    "        self.n_features = n_features\n",
    "        self.const_range = const_range\n",
    "        \n",
    "    def _calculate_weights(self):\n",
    "        \"\"\"Calcola i pesi cumulativi per la selezione pesata di funzioni e terminali\"\"\"\n",
    "        # Pesi cumulativi per le funzioni\n",
    "        cum_weight = 0\n",
    "        self.function_weights = []\n",
    "        for func in self.function_set:\n",
    "            cum_weight += func['weight']\n",
    "            self.function_weights.append(cum_weight)\n",
    "        \n",
    "        # Normalizza i pesi\n",
    "        if cum_weight > 0:\n",
    "            self.function_weights = [w / cum_weight for w in self.function_weights]\n",
    "        \n",
    "        # Pesi cumulativi per i terminali variabili\n",
    "        cum_weight = 0\n",
    "        self.variable_weights = []\n",
    "        for var in self.variable_terminals:\n",
    "            cum_weight += var['weight']\n",
    "            self.variable_weights.append(cum_weight)\n",
    "        \n",
    "        # Normalizza i pesi\n",
    "        if cum_weight > 0:\n",
    "            self.variable_weights = [w / cum_weight for w in self.variable_weights]\n",
    "        \n",
    "        # Pesi cumulativi per i terminali costanti\n",
    "        cum_weight = 0\n",
    "        self.constant_weights = []\n",
    "        for const in self.constant_terminals:\n",
    "            cum_weight += const['weight']\n",
    "            self.constant_weights.append(cum_weight)\n",
    "        \n",
    "        # Normalizza i pesi\n",
    "        if cum_weight > 0:\n",
    "            self.constant_weights = [w / cum_weight for w in self.constant_weights]\n",
    "    \n",
    "    def get_random_function(self) -> Dict[str, Any]:\n",
    "        \"\"\"Seleziona casualmente una funzione dal set, basandosi sui pesi\"\"\"\n",
    "        r = random.random()\n",
    "        for i, w in enumerate(self.function_weights):\n",
    "            if r <= w:\n",
    "                return self.function_set[i]\n",
    "        return self.function_set[-1]  # fallback\n",
    "    \n",
    "    def get_random_variable(self) -> Dict[str, Any]:\n",
    "        \"\"\"Seleziona casualmente una variabile terminale dal set, basandosi sui pesi\"\"\"\n",
    "        if not self.variable_terminals:\n",
    "            raise ValueError(\"Non ci sono variabili disponibili\")\n",
    "        \n",
    "        r = random.random()\n",
    "        for i, w in enumerate(self.variable_weights):\n",
    "            if r <= w:\n",
    "                return self.variable_terminals[i]\n",
    "        return self.variable_terminals[-1]  # fallback\n",
    "    \n",
    "    def get_random_constant(self) -> Dict[str, Any]:\n",
    "        \"\"\"Seleziona casualmente una costante terminale dal set, basandosi sui pesi\"\"\"\n",
    "        if not self.constant_terminals:\n",
    "            # Genera una costante efimera se non ci sono constanti predefinite\n",
    "            return {'is_variable': False, 'value': generate_ephemeral_constant(self.const_range)}\n",
    "        \n",
    "        # Occasionalmente genera una nuova costante efimera anziché usarne una predefinita\n",
    "        if random.random() < 0.3:  # 30% di probabilità di generare una nuova costante\n",
    "            return {'is_variable': False, 'value': generate_ephemeral_constant(self.const_range)}\n",
    "        \n",
    "        # Altrimenti seleziona dalle costanti predefinite\n",
    "        r = random.random()\n",
    "        for i, w in enumerate(self.constant_weights):\n",
    "            if r <= w:\n",
    "                return self.constant_terminals[i]\n",
    "        return self.constant_terminals[-1]  # fallback\n",
    "    \n",
    "    def get_random_terminal(self) -> Dict[str, Any]:\n",
    "        \"\"\"Seleziona casualmente un terminale (variabile o costante)\"\"\"\n",
    "        # Probabilità di selezionare una variabile vs una costante\n",
    "        # In genere vogliamo dare più peso alle variabili\n",
    "        if random.random() < 0.7:  # 70% di probabilità di selezionare una variabile\n",
    "            try:\n",
    "                return self.get_random_variable()\n",
    "            except ValueError:\n",
    "                return self.get_random_constant()\n",
    "        else:\n",
    "            return self.get_random_constant()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b102241",
   "metadata": {},
   "source": [
    "### Initial Population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec8fc748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grow_tree(config: GPConfig, max_depth: int, min_depth: int = 1, current_depth: int = 0) -> Node:\n",
    "    \"\"\"\n",
    "    Metodo 'grow' per generare un albero con profondità variabile\n",
    "    \n",
    "    Args:\n",
    "        config: Configurazione del GP\n",
    "        max_depth: Profondità massima dell'albero\n",
    "        min_depth: Profondità minima dell'albero\n",
    "        current_depth: Profondità corrente del nodo\n",
    "        \n",
    "    Returns:\n",
    "        Nodo radice dell'albero generato\n",
    "    \"\"\"\n",
    "    # Se siamo alla profondità massima, creiamo solo nodi terminali\n",
    "    if current_depth >= max_depth:\n",
    "        terminal_info = config.get_random_terminal()\n",
    "        if terminal_info['is_variable']:\n",
    "            return TerminalNode(None, is_variable=True, var_index=terminal_info['var_index'])\n",
    "        else:\n",
    "            return TerminalNode(terminal_info['value'], is_variable=False)\n",
    "    \n",
    "    # Se non abbiamo ancora raggiunto la profondità minima, creiamo solo nodi funzione\n",
    "    if current_depth < min_depth:\n",
    "        function_info = config.get_random_function()\n",
    "        children = [grow_tree(config, max_depth, min_depth, current_depth + 1) for _ in range(function_info['arity'])]\n",
    "        return FunctionNode(function_info['function'], function_info['arity'], function_info['symbol'], children)\n",
    "    \n",
    "    # Altrimenti, scegliamo casualmente tra funzioni e terminali\n",
    "    if random.random() < 0.5:  # 50% di probabilità per funzioni o terminali\n",
    "        function_info = config.get_random_function()\n",
    "        children = [grow_tree(config, max_depth, min_depth, current_depth + 1) for _ in range(function_info['arity'])]\n",
    "        return FunctionNode(function_info['function'], function_info['arity'], function_info['symbol'], children)\n",
    "    else:\n",
    "        terminal_info = config.get_random_terminal()\n",
    "        if terminal_info['is_variable']:\n",
    "            return TerminalNode(None, is_variable=True, var_index=terminal_info['var_index'])\n",
    "        else:\n",
    "            return TerminalNode(terminal_info['value'], is_variable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc30d520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_tree(config: GPConfig, max_depth: int, current_depth: int = 0) -> Node:\n",
    "    \"\"\"\n",
    "    Metodo 'full' per generare un albero con tutti i rami alla stessa profondità\n",
    "    \n",
    "    Args:\n",
    "        config: Configurazione del GP\n",
    "        max_depth: Profondità massima dell'albero\n",
    "        current_depth: Profondità corrente del nodo\n",
    "        \n",
    "    Returns:\n",
    "        Nodo radice dell'albero generato\n",
    "    \"\"\"\n",
    "    # Se siamo alla profondità massima, creiamo solo nodi terminali\n",
    "    if current_depth >= max_depth:\n",
    "        terminal_info = config.get_random_terminal()\n",
    "        if terminal_info['is_variable']:\n",
    "            return TerminalNode(None, is_variable=True, var_index=terminal_info['var_index'])\n",
    "        else:\n",
    "            return TerminalNode(terminal_info['value'], is_variable=False)\n",
    "    \n",
    "    # Altrimenti, creiamo solo nodi funzione\n",
    "    function_info = config.get_random_function()\n",
    "    children = [full_tree(config, max_depth, current_depth + 1) for _ in range(function_info['arity'])]\n",
    "    return FunctionNode(function_info['function'], function_info['arity'], function_info['symbol'], children)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b52d2edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ramped_half_and_half(config: GPConfig, min_depth: int, max_depth: int) -> ExpressionTree:\n",
    "    \"\"\"\n",
    "    Metodo di inizializzazione 'ramped half-and-half'\n",
    "    Combina 'grow' e 'full' per una maggiore diversità\n",
    "    \n",
    "    Args:\n",
    "        config: Configurazione del GP\n",
    "        min_depth: Profondità minima degli alberi\n",
    "        max_depth: Profondità massima degli alberi\n",
    "        \n",
    "    Returns:\n",
    "        Un nuovo albero di espressione\n",
    "    \"\"\"\n",
    "    # Scegli una profondità casuale tra min_depth e max_depth\n",
    "    depth = random.randint(min_depth, max_depth)\n",
    "    \n",
    "    # Scegli casualmente tra 'grow' e 'full'\n",
    "    if random.random() < 0.5:\n",
    "        root = grow_tree(config, depth, min_depth)\n",
    "    else:\n",
    "        root = full_tree(config, depth)\n",
    "    \n",
    "    return ExpressionTree(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52eb95a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_population(config: GPConfig) -> List[ExpressionTree]:\n",
    "    \"\"\"\n",
    "    Crea la popolazione iniziale di alberi di espressione\n",
    "    \n",
    "    Args:\n",
    "        config: Configurazione del GP\n",
    "        \n",
    "    Returns:\n",
    "        Lista di alberi di espressione\n",
    "    \"\"\"\n",
    "    population = []\n",
    "    unique_expressions = set()  # Per il controllo dei duplicati\n",
    "    \n",
    "    print(f\"Inizializzazione popolazione di {config.pop_size} individui...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Continua a generare fino a quando non abbiamo abbastanza individui unici\n",
    "    while len(population) < config.pop_size:\n",
    "        tree = ramped_half_and_half(config, config.min_depth, config.max_depth)\n",
    "        \n",
    "        # Controllo dei duplicati (opzionale, ma aiuta la diversità iniziale)\n",
    "        expr_str = tree.to_string()\n",
    "        if expr_str not in unique_expressions:\n",
    "            unique_expressions.add(expr_str)\n",
    "            population.append(tree)\n",
    "            \n",
    "            # Aggiorniamo lo stato ogni 100 individui\n",
    "            if len(population) % 1000 == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print(f\"  Generati {len(population)} individui in {elapsed:.2f} secondi\")\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"Popolazione inizializzata in {elapsed:.2f} secondi\")\n",
    "    \n",
    "    # Statistiche sulla popolazione iniziale\n",
    "    heights = [tree.get_height() for tree in population]\n",
    "    sizes = [tree.get_complexity() for tree in population]\n",
    "    print(f\"Statistiche sulla popolazione iniziale:\")\n",
    "    print(f\"  - Altezza media: {np.mean(heights):.2f} (min: {min(heights)}, max: {max(heights)})\")\n",
    "    print(f\"  - Dimensione media: {np.mean(sizes):.2f} nodi (min: {min(sizes)}, max: {max(sizes)})\")\n",
    "    \n",
    "    return population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ea1ca6",
   "metadata": {},
   "source": [
    "### Fitness Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e30d6f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fitness(tree: ExpressionTree, X: np.ndarray, y: np.ndarray, \n",
    "                      parsimony_coef: float = 0.001) -> float:\n",
    "    \"\"\"\n",
    "    Calcola il fitness di un individuo\n",
    "    \n",
    "    Args:\n",
    "        tree: L'albero di espressione da valutare\n",
    "        X: Input features\n",
    "        y: Output target\n",
    "        parsimony_coef: Coefficiente di penalità per la complessità dell'albero\n",
    "        \n",
    "    Returns:\n",
    "        Valore di fitness (più basso è migliore)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Valuta l'albero sui dati di input        \n",
    "        predictions = tree.evaluate(X)        # Nel caso di valori NaN o infiniti, assegna un fitness molto alto (cattivo)\n",
    "        if np.any(np.isnan(predictions)) or np.any(np.isinf(predictions)):\n",
    "            return float('inf')\n",
    "        \n",
    "        # Calcola l'errore quadratico medio (MSE)\n",
    "        mse = np.mean((predictions - y) ** 2)\n",
    "        #Per il problema che stiamo affrontando, se la complessità è 1 (ovvero solo x[0] o x[1]),\n",
    "        # aggiungiamo una piccola penalità per incoraggiare soluzioni più complesse\n",
    "        #complexity = tree.get_complexity()\n",
    "        #if complexity <= 1:\n",
    "            # Penalizza leggermente le espressioni troppo semplici\n",
    "        #    complexity_penalty = parsimony_coef * max(3 - complexity, 0)\n",
    "        #else:\n",
    "            # Penalizza normalmente la complessità per espressioni più grandi\n",
    "        #    complexity_penalty = parsimony_coef * (complexity - 2)\n",
    "        \n",
    "        # Il fitness finale è MSE + penalità (più basso è migliore)\n",
    "        #fitness = mse + complexity_penalty\n",
    "        fitness = mse\n",
    "        return fitness\n",
    "    \n",
    "    except Exception as e:\n",
    "        # In caso di errori durante la valutazione, assegna un fitness molto alto\n",
    "        print(f\"Errore durante la valutazione: {e}\")\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d1cfbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_population(population: List[ExpressionTree], X: np.ndarray, y: np.ndarray, \n",
    "                       config: GPConfig) -> None:\n",
    "    \"\"\"\n",
    "    Valuta tutti gli individui della popolazione\n",
    "    \n",
    "    Args:\n",
    "        population: Lista di alberi di espressione\n",
    "        X: Input features\n",
    "        y: Output target\n",
    "        config: Configurazione del GP\n",
    "    \"\"\"\n",
    "    for i, tree in enumerate(population):\n",
    "        tree.fitness = calculate_fitness(tree, X, y, config.parsimony_coef)\n",
    "    \n",
    " \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9698616",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_fitness_sharing(population: List[ExpressionTree], sigma: float = 0.1) -> None:\n",
    "    \"\"\"\n",
    "    Applica fitness sharing per favorire la diversità nella popolazione\n",
    "    \n",
    "    Args:\n",
    "        population: Lista di alberi di espressione già valutati\n",
    "        sigma: Raggio del kernel di sharing\n",
    "    \"\"\"\n",
    "    n = len(population)\n",
    "    \n",
    "    # Prima calcola le distanze semantiche (o sintattiche)\n",
    "    for i in range(n):\n",
    "        # Inizializza il fattore di sharing\n",
    "        sharing_factor = 1.0\n",
    "        \n",
    "        # Calcola la distanza rispetto a tutti gli altri individui\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                # Qui si può usare una distanza sintattica o semantica\n",
    "                # Per semplicità, usiamo la distanza basata sulla stringa dell'espressione\n",
    "                expr_i = population[i].to_string()\n",
    "                expr_j = population[j].to_string()\n",
    "                \n",
    "                # Calcola una misura di somiglianza (0 = completamente diversi, 1 = identici)\n",
    "                # Si potrebbe usare una misura più sofisticata\n",
    "                similarity = len(set(expr_i) & set(expr_j)) / len(set(expr_i) | set(expr_j))\n",
    "                \n",
    "                # Se la somiglianza è maggiore di una certa soglia, incrementa il fattore di sharing\n",
    "                if similarity > 1 - sigma:\n",
    "                    # Formula di sharing: 1 - (d/sigma)^2 se d < sigma, 0 altrimenti\n",
    "                    d = 1 - similarity  # converte similarità in distanza\n",
    "                    sharing_factor += max(0, 1 - (d/sigma)**2)\n",
    "        \n",
    "        # Evita la divisione per zero\n",
    "        sharing_factor = min(10.0, max(1.0, sharing_factor))\n",
    "        \n",
    "        # Adjust fitness\n",
    "        if population[i].fitness != float('inf'):\n",
    "            population[i].adjusted_fitness = population[i].fitness * sharing_factor\n",
    "        else:\n",
    "            population[i].adjusted_fitness = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e1fde4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_semantic_distance(tree1: ExpressionTree, tree2: ExpressionTree, \n",
    "                               X_sample: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calcola la distanza semantica tra due alberi di espressione\n",
    "    basata sul comportamento su un campione di dati\n",
    "    \n",
    "    Args:\n",
    "        tree1, tree2: Alberi di espressione da confrontare\n",
    "        X_sample: Campione di dati di input per testare il comportamento\n",
    "        \n",
    "    Returns:\n",
    "        Distanza semantica (0 = comportamento identico)\n",
    "    \"\"\"\n",
    "    # Valutiamo gli alberi sul campione di dati\n",
    "    try:\n",
    "        output1 = tree1.evaluate(X_sample)\n",
    "        output2 = tree2.evaluate(X_sample)\n",
    "        \n",
    "        # Calcolo della distanza (errore quadratico medio)\n",
    "        if np.any(np.isnan(output1)) or np.any(np.isinf(output1)) or \\\n",
    "           np.any(np.isnan(output2)) or np.any(np.isinf(output2)):\n",
    "            return float('inf')\n",
    "        \n",
    "        # Normalizzazione degli output per confronto più equo\n",
    "        if np.std(output1) > 0 and np.std(output2) > 0:\n",
    "            output1 = (output1 - np.mean(output1)) / np.std(output1)\n",
    "            output2 = (output2 - np.mean(output2)) / np.std(output2)\n",
    "        \n",
    "        # Calcola distanza\n",
    "        return np.mean((output1 - output2) ** 2)\n",
    "    \n",
    "    except Exception:\n",
    "        # In caso di errori, consideriamo gli alberi molto distanti\n",
    "        return float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df07dec",
   "metadata": {},
   "source": [
    "### Selection Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b903d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tournament_selection(population: List[ExpressionTree], tournament_size: int, \n",
    "                         use_adjusted_fitness: bool = False) -> ExpressionTree:\n",
    "    \"\"\"\n",
    "    Seleziona un individuo tramite selezione a torneo\n",
    "    \n",
    "    Args:\n",
    "        population: Lista di alberi di espressione\n",
    "        tournament_size: Numero di partecipanti al torneo\n",
    "        use_adjusted_fitness: Se usare il fitness aggiustato per la diversità\n",
    "        \n",
    "    Returns:\n",
    "        L'individuo selezionato\n",
    "    \"\"\"\n",
    "    # Seleziona casualmente tournament_size individui dalla popolazione\n",
    "    contestants = random.sample(population, min(tournament_size, len(population)))\n",
    "    \n",
    "    # Trova l'individuo con il miglior fitness (il più basso)\n",
    "    if use_adjusted_fitness:\n",
    "        # Usa il fitness aggiustato per la diversità, se disponibile\n",
    "        best = min(contestants, key=lambda x: float('inf') if x.adjusted_fitness is None else x.adjusted_fitness)\n",
    "    else:\n",
    "        best = min(contestants, key=lambda x: float('inf') if x.fitness is None else x.fitness)\n",
    "    \n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5fa8ead4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_weighted_selection(population: List[ExpressionTree], \n",
    "                          max_age: int = 10, \n",
    "                          young_advantage: float = 0.3) -> ExpressionTree:\n",
    "    \"\"\"\n",
    "    Selezione che favorisce individui più giovani (con minore età)\n",
    "    \n",
    "    Args:\n",
    "        population: Lista di alberi di espressione\n",
    "        max_age: Età massima considerata per il vantaggio\n",
    "        young_advantage: Vantaggio percentuale per individui giovani\n",
    "        \n",
    "    Returns:\n",
    "        L'individuo selezionato\n",
    "    \"\"\"\n",
    "    # Calcola pesi basati sull'età\n",
    "    age_weights = [max(0.1, 1.0 - (tree.age / max_age) * young_advantage) \n",
    "                  for tree in population]\n",
    "    \n",
    "    # Normalizza i pesi\n",
    "    total_weight = sum(age_weights)\n",
    "    if total_weight > 0:\n",
    "        norm_weights = [w / total_weight for w in age_weights]\n",
    "    else:\n",
    "        norm_weights = [1.0 / len(population)] * len(population)\n",
    "    \n",
    "    # Selezione pesata\n",
    "    return random.choices(population, weights=norm_weights, k=1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9fb667ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diversity_tournament_selection(population: List[ExpressionTree], \n",
    "                                  X_sample: np.ndarray,\n",
    "                                  tournament_size: int = 5, \n",
    "                                  diversity_weight: float = 0.3) -> ExpressionTree:\n",
    "    \"\"\"\n",
    "    Selezione a torneo che considera sia il fitness che la diversità semantica\n",
    "    \n",
    "    Args:\n",
    "        population: Lista di alberi di espressione\n",
    "        X_sample: Campione di dati per calcolare il comportamento semantico\n",
    "        tournament_size: Numero di partecipanti al torneo\n",
    "        diversity_weight: Peso dato alla diversità (vs. fitness)\n",
    "        \n",
    "    Returns:\n",
    "        L'individuo selezionato\n",
    "    \"\"\"\n",
    "    if len(population) <= 1:\n",
    "        return population[0]\n",
    "    \n",
    "    # Seleziona casualmente tournament_size individui\n",
    "    contestants = random.sample(population, min(tournament_size, len(population)))\n",
    "    \n",
    "    # Trova i punteggi di fitness (normalizzati)\n",
    "    fitness_values = [tree.fitness for tree in contestants]\n",
    "    max_fitness = max(fitness_values)\n",
    "    min_fitness = min(fitness_values)\n",
    "    fitness_range = max_fitness - min_fitness\n",
    "    \n",
    "    if fitness_range > 0:\n",
    "        norm_fitness = [(f - min_fitness) / fitness_range for f in fitness_values]\n",
    "    else:\n",
    "        norm_fitness = [0.5] * len(contestants)\n",
    "    \n",
    "    # Calcola la diversità di ogni individuo rispetto alla popolazione\n",
    "    diversity_scores = []\n",
    "    \n",
    "    for i, tree in enumerate(contestants):\n",
    "        diversity = 0\n",
    "        valid_comparisons = 0\n",
    "        \n",
    "        # Confronta con un campione casuale della popolazione per efficienza\n",
    "        population_sample = random.sample(population, min(10, len(population)))\n",
    "        \n",
    "        for other in population_sample:\n",
    "            if tree != other:\n",
    "                dist = calculate_semantic_distance(tree, other, X_sample)\n",
    "                if dist != float('inf'):\n",
    "                    diversity += dist\n",
    "                    valid_comparisons += 1\n",
    "        \n",
    "        # Media delle distanze o valore predefinito se non ci sono confronti validi\n",
    "        if valid_comparisons > 0:\n",
    "            diversity_scores.append(diversity / valid_comparisons)\n",
    "        else:\n",
    "            diversity_scores.append(0.0)\n",
    "    \n",
    "    # Normalizza i punteggi di diversità\n",
    "    max_div = max(diversity_scores) if diversity_scores else 1.0\n",
    "    min_div = min(diversity_scores) if diversity_scores else 0.0\n",
    "    div_range = max_div - min_div\n",
    "    \n",
    "    if div_range > 0:\n",
    "        norm_diversity = [(d - min_div) / div_range for d in diversity_scores]\n",
    "    else:\n",
    "        norm_diversity = [0.5] * len(contestants)\n",
    "    \n",
    "    # Combina fitness e diversità per un punteggio totale\n",
    "    # Più alto è migliore (quindi invertiamo il fitness normalizzato)\n",
    "    total_scores = [(1 - nf) * (1 - diversity_weight) + nd * diversity_weight \n",
    "                   for nf, nd in zip(norm_fitness, norm_diversity)]\n",
    "    \n",
    "    # Seleziona l'individuo con il miglior punteggio totale\n",
    "    best_idx = total_scores.index(max(total_scores))\n",
    "    return contestants[best_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3be03a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_parents(population: List[ExpressionTree], config: GPConfig, \n",
    "                  X_sample: np.ndarray) -> Tuple[ExpressionTree, ExpressionTree]:\n",
    "    \"\"\"\n",
    "    Seleziona due genitori dalla popolazione\n",
    "    \n",
    "    Args:\n",
    "        population: Lista di alberi di espressione\n",
    "        config: Configurazione del GP\n",
    "        X_sample: Campione di dati per calcolare la diversità semantica\n",
    "        \n",
    "    Returns:\n",
    "        Coppia di genitori\n",
    "    \"\"\"\n",
    "    # Scegliamo casualmente il metodo di selezione\n",
    "    selection_r = random.random()\n",
    "    \n",
    "    if selection_r < 0.9:  # 90% probabilità di usare il torneo standard con adjusted fitness\n",
    "        parent1 = tournament_selection(population, config.tournament_size, use_adjusted_fitness=True)\n",
    "        parent2 = tournament_selection(population, config.tournament_size, use_adjusted_fitness=True)\n",
    "    else:  # 10% probabilità di usare selezione basata sull'età\n",
    "        parent1 = age_weighted_selection(population)\n",
    "        parent2 = age_weighted_selection(population)\n",
    "    \n",
    "    # Assicurati che i genitori siano diversi\n",
    "    attempts = 0\n",
    "    while parent1 == parent2 and attempts < 5:\n",
    "        parent2 = tournament_selection(population, config.tournament_size)\n",
    "        attempts += 1\n",
    "    \n",
    "    return parent1, parent2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eda1b96",
   "metadata": {},
   "source": [
    "### Genetic Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "026db31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtree_crossover(parent1: ExpressionTree, parent2: ExpressionTree, \n",
    "                     max_tries: int = 5, max_depth: int = 10) -> Tuple[ExpressionTree, ExpressionTree]:\n",
    "    \"\"\"\n",
    "    Crossover per alberi: scambia sottoalberi tra i genitori\n",
    "    \n",
    "    Args:\n",
    "        parent1, parent2: Alberi genitori\n",
    "        max_tries: Numero massimo di tentativi per trovare punti di crossover validi\n",
    "        max_depth: Profondità massima consentita per l'albero risultante\n",
    "        \n",
    "    Returns:\n",
    "        Due alberi figli generati dal crossover\n",
    "    \"\"\"\n",
    "    # Creiamo copie dei genitori\n",
    "    child1 = parent1.copy()\n",
    "    child2 = parent2.copy()\n",
    "    \n",
    "    # Ottieni tutti i nodi negli alberi\n",
    "    nodes1 = child1.get_nodes()\n",
    "    nodes2 = child2.get_nodes()\n",
    "    \n",
    "    if not nodes1 or not nodes2:\n",
    "        return child1, child2  # Non possiamo fare crossover se uno degli alberi è vuoto\n",
    "    \n",
    "    # Tenta il crossover per un numero limitato di volte\n",
    "    for _ in range(max_tries):\n",
    "        # Scegli casualmente i punti di crossover\n",
    "        crossover_point1 = random.randrange(len(nodes1))\n",
    "        crossover_point2 = random.randrange(len(nodes2))\n",
    "        \n",
    "        # Ottieni i sottoalberi\n",
    "        subtree1 = nodes1[crossover_point1]\n",
    "        subtree2 = nodes2[crossover_point2]\n",
    "        \n",
    "        # Crea copie dei sottoalberi\n",
    "        subtree1_copy = subtree1.copy()\n",
    "        subtree2_copy = subtree2.copy()\n",
    "        \n",
    "        # Sostituisci i sottoalberi\n",
    "        child1.replace_subtree_at_index(crossover_point1, subtree2_copy)\n",
    "        child2.replace_subtree_at_index(crossover_point2, subtree1_copy)\n",
    "        \n",
    "        # Aggiorna le profondità dei nodi\n",
    "        child1.update_node_depths()\n",
    "        child2.update_node_depths()\n",
    "        \n",
    "        # Controlla se i figli rispettano il vincolo di profondità massima\n",
    "        if child1.get_height() <= max_depth and child2.get_height() <= max_depth:\n",
    "            # Crossover riuscito\n",
    "            break\n",
    "        else:\n",
    "            # Ripristina i figli dalle copie dei genitori\n",
    "            child1 = parent1.copy()\n",
    "            child2 = parent2.copy()\n",
    "            nodes1 = child1.get_nodes()\n",
    "            nodes2 = child2.get_nodes()\n",
    "    \n",
    "    # Incrementa l'età\n",
    "    child1.age = 0\n",
    "    child2.age = 0\n",
    "    \n",
    "    return child1, child2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2c818b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtree_mutation(tree: ExpressionTree, config: GPConfig, \n",
    "                    max_depth: int = 10) -> ExpressionTree:\n",
    "    \"\"\"\n",
    "    Mutazione di sottoalbero: sostituisce un sottoalbero casuale con uno nuovo\n",
    "    \n",
    "    Args:\n",
    "        tree: Albero da mutare\n",
    "        config: Configurazione del GP\n",
    "        max_depth: Profondità massima consentita per l'albero risultante\n",
    "        \n",
    "    Returns:\n",
    "        Albero mutato\n",
    "    \"\"\"\n",
    "    # Crea una copia dell'albero\n",
    "    mutated = tree.copy()\n",
    "    \n",
    "    # Ottieni tutti i nodi nell'albero\n",
    "    nodes = mutated.get_nodes()\n",
    "    \n",
    "    if not nodes:\n",
    "        return mutated  # Non possiamo mutare un albero vuoto\n",
    "    \n",
    "    # Scegli casualmente un punto di mutazione\n",
    "    mutation_point = random.randrange(len(nodes))\n",
    "    \n",
    "    # Calcola la profondità massima per il nuovo sottoalbero\n",
    "    node_depth = nodes[mutation_point].depth\n",
    "    remaining_depth = max_depth - node_depth\n",
    "    \n",
    "    if remaining_depth < 1:\n",
    "        return mutated  # Non possiamo mutare se non c'è spazio per crescere\n",
    "    \n",
    "    # Genera un nuovo sottoalbero casuale\n",
    "    new_subtree = grow_tree(config, remaining_depth, min_depth=1)\n",
    "    \n",
    "    # Sostituisci il sottoalbero\n",
    "    mutated.replace_subtree_at_index(mutation_point, new_subtree)\n",
    "    \n",
    "    # Aggiorna le profondità dei nodi\n",
    "    mutated.update_node_depths()\n",
    "    \n",
    "    # Resetta l'età\n",
    "    mutated.age = 0\n",
    "    \n",
    "    return mutated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cdedbc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_mutation(tree: ExpressionTree, config: GPConfig) -> ExpressionTree:\n",
    "    \"\"\"\n",
    "    Mutazione puntuale: cambia un singolo nodo mantenendo la struttura dell'albero\n",
    "    \n",
    "    Args:\n",
    "        tree: Albero da mutare\n",
    "        config: Configurazione del GP\n",
    "        \n",
    "    Returns:\n",
    "        Albero mutato\n",
    "    \"\"\"\n",
    "    # Crea una copia dell'albero\n",
    "    mutated = tree.copy()\n",
    "    \n",
    "    # Ottieni tutti i nodi nell'albero\n",
    "    nodes = mutated.get_nodes()\n",
    "    \n",
    "    if not nodes:\n",
    "        return mutated  # Non possiamo mutare un albero vuoto\n",
    "    \n",
    "    # Scegli casualmente un punto di mutazione\n",
    "    mutation_point = random.randrange(len(nodes))\n",
    "    node = nodes[mutation_point]\n",
    "    \n",
    "    # Mutazione basata sul tipo di nodo\n",
    "    if isinstance(node, FunctionNode):\n",
    "        # Sostituisci con un'altra funzione della stessa arità\n",
    "        compatible_functions = [f for f in config.function_set if f['arity'] == node.arity]\n",
    "        if compatible_functions:\n",
    "            function_info = random.choice(compatible_functions)\n",
    "            new_node = FunctionNode(function_info['function'], \n",
    "                                   function_info['arity'], \n",
    "                                   function_info['symbol'],\n",
    "                                   node.children.copy())  # riutilizza gli stessi figli\n",
    "            \n",
    "            # Sostituisci il nodo\n",
    "            mutated.replace_subtree_at_index(mutation_point, new_node)\n",
    "    \n",
    "    elif isinstance(node, TerminalNode):\n",
    "        if node.is_variable:\n",
    "            # Sostituisci con un'altra variabile\n",
    "            if len(config.variable_terminals) > 1:\n",
    "                terminal_info = config.get_random_variable()\n",
    "                while terminal_info['var_index'] == node.var_index:\n",
    "                    terminal_info = config.get_random_variable()\n",
    "                \n",
    "                new_node = TerminalNode(None, True, terminal_info['var_index'])\n",
    "                mutated.replace_subtree_at_index(mutation_point, new_node)\n",
    "        else:\n",
    "            # Potremmo sostituire con un'altra costante o modificare leggermente il valore\n",
    "            if random.random() < 0.5:  # 50% probabilità di modificare il valore\n",
    "                # Modifica il valore esistente (small perturbation)\n",
    "                new_value = node.value * (1.0 + random.uniform(-0.1, 0.1))\n",
    "                new_node = TerminalNode(new_value, False)\n",
    "            else:\n",
    "                # Sostituisci con una nuova costante\n",
    "                terminal_info = config.get_random_constant()\n",
    "                new_node = TerminalNode(terminal_info['value'], False)\n",
    "            \n",
    "            mutated.replace_subtree_at_index(mutation_point, new_node)\n",
    "    \n",
    "    # Aggiorna le profondità dei nodi\n",
    "    mutated.update_node_depths()\n",
    "    \n",
    "    # Resetta l'età\n",
    "    mutated.age = 0\n",
    "    \n",
    "    return mutated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ec9a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deterministic_crowding(parent1: ExpressionTree, parent2: ExpressionTree,\n",
    "                          child1: ExpressionTree, child2: ExpressionTree,\n",
    "                          X: np.ndarray, y: np.ndarray, config: GPConfig) -> List[ExpressionTree]:\n",
    "    \"\"\"\n",
    "    Deterministic crowding: i figli sostituiscono i genitori solo se hanno fitness migliore\n",
    "    \n",
    "    Args:\n",
    "        parent1, parent2: Genitori\n",
    "        child1, child2: Figli generati dai genitori\n",
    "        X, y: Dati per la valutazione\n",
    "        config: Configurazione del GP\n",
    "        \n",
    "    Returns:\n",
    "        Lista di individui selezionati\n",
    "    \"\"\"\n",
    "    # Calcola il fitness dei figli\n",
    "    child1.fitness = calculate_fitness(child1, X, y, config.parsimony_coef)\n",
    "    child2.fitness = calculate_fitness(child2, X, y, config.parsimony_coef)\n",
    "    \n",
    "    # Applica fitness sharing ai figli\n",
    "    # Possiamo creare una piccola popolazione temporanea con i figli per calcolare il loro adjusted_fitness\n",
    "    temp_pop = [parent1, parent2, child1, child2]\n",
    "    apply_fitness_sharing(temp_pop)\n",
    "\n",
    "    # Calcola similarità tra genitori e figli\n",
    "    X_sample = X[:min(len(X), 100)]  # Usa un campione per efficienza\n",
    "    \n",
    "    dist_p1c1 = calculate_semantic_distance(parent1, child1, X_sample)\n",
    "    dist_p1c2 = calculate_semantic_distance(parent1, child2, X_sample)\n",
    "    \n",
    "    # Decidi quali abbinamenti genitore-figlio confrontare\n",
    "    if dist_p1c1 <= dist_p1c2:\n",
    "        # parent1 vs child1, parent2 vs child2\n",
    "        competition1 = (parent1, child1)\n",
    "        competition2 = (parent2, child2)\n",
    "    else:\n",
    "        # parent1 vs child2, parent2 vs child1\n",
    "        competition1 = (parent1, child2)\n",
    "        competition2 = (parent2, child1)\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    # Prima competizione\n",
    "    if competition1[1].adjusted_fitness <= competition1[0].adjusted_fitness:\n",
    "        result.append(competition1[1])  # Il figlio vince\n",
    "    else:\n",
    "        result.append(competition1[0])  # Il genitore vince\n",
    "    \n",
    "    # Seconda competizione\n",
    "    if competition2[1].adjusted_fitness <= competition2[0].adjusted_fitness:\n",
    "        result.append(competition2[1])  # Il figlio vince\n",
    "    else:\n",
    "        result.append(competition2[0])  # Il genitore vince\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54d457",
   "metadata": {},
   "source": [
    "###  Genetic Operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16152735",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_genetic_operators(population: List[ExpressionTree], X: np.ndarray, y: np.ndarray, \n",
    "                           config: GPConfig) -> List[ExpressionTree]:\n",
    "    \"\"\"\n",
    "    Applica operatori genetici per creare una nuova popolazione\n",
    "    \n",
    "    Args:\n",
    "        population: Lista di alberi di espressione\n",
    "        X, y: Dati per la valutazione\n",
    "        config: Configurazione del GP\n",
    "        \n",
    "    Returns:\n",
    "        Nuova popolazione\n",
    "    \"\"\"\n",
    "    # Ordina la popolazione per fitness (migliore al primo posto)\n",
    "    sorted_population = sorted(population, key=lambda x: float('inf') if x.adjusted_fitness is None else x.adjusted_fitness)\n",
    "    \n",
    "    # Numero di individui da selezionare tramite elitismo\n",
    "    n_elite = int(config.pop_size * config.elitism_rate)\n",
    "    \n",
    "    # Campione per calcolare diversità semantica\n",
    "    X_sample = X[:min(len(X), 100)]  # Usa un campione per efficienza\n",
    "    \n",
    "    # Seleziona gli elite\n",
    "    new_population = [tree.copy() for tree in sorted_population[:n_elite]]\n",
    "    \n",
    "    # Incrementa l'età di ogni individuo elite\n",
    "    for tree in new_population:\n",
    "        tree.age += 1\n",
    "    \n",
    "    # Completa la popolazione con nuovi individui\n",
    "    while len(new_population) < config.pop_size:\n",
    "        # Seleziona operazione genetica (crossover o mutazione)\n",
    "        op_choice = random.random()\n",
    "        \n",
    "        if op_choice < config.crossover_prob:\n",
    "            # Crossover\n",
    "            parent1, parent2 = select_parents(population, config, X_sample)\n",
    "            child1, child2 = subtree_crossover(parent1, parent2, max_depth=config.max_depth)\n",
    "            \n",
    "            # Usa deterministic crowding per decidere quali individui tenere\n",
    "            selected = deterministic_crowding(parent1, parent2, child1, child2, X, y, config)\n",
    "            \n",
    "            # Aggiungi alla nuova popolazione\n",
    "            new_population.extend(selected)\n",
    "            if len(new_population) > config.pop_size:\n",
    "                new_population = new_population[:config.pop_size]\n",
    "        \n",
    "        elif op_choice < config.crossover_prob + config.mutation_prob:\n",
    "            # Mutazione\n",
    "            parent = tournament_selection(population, config.tournament_size)\n",
    "            \n",
    "            # Scegli casualmente il tipo di mutazione\n",
    "            mutation_choice = random.random()\n",
    "            \n",
    "            if mutation_choice < 0.7:  # 70% subtree mutation\n",
    "                child = subtree_mutation(parent, config, max_depth=config.max_depth)\n",
    "            else:  # 30% point mutation\n",
    "                child = point_mutation(parent, config)\n",
    "            \n",
    "            # Calcola fitness del figlio\n",
    "            child.fitness = calculate_fitness(child, X, y, config.parsimony_coef)\n",
    "            temp_pop = [parent, child]\n",
    "            apply_fitness_sharing(temp_pop)\n",
    "            # Confronta genitore e figlio\n",
    "            if child.adjusted_fitness <= parent.adjusted_fitness:\n",
    "                new_population.append(child)\n",
    "            else:\n",
    "                # Aggiungi comunque il figlio con una certa probabilità\n",
    "                if random.random() < 0.1:  # 10% di probabilità\n",
    "                    new_population.append(child)\n",
    "                else:\n",
    "                    new_population.append(parent.copy())\n",
    "        \n",
    "        else:\n",
    "            # Riproduzione (copia diretta)\n",
    "            parent = tournament_selection(population, config.tournament_size)\n",
    "            offspring = parent.copy()\n",
    "            offspring.age += 1  # Incrementa l'età\n",
    "            new_population.append(offspring)\n",
    "    \n",
    "    # Assicurati che la popolazione abbia esattamente la dimensione richiesta\n",
    "    if len(new_population) > config.pop_size:\n",
    "        new_population = new_population[:config.pop_size]\n",
    "    \n",
    "    # Aggiorna il fitness adjusted per diversità\n",
    "    apply_fitness_sharing(new_population)\n",
    "    \n",
    "    return new_population"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4358633",
   "metadata": {},
   "source": [
    "### Diversity Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "505d6125",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Island:\n",
    "    \"\"\"Rappresenta un'isola nell'Island Model\"\"\"\n",
    "    \n",
    "    def __init__(self, population: List[ExpressionTree], config: GPConfig, island_id: int):\n",
    "        self.population = population\n",
    "        self.config = config\n",
    "        self.id = island_id\n",
    "        self.best_individual = None\n",
    "        self.best_fitness = float('inf')\n",
    "        self.generations_without_improvement = 0\n",
    "    \n",
    "    def evolve(self, X: np.ndarray, y: np.ndarray, generation: int) -> None:\n",
    "        \"\"\"\n",
    "        Evolve l'isola per una generazione\n",
    "        \n",
    "        Args:\n",
    "            X, y: Dati di training\n",
    "            generation: Numero della generazione corrente\n",
    "        \"\"\"\n",
    "        # Applica operatori genetici\n",
    "        self.population = apply_genetic_operators(self.population, X, y, self.config)\n",
    "\n",
    "         # Valuta la popolazione\n",
    "        #evaluate_population(self.population, X, y, self.config) \n",
    "\n",
    "        # Applica fitness sharing per mantenere la diversità\n",
    "        #apply_fitness_sharing(self.population)\n",
    "        \n",
    "        # Aggiorna la miglior soluzione\n",
    "        current_best = min(self.population, key=lambda x: float('inf') if x.adjusted_fitness is None else x.adjusted_fitness)\n",
    "        if current_best.adjusted_fitness < self.best_fitness:\n",
    "            self.best_individual = current_best.copy()\n",
    "            self.best_fitness = current_best.adjusted_fitness\n",
    "            self.generations_without_improvement = 0\n",
    "        else:\n",
    "            self.generations_without_improvement += 1\n",
    "        \n",
    "        # Log dei progressi\n",
    "        if generation % 5 == 0:  # Ogni 5 generazioni\n",
    "            ic(f\"Isola {self.id}\", f\"Gen {generation}\", self.best_fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcd731c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_islands(total_population: List[ExpressionTree], config: GPConfig, n_islands: int = 3) -> List[Island]:\n",
    "    \"\"\"\n",
    "    Inizializza le isole dividendo la popolazione\n",
    "    \n",
    "    Args:\n",
    "        total_population: Lista completa di alberi di espressione\n",
    "        config: Configurazione del GP\n",
    "        n_islands: Numero di isole da creare\n",
    "        \n",
    "    Returns:\n",
    "        Lista di oggetti Island\n",
    "    \"\"\"\n",
    "    islands = []\n",
    "    # Mescola casualmente la popolazione\n",
    "    shuffled_population = random.sample(total_population, len(total_population))\n",
    "    \n",
    "    # Calcola la dimensione di ciascuna isola\n",
    "    island_size = len(shuffled_population ) // n_islands\n",
    "    \n",
    "    # Distribuisci la popolazione tra le isole\n",
    "    for i in range(n_islands):\n",
    "        start_idx = i * island_size\n",
    "        end_idx = start_idx + island_size if i < n_islands - 1 else len(shuffled_population)\n",
    "        island_population = shuffled_population[start_idx:end_idx]\n",
    "        \n",
    "        # Crea configurazione specifica per l'isola\n",
    "        island_config = copy.deepcopy(config)\n",
    "        island_config.pop_size = len(island_population)\n",
    "        \n",
    "        # Crea l'isola\n",
    "        island = Island(island_population, island_config, i)\n",
    "        islands.append(island)\n",
    "    \n",
    "    return islands\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d31ecff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def migration(islands: List[Island], migration_rate: float = 0.2) -> None:\n",
    "    \"\"\"\n",
    "    Permette la migrazione di individui tra isole\n",
    "    \n",
    "    Args:\n",
    "        islands: Lista di oggetti Island\n",
    "        migration_rate: Percentuale di popolazione che migra\n",
    "    \"\"\"\n",
    "    if len(islands) <= 1:\n",
    "        return\n",
    "    \n",
    "    print(\"Esecuzione migrazione tra isole...\")\n",
    "    \n",
    "    for i, source_island in enumerate(islands):\n",
    "        # Calcola l'isola di destinazione (la successiva, o la prima se è l'ultima)\n",
    "        dest_idx = (i + 1) % len(islands)\n",
    "        dest_island = islands[dest_idx]\n",
    "        \n",
    "        # Numero di individui da migrare\n",
    "        n_migrants = max(1, int(source_island.config.pop_size * migration_rate))\n",
    "        \n",
    "        # Seleziona i migranti (metà migliori, metà casuali)\n",
    "        n_best = n_migrants // 2\n",
    "        n_random = n_migrants - n_best\n",
    "        \n",
    "        # Ordina per fitness\n",
    "        sorted_pop = sorted(source_island.population, \n",
    "                          key=lambda x: float('inf') if x.adjusted_fitness is None else x.adjusted_fitness)\n",
    "        \n",
    "        # Prendi i migliori\n",
    "        migrants_best = [ind.copy() for ind in sorted_pop[:n_best]]\n",
    "        \n",
    "        # Prendi alcuni casuali\n",
    "        migrants_random = [ind.copy() for ind in random.sample(source_island.population, n_random)]\n",
    "        \n",
    "        migrants = migrants_best + migrants_random\n",
    "        \n",
    "        # Sostituisci i peggiori nell'isola di destinazione\n",
    "        dest_sorted = sorted(dest_island.population, \n",
    "                           key=lambda x: float('inf') if x.adjusted_fitness is None else x.adjusted_fitness, \n",
    "                           reverse=True)  # ordine decrescente\n",
    "        \n",
    "        # Rimuovi i peggiori\n",
    "        for j in range(min(n_migrants, len(dest_sorted))):\n",
    "            dest_island.population.remove(dest_sorted[j])\n",
    "        \n",
    "        # Aggiungi i migranti\n",
    "        dest_island.population.extend(migrants)\n",
    "        \n",
    "        print(f\"  Migrazione: {n_migrants} individui dall'isola {i} all'isola {dest_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f1939a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_novelty_search(population: List[ExpressionTree], X: np.ndarray, \n",
    "                        archive_size: int = 10) -> None:\n",
    "    \"\"\"\n",
    "    Applica novelty search per promuovere la diversità\n",
    "    \n",
    "    Args:\n",
    "        population: Lista di alberi di espressione\n",
    "        X: Dati di input per calcolare il comportamento\n",
    "        archive_size: Dimensione dell'archivio delle novità\n",
    "    \"\"\"\n",
    "    # Campione per calcolare il comportamento\n",
    "    X_sample = X[:min(len(X), 100)]\n",
    "    \n",
    "    # Calcola il \"comportamento\" di ogni individuo\n",
    "    behaviors = []\n",
    "    for tree in population:\n",
    "        try:\n",
    "            # Usiamo l'output su X_sample come comportamento\n",
    "            behavior = tree.evaluate(X_sample)\n",
    "            behaviors.append(behavior)\n",
    "        except:\n",
    "            # In caso di errori usiamo un vettore di zeri\n",
    "            behaviors.append(np.zeros(len(X_sample)))\n",
    "    \n",
    "    # Calcola la novelty score per ogni individuo\n",
    "    k = min(5, len(population) - 1)  # numero di vicini più prossimi\n",
    "    \n",
    "    for i, tree in enumerate(population):\n",
    "        # Calcola distanze rispetto a tutti gli altri\n",
    "        distances = []\n",
    "        for j, other_behavior in enumerate(behaviors):\n",
    "            if i != j:\n",
    "                # Distanza del comportamento\n",
    "                dist = np.mean((behaviors[i] - other_behavior) ** 2)\n",
    "                distances.append(dist)\n",
    "        \n",
    "        # Calcola la novità come media delle k distanze più piccole\n",
    "        if distances:\n",
    "            distances.sort()\n",
    "            novelty = np.mean(distances[:k])\n",
    "            # Aggiungi la novità al fitness adjusted\n",
    "            if tree.adjusted_fitness is not None and tree.adjusted_fitness != float('inf'):\n",
    "                # Combina fitness e novità (più basso è meglio per fitness, più alto è meglio per novità)\n",
    "                tree.adjusted_fitness = tree.adjusted_fitness * (1.0 - 0.2 / (1.0 + novelty))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c8be6f",
   "metadata": {},
   "source": [
    "### Bloat Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18881137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bloat_control(population: List[ExpressionTree], config: GPConfig) -> None:\n",
    "    \"\"\"\n",
    "    Applica varie tecniche di controllo del bloat\n",
    "    \n",
    "    Args:\n",
    "        population: Lista di alberi di espressione\n",
    "        config: Configurazione del GP\n",
    "    \"\"\"\n",
    "    # Controllo della dimensione massima\n",
    "    oversized = [i for i, tree in enumerate(population) if tree.get_complexity() > config.max_tree_size]\n",
    "    \n",
    "    if oversized:\n",
    "        print(f\"Controllo del bloat: {len(oversized)} individui superano la dimensione massima\")\n",
    "        \n",
    "        for idx in oversized:\n",
    "            # Tenta di ridurre la dimensione sostituendo sottoalberi con terminali\n",
    "            tree = population[idx]\n",
    "            nodes = tree.get_nodes()\n",
    "            \n",
    "            # Trova nodi non terminali a profondità maggiore\n",
    "            non_terminal_nodes = [i for i, node in enumerate(nodes) \n",
    "                                if isinstance(node, FunctionNode) and node.depth > 2]\n",
    "            \n",
    "            if non_terminal_nodes:\n",
    "                # Sostituisci un nodo casuale con un terminale\n",
    "                node_idx = random.choice(non_terminal_nodes)\n",
    "                \n",
    "                # Crea un nuovo nodo terminale\n",
    "                terminal_info = config.get_random_terminal()\n",
    "                if terminal_info['is_variable']:\n",
    "                    new_node = TerminalNode(None, True, terminal_info['var_index'])\n",
    "                else:\n",
    "                    new_node = TerminalNode(terminal_info['value'], False)\n",
    "                \n",
    "                # Sostituisci il sottoalbero\n",
    "                tree.replace_subtree_at_index(node_idx, new_node)\n",
    "                tree.update_node_depths()\n",
    "    \n",
    "    # Applica lexicographic parsimony pressure\n",
    "    # Quando due individui hanno fitness simili, preferisce quello più semplice\n",
    "    epsilon = 0.0000001  # soglia per considerare fitness simili\n",
    "    \n",
    "    for i in range(len(population)):\n",
    "        for j in range(i + 1, len(population)):\n",
    "            tree_i = population[i]\n",
    "            tree_j = population[j]\n",
    "            \n",
    "            # Se i fitness sono simili\n",
    "            if abs(tree_i.adjusted_fitness - tree_j.adjusted_fitness) < epsilon:\n",
    "                # Ottieni complessità\n",
    "                complexity_i = tree_i.get_complexity()\n",
    "                complexity_j = tree_j.get_complexity()\n",
    "                \n",
    "                # Se l'albero j è significativamente più complesso, penalizzarlo\n",
    "                if complexity_j > complexity_i * 1.5:\n",
    "                    # Aggiungi una piccola penalità al fitness\n",
    "                    tree_j.adjusted_fitness += epsilon\n",
    "                \n",
    "                # Se l'albero i è significativamente più complesso, penalizzarlo\n",
    "                elif complexity_i > complexity_j * 1.5:\n",
    "                    # Aggiungi una piccola penalità al fitness\n",
    "                    tree_i.adjusted_fitness += epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63257b48",
   "metadata": {},
   "source": [
    "### Princial Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61327cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic_programming(X: np.ndarray, y: np.ndarray, config: GPConfig, \n",
    "                       use_islands: bool = False, n_islands: int = 5, \n",
    "                       migration_interval: int = 100) -> ExpressionTree:\n",
    "    \"\"\"\n",
    "    Algoritmo principale di Genetic Programming per Symbolic Regression\n",
    "    \n",
    "    Args:\n",
    "        X: Input features\n",
    "        y: Output target\n",
    "        config: Configurazione del GP\n",
    "        use_islands: Se usare il modello a isole\n",
    "        n_islands: Numero di isole (se use_islands è True)\n",
    "        migration_interval: Intervallo di generazioni tra migrazioni\n",
    "        \n",
    "    Returns:\n",
    "        Il miglior albero di espressione trovato\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    print(f\"Avvio Genetic Programming per Symbolic Regression...\")\n",
    "    print(f\"Configurazione: pop_size={config.pop_size}, max_depth={config.max_depth}, \"\n",
    "          f\"generations={config.generations}\")\n",
    "    \n",
    "    # Inizializza la popolazione\n",
    "    initial_population = initialize_population(config)\n",
    "    \n",
    "\n",
    "    # Valuta la popolazione iniziale\n",
    "    evaluate_population(initial_population, X, y, config)\n",
    "    \n",
    "    # Applica fitness sharing per diversità\n",
    "    apply_fitness_sharing(initial_population) \n",
    "    \n",
    "    # Inizializza isole o popolazione unica\n",
    "    if use_islands:\n",
    "        islands = initialize_islands(initial_population, config, n_islands)\n",
    "        best_individual = min([island.best_individual for island in islands if island.best_individual], \n",
    "                            key=lambda x: x.adjusted_fitness, default=None)\n",
    "        best_fitness = float('inf') if best_individual is None else best_individual.adjusted_fitness\n",
    "    else:\n",
    "        population = initial_population\n",
    "        best_individual = min(population, key=lambda x: float('inf') if x.adjusted_fitness is None else x.adjusted_fitness)\n",
    "        best_fitness = best_individual.adjusted_fitness\n",
    "    \n",
    "    # Statistiche per monitoraggio\n",
    "    stats = {\n",
    "        'best_fitness': [],\n",
    "        'avg_fitness': [],\n",
    "        'avg_size': [],\n",
    "        'best_size': [],\n",
    "        'diversity': []\n",
    "    }\n",
    "    \n",
    "    # Loop principale evolutivo\n",
    "    generations_without_improvement = 0\n",
    "    for generation in tqdm(range(config.generations)):\n",
    "        generation_start = time.time()\n",
    "        \n",
    "        if use_islands:\n",
    "            # Evolvi ogni isola separatamente\n",
    "            for island in islands:\n",
    "                island.evolve(X, y, generation)\n",
    "            \n",
    "            # Migrazione periodica\n",
    "            if (generation + 1) % migration_interval == 0:\n",
    "                migration(islands, migration_rate=0.1)\n",
    "            \n",
    "            # Calcola il miglior individuo globale\n",
    "            current_best = min([island.best_individual for island in islands if island.best_individual], \n",
    "                             key=lambda x: x.adjusted_fitness)\n",
    "            \n",
    "            # Calcola statistiche aggregate\n",
    "            all_individuals = []\n",
    "            for island in islands:\n",
    "                all_individuals.extend(island.population)\n",
    "            \n",
    "            avg_fitness = np.mean([tree.adjusted_fitness for tree in all_individuals if tree.adjusted_fitness != float('inf')])\n",
    "            avg_size = np.mean([tree.get_complexity() for tree in all_individuals])\n",
    "            \n",
    "            # Calcola diversità (numero di espressioni uniche)\n",
    "            unique_expressions = set()\n",
    "            for tree in all_individuals:\n",
    "                unique_expressions.add(tree.to_string())\n",
    "            diversity = len(unique_expressions) / len(all_individuals)\n",
    "            \n",
    "        else:\n",
    "            # Applica operatori genetici\n",
    "            population = apply_genetic_operators(population, X, y, config)\n",
    "            \n",
    "            #apply_novelty_search(population, X)\n",
    "            \n",
    "            # Controllo del bloat\n",
    "            apply_bloat_control(population, config)\n",
    "            \n",
    "            # Calcola il miglior individuo\n",
    "            current_best = min(population, key=lambda x: float('inf') if x.adjusted_fitness is None else x.adjusted_fitness)\n",
    "            \n",
    "            # Calcola statistiche\n",
    "            avg_fitness = np.mean([tree.adjusted_fitness for tree in population if tree.adjusted_fitness != float('inf')])\n",
    "            avg_size = np.mean([tree.get_complexity() for tree in population])\n",
    "            \n",
    "            # Calcola diversità (numero di espressioni uniche)\n",
    "            unique_expressions = set()\n",
    "            for tree in population:\n",
    "                unique_expressions.add(tree.to_string())\n",
    "            diversity = len(unique_expressions) / len(population)\n",
    "        \n",
    "        # Aggiorna il miglior individuo globale\n",
    "        if current_best.adjusted_fitness < best_fitness:\n",
    "            best_individual = current_best.copy()\n",
    "            best_fitness = current_best.adjusted_fitness\n",
    "            generations_without_improvement = 0\n",
    "            print(f\"Nuova miglior soluzione trovata:\")\n",
    "            print(f\"  Espressione: {best_individual.to_string()}\")\n",
    "            print(f\"  Fitness: {best_fitness}\")\n",
    "            print(f\"  Complessità: {best_individual.get_complexity()} nodi\")\n",
    "        else:\n",
    "            generations_without_improvement += 1\n",
    "        \n",
    "        # Registra statistiche\n",
    "        stats['best_fitness'].append(best_fitness)\n",
    "        stats['avg_fitness'].append(avg_fitness)\n",
    "        stats['avg_size'].append(avg_size)\n",
    "        stats['best_size'].append(best_individual.get_complexity())\n",
    "        stats['diversity'].append(diversity)\n",
    "        \n",
    "        # Log della generazione\n",
    "        generation_time = time.time() - generation_start\n",
    "        if generation % 5 == 0 or generation == config.generations - 1:\n",
    "           ic(f\"Generazione {generation}\", best_fitness, f\"Diversità {diversity:.2f}\", f\"Tempo {generation_time:.2f}s\")\n",
    "        \n",
    "        # Criterio di terminazione anticipata\n",
    "        if generations_without_improvement >= 100:\n",
    "            print(\"Terminazione anticipata: nessun miglioramento nelle ultime 20 generazioni\")\n",
    "            break\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"Algoritmo completato in {total_time:.2f} secondi\")\n",
    "    print(f\"Miglior soluzione trovata:\")\n",
    "    print(f\"  Espressione: {best_individual.to_string()}\")\n",
    "    print(f\"  Fitness: {best_fitness}\")\n",
    "    print(f\"  Complessità: {best_individual.get_complexity()} nodi\")\n",
    "    \n",
    "    # Visualizza statistiche\n",
    "    plot_statistics(stats)\n",
    "    \n",
    "    return best_individual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444fe737",
   "metadata": {},
   "source": [
    "### Termination AND Evaluetion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d4e75dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_statistics(stats: Dict) -> None:\n",
    "    \"\"\"\n",
    "    Visualizza le statistiche dell'esecuzione\n",
    "    \n",
    "    Args:\n",
    "        stats: Dizionario con le statistiche raccolte\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(10, 12))\n",
    "    \n",
    "    # Fitness plot\n",
    "    axs[0].plot(stats['best_fitness'], label='Miglior fitness')\n",
    "    axs[0].plot(stats['avg_fitness'], label='Fitness medio')\n",
    "    axs[0].set_title('Evoluzione del fitness')\n",
    "    axs[0].set_xlabel('Generazione')\n",
    "    axs[0].set_ylabel('Fitness (MSE)')\n",
    "    axs[0].legend()\n",
    "    axs[0].grid(True)\n",
    "    \n",
    "    # Size plot\n",
    "    axs[1].plot(stats['best_size'], label='Dimensione miglior individuo')\n",
    "    axs[1].plot(stats['avg_size'], label='Dimensione media')\n",
    "    axs[1].set_title('Evoluzione della dimensione')\n",
    "    axs[1].set_xlabel('Generazione')\n",
    "    axs[1].set_ylabel('Numero di nodi')\n",
    "    axs[1].legend()\n",
    "    axs[1].grid(True)\n",
    "    \n",
    "    # Diversity plot\n",
    "    axs[2].plot(stats['diversity'], label='Diversità')\n",
    "    axs[2].set_title('Evoluzione della diversità')\n",
    "    axs[2].set_xlabel('Generazione')\n",
    "    axs[2].set_ylabel('Proporzione di espressioni uniche')\n",
    "    axs[2].legend()\n",
    "    axs[2].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gp_statistics.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_predictions(tree: ExpressionTree, X: np.ndarray, y: np.ndarray, title: str) -> None:\n",
    "    \"\"\"\n",
    "    Visualizza le previsioni del modello confrontate con i dati reali\n",
    "    \n",
    "    Args:\n",
    "        tree: Albero di espressione\n",
    "        X: Input features\n",
    "        y: Output target\n",
    "        title: Titolo del grafico\n",
    "    \"\"\"\n",
    "    # Calcola le previsioni\n",
    "    predictions = tree.evaluate(X)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    if X.ndim == 1 or (X.ndim == 2 and X.shape[1] == 1):\n",
    "        # Per dati 1D, visualizza previsioni vs. dati reali\n",
    "        x_plot = X.flatten() if X.ndim == 2 else X\n",
    "        sort_idx = np.argsort(x_plot)\n",
    "        x_plot = x_plot[sort_idx]\n",
    "        y_plot = y[sort_idx]\n",
    "        predictions = predictions[sort_idx]\n",
    "        \n",
    "        plt.scatter(x_plot, y_plot, alpha=0.5, label='Dati reali')\n",
    "        plt.plot(x_plot, predictions, 'r-', linewidth=2, label='Modello GP')\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('y')\n",
    "    else:\n",
    "        # Per dati multidimensionali, visualizza previsioni vs. reali\n",
    "        plt.scatter(y, predictions, alpha=0.5)\n",
    "        plt.plot([min(y), max(y)], [min(y), max(y)], 'r--', linewidth=2)\n",
    "        plt.xlabel('Target reale')\n",
    "        plt.ylabel('Previsione')\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('gp_predictions.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33f115e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_expression(expression: str) -> str:\n",
    "    \"\"\"\n",
    "    Semplifica un'espressione (implementazione base)\n",
    "    \n",
    "    Args:\n",
    "        expression: Espressione come stringa\n",
    "        \n",
    "    Returns:\n",
    "        Espressione semplificata\n",
    "    \"\"\"\n",
    "    # Questo è un semplificatore molto elementare\n",
    "    # Per una semplificazione completa sarebbe necessario utilizzare una libreria\n",
    "    # come sympy\n",
    "    \n",
    "    # Esempio di alcune semplificazioni\n",
    "    simplifications = [\n",
    "        # Operazioni con 0\n",
    "        ('(0.0000 + ', '('),\n",
    "        ('(0.0000 * ', '(0.0000 * '),\n",
    "        ('+ 0.0000)', ')'),\n",
    "        ('* 0.0000)', '* 0.0000)'),\n",
    "        ('(x[0] * 0.0000)', '0.0000'),\n",
    "        ('(0.0000 * x[0])', '0.0000'),\n",
    "        \n",
    "        # Operazioni con 1\n",
    "        ('(x[0] * 1.0000)', 'x[0]'),\n",
    "        ('(1.0000 * x[0])', 'x[0]'),\n",
    "        ('(x[0] / 1.0000)', 'x[0]'),\n",
    "        \n",
    "        # Operazioni con se stesso\n",
    "        ('(x[0] - x[0])', '0.0000'),\n",
    "        ('(x[0] / x[0])', '1.0000'),\n",
    "    ]\n",
    "    \n",
    "    # Applica semplificazioni ripetutamente\n",
    "    prev_expr = \"\"\n",
    "    simplified = expression\n",
    "    while prev_expr != simplified:\n",
    "        prev_expr = simplified\n",
    "        for pattern, replacement in simplifications:\n",
    "            simplified = simplified.replace(pattern, replacement)\n",
    "    \n",
    "    return simplified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c43ec6",
   "metadata": {},
   "source": [
    "### Configuration and Execution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8dda068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gp_on_problem(file_path: str, config_overrides: Dict = None) -> ExpressionTree:\n",
    "    \"\"\"\n",
    "    Esegue l'algoritmo GP su un problema specifico\n",
    "    \n",
    "    Args:\n",
    "        file_path: Percorso del file del problema\n",
    "        config_overrides: Sovrascritture alla configurazione predefinita\n",
    "        \n",
    "    Returns:\n",
    "        Il miglior albero di espressione trovato\n",
    "    \"\"\"\n",
    "    # Carica e prepara i dati\n",
    "    X, y, data_config = prepare_data(file_path)\n",
    "    \n",
    "    # Crea la configurazione base\n",
    "    config = GPConfig(\n",
    "        n_features=data_config['n_features'],\n",
    "        const_range=data_config['const_range'],\n",
    "        use_trig=True,\n",
    "        use_exp_log=True,\n",
    "        min_depth=2,\n",
    "        max_depth=6,\n",
    "        pop_size=500,\n",
    "        generations=50,\n",
    "        tournament_size=100,\n",
    "        crossover_prob=0.7,\n",
    "        mutation_prob=0.05,\n",
    "        elitism_rate=0.1,\n",
    "        max_tree_size=50,\n",
    "        parsimony_coef=0.01,\n",
    "        diversity_weight=0.2\n",
    "    )\n",
    "    \n",
    "    # Applica sovrascritture alla configurazione\n",
    "    if config_overrides:\n",
    "        for key, value in config_overrides.items():\n",
    "            if hasattr(config, key):\n",
    "                setattr(config, key, value)\n",
    "    \n",
    "    # Esegui l'algoritmo\n",
    "    print(f\"\\nEsecuzione GP su {file_path}...\")\n",
    "    best_tree = genetic_programming(X, y, config, use_islands=True)\n",
    "    \n",
    "    # Visualizza risultati\n",
    "    plot_predictions(best_tree, X, y, f\"Previsioni GP su {file_path}\")\n",
    "    \n",
    "    # Semplifica l'espressione\n",
    "    simplified_expr = simplify_expression(best_tree.to_string())\n",
    "    print(f\"Espressione semplificata: {simplified_expr}\")\n",
    "    \n",
    "    return best_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "23fb8320",
   "metadata": {},
   "outputs": [],
   "source": [
    "problems=[\n",
    "    {\"file_path\": \"../data/problem_0.npz\", \"config\":{\"max_depth\": 3, \"pop_size\": 10000, \"generations\": 1000}},\n",
    "    {\"file_path\": \"../data/problem_1.npz\", \"config\":{\"max_depth\": 8, \"pop_size\": 10000, \"generations\": 1000}},\n",
    "    {\"file_path\": \"../data/problem_2.npz\", \"config\":{\"max_depth\": 8, \"pop_size\": 10000, \"generations\": 1000}},\n",
    "    {\"file_path\": \"../data/problem_3.npz\", \"config\":{\"max_depth\": 8, \"pop_size\": 10000, \"generations\": 1000}},\n",
    "    {\"file_path\": \"../data/problem_4.npz\", \"config\":{\"max_depth\": 8, \"pop_size\": 10000, \"generations\": 1000}},\n",
    "    {\"file_path\": \"../data/problem_5.npz\", \"config\":{\"max_depth\": 8, \"pop_size\": 10000, \"generations\": 1000}},\n",
    "    {\"file_path\": \"../data/problem_6.npz\", \"config\":{\"max_depth\": 8, \"pop_size\": 10000, \"generations\": 1000}},\n",
    "    {\"file_path\": \"../data/problem_7.npz\", \"config\":{\"max_depth\": 8, \"pop_size\": 10000, \"generations\": 1000}},\n",
    "    {\"file_path\": \"../data/problem_8.npz\", \"config\":{\"max_depth\": 8, \"pop_size\": 10000, \"generations\": 1000}},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276b2b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Esecuzione GP su ../data/problem_0.npz ===\n",
      "Caricamento dati da ../data/problem_0.npz...\n",
      "Forme originali: X shape (2, 1000), y shape (1000,)\n",
      "Rilevato formato con features sulle righe e campioni sulle colonne, trasposizione...\n",
      "X trasposto ha forma (1000, 2)\n",
      "Forme finali: X shape (1000, 2), y shape (1000,)\n",
      "Input 2-dimensionale con 1000 campioni\n",
      "\n",
      "Esecuzione GP su ../data/problem_0.npz...\n",
      "Avvio Genetic Programming per Symbolic Regression...\n",
      "Configurazione: pop_size=10000, max_depth=3, generations=1000\n",
      "Inizializzazione popolazione di 10000 individui...\n",
      "  Generati 1000 individui in 0.01 secondi\n",
      "  Generati 2000 individui in 0.03 secondi\n",
      "  Generati 3000 individui in 0.04 secondi\n",
      "  Generati 4000 individui in 0.06 secondi\n",
      "  Generati 5000 individui in 0.08 secondi\n",
      "  Generati 6000 individui in 0.09 secondi\n",
      "  Generati 7000 individui in 0.15 secondi\n",
      "  Generati 8000 individui in 0.16 secondi\n",
      "  Generati 9000 individui in 0.18 secondi\n",
      "  Generati 10000 individui in 0.19 secondi\n",
      "Popolazione inizializzata in 0.19 secondi\n",
      "Statistiche sulla popolazione iniziale:\n",
      "  - Altezza media: 2.53 (min: 2, max: 3)\n",
      "  - Dimensione media: 6.82 nodi (min: 3, max: 15)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[0]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(problems[0]['file_path'], problems[0]['config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f05602",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[1]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(problems[1]['file_path'], problems[1]['config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a93d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[2]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(problems[2]['file_path'], problems[2]['config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d9c433",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[3]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(problems[3]['file_path'], problems[3]['config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750a8f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[4]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(problems[4]['file_path'], problems[4]['config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4203d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[5]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(problems[5]['file_path'], problems[5]['config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b247a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[6]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(problems[6]['file_path'], problems[6]['config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dceedcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[7]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(problems[7]['file_path'], problems[7]['config'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f81a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n=== Esecuzione GP su {problems[8]['file_path']} ===\")\n",
    "best_tree = run_gp_on_problem(problems[8]['file_path'], problems[8]['config'])    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
